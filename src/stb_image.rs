// Generated by Ur at 12.08.2018 2:32:18

use std;
use c_runtime;

const STBI_default:i32 = 0;
const STBI_grey:i32 = 1;
const STBI_grey_alpha:i32 = 2;
const STBI_rgb:i32 = 3;
const STBI_rgb_alpha:i32 = 4;
const STBI_ORDER_RGB:i32 = 0;
const STBI_ORDER_BGR:i32 = 1;
const STBI__SCAN_load:i32 = 0;
const STBI__SCAN_type:i32 = 1;
const STBI__SCAN_header:i32 = 2;
const STBI__F_none:i32 = 0;
const STBI__F_sub:i32 = 1;
const STBI__F_up:i32 = 2;
const STBI__F_avg:i32 = 3;
const STBI__F_paeth:i32 = 4;
const STBI__F_avg_first:i32 = 5;
const STBI__F_paeth_first:i32 = 6;

const stbi__vertically_flip_on_load:i32 = 0;
const stbi__h2l_gamma_i:f32 = 1.0f32 / 2.2f32;
const stbi__h2l_scale_i:f32 = 1.0f32;
const stbi__zlength_base:[i32;31] = unsafe {std::mem::uninitialized()};
const stbi__zlength_extra:[i32;31] = unsafe {std::mem::uninitialized()};
const stbi__zdist_base:[i32;32] = unsafe {std::mem::uninitialized()};
const stbi__zdist_extra:[i32;30] = unsafe {std::mem::uninitialized()};
const length_dezigzag:[u8;19] = unsafe {std::mem::uninitialized()};
const stbi__zdefault_length:[u8;288] = unsafe {std::mem::uninitialized()};
const stbi__zdefault_distance:[u8;32] = unsafe {std::mem::uninitialized()};
const png_sig:[u8;8] = unsafe {std::mem::uninitialized()};
const first_row_filter:[i32;5] = unsafe {std::mem::uninitialized()};
const stbi__depth_scale_table:[u8;9] = unsafe {std::mem::uninitialized()};
const stbi__unpremultiply_on_load:i32 = 0;
const stbi__de_iphone_flag:i32 = 0;
struct stbi__context {
img_x: u32,
img_y: u32,
img_n: i32,
img_out_n: i32,
io: stbi_io_callbacks,
io_user_data: *mut u8,
read_from_callbacks: i32,
buflen: i32,
buffer_start: [u8;128],
img_buffer: *mut u8,
img_buffer_end: *mut u8,
img_buffer_original: *mut u8,
img_buffer_original_end: *mut u8,
}

struct stbi__result_info {
bits_per_channel: i32,
num_channels: i32,
channel_order: i32,
}

struct stbi__zhuffman {
fast: [u16;512],
firstcode: [u16;16],
maxcode: [i32;17],
firstsymbol: [u16;16],
size: [u8;288],
value: [u16;288],
}

struct stbi__zbuf {
zbuffer: *mut u8,
zbuffer_end: *mut u8,
num_bits: i32,
code_buffer: u32,
zout: *mut i8,
zout_start: *mut i8,
zout_end: *mut i8,
z_expandable: i32,
z_length: stbi__zhuffman,
z_distance: stbi__zhuffman,
}

struct stbi__pngchunk {
length: u32,
_type_: u32,
}

struct stbi__png {
s: *mut stbi__context,
idata: *mut u8,
expanded: *mut u8,
_out_: *mut u8,
depth: i32,
}

unsafe fn stbi__start_mem(s:*mut stbi__context, buffer:*mut u8, len:i32){
	(*s).io.read = (std::ptr::null_mut());
	(*s).read_from_callbacks = ((0) as i32);
	(*s).img_buffer = buffer;
	(*s).img_buffer_original = buffer;
	(*s).img_buffer_end = (buffer).offset((len) as isize);
	(*s).img_buffer_original_end = (buffer).offset((len) as isize);
}

unsafe fn stbi__start_callbacks(s:*mut stbi__context, c:*mut stbi_io_callbacks, user:*mut u8){
	(*s).io = ((*c) as stbi_io_callbacks);
	(*s).io_user_data = user;
	(*s).buflen = (((std::mem::size_of((*s).buffer_start)) as i32) as i32);
	(*s).read_from_callbacks = ((1) as i32);
	(*s).img_buffer_original = (*s).buffer_start.as_mut_ptr();
	stbi__refill_buffer(s);
	(*s).img_buffer_original_end = (*s).img_buffer_end;
}

unsafe fn stbi__rewind(s:*mut stbi__context){
	(*s).img_buffer = (*s).img_buffer_original;
	(*s).img_buffer_end = (*s).img_buffer_original_end;
}

unsafe fn stbi__malloc(size:u64) -> *mut u8 {
	return c_runtime::malloc(((size) as u64));
}

unsafe fn stbi__addsizes_valid(a:i32, b:i32) -> i32 {
	if b < 0 {return 0;}
	return (a <= 2147483647 - b) as i32;
}

unsafe fn stbi__mul2sizes_valid(a:i32, b:i32) -> i32 {
	if a < 0 || b < 0 {return 0;}
	if b == 0 {return 1;}
	return (a <= 2147483647 / b) as i32;
}

unsafe fn stbi__mad2sizes_valid(a:i32, b:i32, add:i32) -> i32 {
	return ((stbi__mul2sizes_valid(((a) as i32), ((b) as i32))) != 0 && (stbi__addsizes_valid(((a * b) as i32), ((add) as i32))) != 0) as i32;
}

unsafe fn stbi__mad3sizes_valid(a:i32, b:i32, c:i32, add:i32) -> i32 {
	return ((stbi__mul2sizes_valid(((a) as i32), ((b) as i32))) != 0 && (stbi__mul2sizes_valid(((a * b) as i32), ((c) as i32))) != 0 && (stbi__addsizes_valid(((a * b * c) as i32), ((add) as i32))) != 0) as i32;
}

unsafe fn stbi__mad4sizes_valid(a:i32, b:i32, c:i32, d:i32, add:i32) -> i32 {
	return ((stbi__mul2sizes_valid(((a) as i32), ((b) as i32))) != 0 && (stbi__mul2sizes_valid(((a * b) as i32), ((c) as i32))) != 0 && (stbi__mul2sizes_valid(((a * b * c) as i32), ((d) as i32))) != 0 && (stbi__addsizes_valid(((a * b * c * d) as i32), ((add) as i32))) != 0) as i32;
}

unsafe fn stbi__malloc_mad2(a:i32, b:i32, add:i32) -> *mut u8 {
	if stbi__mad2sizes_valid(((a) as i32), ((b) as i32), ((add) as i32)) == 0 {return (std::ptr::null_mut());}
	return stbi__malloc((((a * b + add) as u64) as u64));
}

unsafe fn stbi__malloc_mad3(a:i32, b:i32, c:i32, add:i32) -> *mut u8 {
	if stbi__mad3sizes_valid(((a) as i32), ((b) as i32), ((c) as i32), ((add) as i32)) == 0 {return (std::ptr::null_mut());}
	return stbi__malloc((((a * b * c + add) as u64) as u64));
}

unsafe fn stbi__malloc_mad4(a:i32, b:i32, c:i32, d:i32, add:i32) -> *mut u8 {
	if stbi__mad4sizes_valid(((a) as i32), ((b) as i32), ((c) as i32), ((d) as i32), ((add) as i32)) == 0 {return (std::ptr::null_mut());}
	return stbi__malloc((((a * b * c * d + add) as u64) as u64));
}

unsafe fn stbi_image_free(retval_from_stbi_load:*mut u8){
	c_runtime::free(retval_from_stbi_load);
}

unsafe fn stbi_set_flip_vertically_on_load(flag_true_if_should_flip:i32){
	stbi__vertically_flip_on_load = ((flag_true_if_should_flip) as i32);
}

unsafe fn stbi__load_main(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32, ri:*mut stbi__result_info, bpc:i32) -> *mut u8 {
	(*ri).bits_per_channel = ((8) as i32);
	(*ri).channel_order = ((STBI_ORDER_RGB) as i32);
	(*ri).num_channels = ((0) as i32);
	if (stbi__png_test(s)) != 0 {return stbi__png_load(s, x, y, comp, ((req_comp) as i32), ri);}
	return if (stbi__err("unknown image type")) != 0{(std::ptr::null_mut())} else {(std::ptr::null_mut())}
}

unsafe fn stbi__convert_16_to_8(orig:*mut u16, w:i32, h:i32, channels:i32) -> *mut u8 {
	let mut i:i32 = std::mem::uninitialized();
	let mut img_len:i32 = w * h * channels;
	let reduced:*mut u8;
	reduced = stbi__malloc((((img_len) as u64) as u64));
	if reduced == (std::ptr::null_mut()) {return if (stbi__err("outofmem")) != 0{(std::ptr::null_mut())} else {(std::ptr::null_mut())}}
	i = ((0) as i32);
while (i < img_len) {
i += 1;
*reduced.offset((i) as isize) = (((((*orig.offset((i) as isize)) as i32) >> 8 & 0xFF) as u8) as u8);}
	c_runtime::free(orig);
	return reduced;
}

unsafe fn stbi__convert_8_to_16(orig:*mut u8, w:i32, h:i32, channels:i32) -> *mut u16 {
	let mut i:i32 = std::mem::uninitialized();
	let mut img_len:i32 = w * h * channels;
	let enlarged:*mut u16;
	enlarged = ((stbi__malloc((((img_len * 2) as u64) as u64))) as *mut u16);
	if enlarged == (std::ptr::null_mut()) {return if ((stbi__err("outofmem")) as *mut u16){(std::ptr::null_mut())} else {(std::ptr::null_mut())}}
	i = ((0) as i32);
while (i < img_len) {
i += 1;
*enlarged.offset((i) as isize) = (((((*orig.offset((i) as isize)) as i32) << 8 + ((*orig.offset((i) as isize)) as i32)) as u16) as u16);}
	c_runtime::free(orig);
	return enlarged;
}

unsafe fn stbi__vertical_flip(image:*mut u8, w:i32, h:i32, bytes_per_pixel:i32){
	let mut row:i32 = std::mem::uninitialized();
	let mut bytes_per_row:u64 = ((w) as u64) * ((bytes_per_pixel) as u64);
	let mut temp:[u8;2048] = unsafe {std::mem::uninitialized()};
	let bytes:*mut u8 = image;
	row = ((0) as i32);
while (row < h >> 1) {row += 1;

let mut row0:i32 = ((((row) as u64) * bytes_per_row) as i32);let mut row1:i32 = ((((h - row - 1) as u64) * bytes_per_row) as i32);let mut bytes_left:u64 = bytes_per_row;while ((bytes_left) != 0) {
let mut bytes_copy:u64 = if bytes_left < ((2048) as u64){bytes_left} else {((2048) as u64)};c_runtime::memcpy(temp.as_mut_ptr(), (bytes).offset((row0) as isize), ((bytes_copy) as u64));c_runtime::memcpy((bytes).offset((row0) as isize), (bytes).offset((row1) as isize), ((bytes_copy) as u64));c_runtime::memcpy((bytes).offset((row1) as isize), temp.as_mut_ptr(), ((bytes_copy) as u64));row0 += ((bytes_copy) as i32);row1 += ((bytes_copy) as i32);bytes_left -= ((bytes_copy) as u64);}}

}

unsafe fn stbi__load_and_postprocess_8bit(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32) -> *mut u8 {
	let mut ri:stbi__result_info = std::mem::uninitialized();
	let result:*mut u8 = stbi__load_main(s, x, y, comp, ((req_comp) as i32), &mut ri, ((8) as i32));
	if result == (std::ptr::null_mut()) {return (std::ptr::null_mut());}
	if ri.bits_per_channel != 8 {
let mut cmp:i32 = req_comp;if cmp == 0 {cmp = ((*comp) as i32);}result = stbi__convert_16_to_8(((result) as *mut u16), ((*x) as i32), ((*y) as i32), ((cmp) as i32));ri.bits_per_channel = ((8) as i32);}
	if (stbi__vertically_flip_on_load) != 0 {
let mut channels:i32 = if (req_comp) != 0{req_comp} else {*comp};stbi__vertical_flip(result, ((*x) as i32), ((*y) as i32), ((channels) as i32));}
	return result;
}

unsafe fn stbi__load_and_postprocess_16bit(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32) -> *mut u16 {
	let mut ri:stbi__result_info = std::mem::uninitialized();
	let result:*mut u8 = stbi__load_main(s, x, y, comp, ((req_comp) as i32), &mut ri, ((16) as i32));
	if result == (std::ptr::null_mut()) {return (std::ptr::null_mut());}
	if ri.bits_per_channel != 16 {
let mut cmp:i32 = req_comp;if cmp == 0 {cmp = ((*comp) as i32);}result = stbi__convert_8_to_16(result, ((*x) as i32), ((*y) as i32), ((cmp) as i32));ri.bits_per_channel = ((16) as i32);}
	if (stbi__vertically_flip_on_load) != 0 {
let mut channels:i32 = if (req_comp) != 0{req_comp} else {*comp};stbi__vertical_flip(result, ((*x) as i32), ((*y) as i32), ((channels * 2) as i32));}
	return ((result) as *mut u16);
}

unsafe fn stbi_load_16_from_memory(buffer:*mut u8, len:i32, x:*mut i32, y:*mut i32, channels_in_file:*mut i32, desired_channels:i32) -> *mut u16 {
	let mut s:stbi__context = std::mem::uninitialized();
	stbi__start_mem(&mut s, buffer, ((len) as i32));
	return stbi__load_and_postprocess_16bit(&mut s, x, y, channels_in_file, ((desired_channels) as i32));
}

unsafe fn stbi_load_16_from_callbacks(clbk:*mut stbi_io_callbacks, user:*mut u8, x:*mut i32, y:*mut i32, channels_in_file:*mut i32, desired_channels:i32) -> *mut u16 {
	let mut s:stbi__context = std::mem::uninitialized();
	stbi__start_callbacks(&mut s, clbk, user);
	return stbi__load_and_postprocess_16bit(&mut s, x, y, channels_in_file, ((desired_channels) as i32));
}

unsafe fn stbi_load_from_memory(buffer:*mut u8, len:i32, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32) -> *mut u8 {
	let mut s:stbi__context = std::mem::uninitialized();
	stbi__start_mem(&mut s, buffer, ((len) as i32));
	return stbi__load_and_postprocess_8bit(&mut s, x, y, comp, ((req_comp) as i32));
}

unsafe fn stbi_load_from_callbacks(clbk:*mut stbi_io_callbacks, user:*mut u8, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32) -> *mut u8 {
	let mut s:stbi__context = std::mem::uninitialized();
	stbi__start_callbacks(&mut s, clbk, user);
	return stbi__load_and_postprocess_8bit(&mut s, x, y, comp, ((req_comp) as i32));
}

unsafe fn stbi_is_hdr_from_memory(buffer:*mut u8, len:i32) -> i32 {
	return 0;
}

unsafe fn stbi_is_hdr_from_callbacks(clbk:*mut stbi_io_callbacks, user:*mut u8) -> i32 {
	return 0;
}

unsafe fn stbi_hdr_to_ldr_gamma(gamma:f32){
	stbi__h2l_gamma_i = ((((1) as f32) / gamma) as f32);
}

unsafe fn stbi_hdr_to_ldr_scale(scale:f32){
	stbi__h2l_scale_i = ((((1) as f32) / scale) as f32);
}

unsafe fn stbi__refill_buffer(s:*mut stbi__context){
	let mut n:i32 = ((*s).io.read)((*s).io_user_data, (((*s).buffer_start.as_mut_ptr()) as *mut i8), (((*s).buflen) as i32));
	if n == 0 {
(*s).read_from_callbacks = ((0) as i32);(*s).img_buffer = (*s).buffer_start.as_mut_ptr();(*s).img_buffer_end = ((*s).buffer_start.as_mut_ptr()).offset((1) as isize);*(*s).img_buffer = (((0) as u8) as u8);} else {
(*s).img_buffer = (*s).buffer_start.as_mut_ptr();(*s).img_buffer_end = ((*s).buffer_start.as_mut_ptr()).offset((n) as isize);}
}

unsafe fn stbi__get8(s:*mut stbi__context) -> u8 {
	if (*s).img_buffer < (*s).img_buffer_end {return *((*s).img_buffer = (*s).img_buffer.offset(1));}
	if ((*s).read_from_callbacks) != 0 {
stbi__refill_buffer(s);return *((*s).img_buffer = (*s).img_buffer.offset(1));}
	return ((0) as u8);
}

unsafe fn stbi__at_eof(s:*mut stbi__context) -> i32 {
	if ((*s).io.read) != std::ptr::null_mut() {
if ((*s).io.eof)((*s).io_user_data) == 0 {return 0;}if (*s).read_from_callbacks == 0 {return 1;}}
	return ((*s).img_buffer >= (*s).img_buffer_end) as i32;
}

unsafe fn stbi__skip(s:*mut stbi__context, n:i32){
	if n < 0 {
(*s).img_buffer = (*s).img_buffer_end;return;}
	if ((*s).io.read) != std::ptr::null_mut() {
let mut blen:i32 = (((*s).img_buffer_end - (*s).img_buffer) as i32);if blen < n {
(*s).img_buffer = (*s).img_buffer_end;((*s).io.skip)((*s).io_user_data, ((n - blen) as i32));return;}}
	(*s).img_buffer += n;
}

unsafe fn stbi__getn(s:*mut stbi__context, buffer:*mut u8, n:i32) -> i32 {
	if ((*s).io.read) != std::ptr::null_mut() {
let mut blen:i32 = (((*s).img_buffer_end - (*s).img_buffer) as i32);if blen < n {
let mut res:i32 = std::mem::uninitialized();let mut count:i32 = std::mem::uninitialized();c_runtime::memcpy(buffer, (*s).img_buffer, (((blen) as u64) as u64));count = ((((*s).io.read)((*s).io_user_data, (((buffer) as *mut i8)).offset((blen) as isize), ((n - blen) as i32))) as i32);res = ((count == n - blen) as i32);(*s).img_buffer = (*s).img_buffer_end;return res;}}
	if ((*s).img_buffer).offset((n) as isize) <= (*s).img_buffer_end {
c_runtime::memcpy(buffer, (*s).img_buffer, (((n) as u64) as u64));(*s).img_buffer += n;return 1;} else {return 0;}
}

unsafe fn stbi__get16be(s:*mut stbi__context) -> i32 {
	let mut z:i32 = ((stbi__get8(s)) as i32);
	return z << 8 + ((stbi__get8(s)) as i32);
}

unsafe fn stbi__get32be(s:*mut stbi__context) -> u32 {
	let mut z:u32 = ((stbi__get16be(s)) as u32);
	return z << 16 + ((stbi__get16be(s)) as u32);
}

unsafe fn stbi__compute_y(r:i32, g:i32, b:i32) -> u8 {
	return ((r * 77 + g * 150 + 29 * b >> 8) as u8);
}

unsafe fn stbi__convert_format(data:*mut u8, img_n:i32, req_comp:i32, x:u32, y:u32) -> *mut u8 {
	let mut i:i32 = std::mem::uninitialized();let mut j:i32 = std::mem::uninitialized();
	let good:*mut u8;
	if req_comp == img_n {return data;}
	good = stbi__malloc_mad3(((req_comp) as i32), (((x) as i32) as i32), (((y) as i32) as i32), ((0) as i32));
	if good == (std::ptr::null_mut()) {
c_runtime::free(data);return if (stbi__err("outofmem")) != 0{(std::ptr::null_mut())} else {(std::ptr::null_mut())}}
	j = ((0) as i32);
while (j < ((y) as i32)) {j += 1;

let mut src:i32 = ((((j) as u32) * x * ((img_n) as u32)) as i32);let mut dest:i32 = ((((j) as u32) * x * ((req_comp) as u32)) as i32);{
if img_n * 8 + req_comp == 1 * 8 + 2 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((1) as i32) ; dest += ((2) as i32);

*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u8);*good.offset((dest + 1) as isize) = (((255) as u8) as u8);}
} else if img_n * 8 + req_comp == 1 * 8 + 3 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((1) as i32) ; dest += ((3) as i32);

*good.offset((dest) as isize) = ((*good.offset((dest + 1) as isize) = ((*good.offset((dest + 2) as isize) = ((*data.offset((src) as isize)) as u8)) as u8)) as u8);}
} else if img_n * 8 + req_comp == 1 * 8 + 4 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((1) as i32) ; dest += ((4) as i32);

*good.offset((dest) as isize) = ((*good.offset((dest + 1) as isize) = ((*good.offset((dest + 2) as isize) = ((*data.offset((src) as isize)) as u8)) as u8)) as u8);}
} else if img_n * 8 + req_comp == 2 * 8 + 1 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((2) as i32) ; dest += ((1) as i32);

*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u8);}
} else if img_n * 8 + req_comp == 2 * 8 + 3 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((2) as i32) ; dest += ((3) as i32);

*good.offset((dest) as isize) = ((*good.offset((dest + 1) as isize) = ((*good.offset((dest + 2) as isize) = ((*data.offset((src) as isize)) as u8)) as u8)) as u8);}
} else if img_n * 8 + req_comp == 2 * 8 + 4 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((2) as i32) ; dest += ((4) as i32);

*good.offset((dest) as isize) = ((*good.offset((dest + 1) as isize) = ((*good.offset((dest + 2) as isize) = ((*data.offset((src) as isize)) as u8)) as u8)) as u8);}
} else if img_n * 8 + req_comp == 3 * 8 + 4 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((3) as i32) ; dest += ((4) as i32);

*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u8);*good.offset((dest + 1) as isize) = ((*data.offset((src + 1) as isize)) as u8);*good.offset((dest + 2) as isize) = ((*data.offset((src + 2) as isize)) as u8);}
} else if img_n * 8 + req_comp == 3 * 8 + 1 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((3) as i32) ; dest += ((1) as i32);

*good.offset((dest) as isize) = ((stbi__compute_y((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u8);}
} else if img_n * 8 + req_comp == 3 * 8 + 2 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((3) as i32) ; dest += ((2) as i32);

*good.offset((dest) as isize) = ((stbi__compute_y((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u8);*good.offset((dest + 1) as isize) = (((255) as u8) as u8);}
} else if img_n * 8 + req_comp == 4 * 8 + 1 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((4) as i32) ; dest += ((1) as i32);

*good.offset((dest) as isize) = ((stbi__compute_y((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u8);}
} else if img_n * 8 + req_comp == 4 * 8 + 2 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((4) as i32) ; dest += ((2) as i32);

*good.offset((dest) as isize) = ((stbi__compute_y((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u8);}
} else if img_n * 8 + req_comp == 4 * 8 + 3 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((4) as i32) ; dest += ((3) as i32);

*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u8);*good.offset((dest + 1) as isize) = ((*data.offset((src + 1) as isize)) as u8);*good.offset((dest + 2) as isize) = ((*data.offset((src + 2) as isize)) as u8);}
} else { return if (stbi__err("0")) != 0{(std::ptr::null_mut())} else {(std::ptr::null_mut())}}
}}

	c_runtime::free(data);
	return good;
}

unsafe fn stbi__compute_y_16(r:i32, g:i32, b:i32) -> u16 {
	return ((r * 77 + g * 150 + 29 * b >> 8) as u16);
}

unsafe fn stbi__convert_format16(data:*mut u16, img_n:i32, req_comp:i32, x:u32, y:u32) -> *mut u16 {
	let mut i:i32 = std::mem::uninitialized();let mut j:i32 = std::mem::uninitialized();
	let good:*mut u16;
	if req_comp == img_n {return data;}
	good = ((stbi__malloc((((((req_comp) as u32) * x * y * ((2) as u32)) as u64) as u64))) as *mut u16);
	if good == (std::ptr::null_mut()) {
c_runtime::free(data);return if ((stbi__err("outofmem")) as *mut u16){(std::ptr::null_mut())} else {(std::ptr::null_mut())}}
	j = ((0) as i32);
while (j < ((y) as i32)) {j += 1;

let mut src:i32 = ((((j) as u32) * x * ((img_n) as u32)) as i32);let mut dest:i32 = ((((j) as u32) * x * ((req_comp) as u32)) as i32);{
if img_n * 8 + req_comp == 1 * 8 + 2 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((1) as i32) ; dest += ((2) as i32);

*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u16);*good.offset((dest + 1) as isize) = (((0xffff) as u16) as u16);}
} else if img_n * 8 + req_comp == 1 * 8 + 3 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((1) as i32) ; dest += ((3) as i32);

*good.offset((dest) as isize) = ((*good.offset((dest + 1) as isize) = ((*good.offset((dest + 2) as isize) = ((*data.offset((src) as isize)) as u16)) as u16)) as u16);}
} else if img_n * 8 + req_comp == 1 * 8 + 4 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((1) as i32) ; dest += ((4) as i32);

*good.offset((dest) as isize) = ((*good.offset((dest + 1) as isize) = ((*good.offset((dest + 2) as isize) = ((*data.offset((src) as isize)) as u16)) as u16)) as u16);}
} else if img_n * 8 + req_comp == 2 * 8 + 1 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((2) as i32) ; dest += ((1) as i32);

*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u16);}
} else if img_n * 8 + req_comp == 2 * 8 + 3 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((2) as i32) ; dest += ((3) as i32);

*good.offset((dest) as isize) = ((*good.offset((dest + 1) as isize) = ((*good.offset((dest + 2) as isize) = ((*data.offset((src) as isize)) as u16)) as u16)) as u16);}
} else if img_n * 8 + req_comp == 2 * 8 + 4 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((2) as i32) ; dest += ((4) as i32);

*good.offset((dest) as isize) = ((*good.offset((dest + 1) as isize) = ((*good.offset((dest + 2) as isize) = ((*data.offset((src) as isize)) as u16)) as u16)) as u16);}
} else if img_n * 8 + req_comp == 3 * 8 + 4 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((3) as i32) ; dest += ((4) as i32);

*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u16);*good.offset((dest + 1) as isize) = ((*data.offset((src + 1) as isize)) as u16);*good.offset((dest + 2) as isize) = ((*data.offset((src + 2) as isize)) as u16);}
} else if img_n * 8 + req_comp == 3 * 8 + 1 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((3) as i32) ; dest += ((1) as i32);

*good.offset((dest) as isize) = ((stbi__compute_y_16((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u16);}
} else if img_n * 8 + req_comp == 3 * 8 + 2 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((3) as i32) ; dest += ((2) as i32);

*good.offset((dest) as isize) = ((stbi__compute_y_16((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u16);*good.offset((dest + 1) as isize) = (((0xffff) as u16) as u16);}
} else if img_n * 8 + req_comp == 4 * 8 + 1 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((4) as i32) ; dest += ((1) as i32);

*good.offset((dest) as isize) = ((stbi__compute_y_16((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u16);}
} else if img_n * 8 + req_comp == 4 * 8 + 2 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((4) as i32) ; dest += ((2) as i32);

*good.offset((dest) as isize) = ((stbi__compute_y_16((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u16);}
} else if img_n * 8 + req_comp == 4 * 8 + 3 {i = (((x - ((1) as u32)) as i32) as i32);
while (i >= 0) {i -= 1 ; src += ((4) as i32) ; dest += ((3) as i32);

*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u16);*good.offset((dest + 1) as isize) = ((*data.offset((src + 1) as isize)) as u16);*good.offset((dest + 2) as isize) = ((*data.offset((src + 2) as isize)) as u16);}
} else { return if ((stbi__err("0")) as *mut u16){(std::ptr::null_mut())} else {(std::ptr::null_mut())}}
}}

	c_runtime::free(data);
	return good;
}

unsafe fn stbi__bitreverse16(n:i32) -> i32 {
	n = ((n & 0xAAAA >> 1 | n & 0x5555 << 1) as i32);
	n = ((n & 0xCCCC >> 2 | n & 0x3333 << 2) as i32);
	n = ((n & 0xF0F0 >> 4 | n & 0x0F0F << 4) as i32);
	n = ((n & 0xFF00 >> 8 | n & 0x00FF << 8) as i32);
	return n;
}

unsafe fn stbi__bit_reverse(v:i32, bits:i32) -> i32 {
	return stbi__bitreverse16(((v) as i32)) >> 16 - bits;
}

unsafe fn stbi__zbuild_huffman(z:*mut stbi__zhuffman, sizelist:*mut u8, num:i32) -> i32 {
	let mut i:i32 = std::mem::uninitialized();let mut k:i32 = 0;
	let mut code:i32 = std::mem::uninitialized();let mut next_code:[i32;16] = unsafe {std::mem::uninitialized()};let mut sizes:[i32;17] = unsafe {std::mem::uninitialized()};
	c_runtime::memset(sizes.as_mut_ptr(), ((0) as i32), ((std::mem::size_of(sizes)) as u64));
	c_runtime::memset((*z).fast.as_mut_ptr(), ((0) as i32), ((std::mem::size_of((*z).fast)) as u64));
	i = ((0) as i32);
while (i < num) {
i += 1;
*sizes.as_mut_ptr().offset((*sizelist.offset((i) as isize)) as isize) += 1;}
	*sizes.as_mut_ptr().offset((0) as isize) = ((0) as i32);
	i = ((1) as i32);
while (i < 16) {
i += 1;
if *sizes.as_mut_ptr().offset((i) as isize) > 1 << i {return stbi__err("bad sizes");}}
	code = ((0) as i32);
	i = ((1) as i32);
while (i < 16) {i += 1;

*next_code.as_mut_ptr().offset((i) as isize) = ((code) as i32);*(*z).firstcode.as_mut_ptr().offset((i) as isize) = (((code) as u16) as u16);*(*z).firstsymbol.as_mut_ptr().offset((i) as isize) = (((k) as u16) as u16);code = ((code + *sizes.as_mut_ptr().offset((i) as isize)) as i32);if (*sizes.as_mut_ptr().offset((i) as isize)) != 0 {if code - 1 >= 1 << i {return stbi__err("bad codelengths");}}*(*z).maxcode.as_mut_ptr().offset((i) as isize) = ((code << 16 - i) as i32);code <<= 1;k += ((*sizes.as_mut_ptr().offset((i) as isize)) as i32);}

	*(*z).maxcode.as_mut_ptr().offset((16) as isize) = ((0x10000) as i32);
	i = ((0) as i32);
while (i < num) {i += 1;

let mut s:i32 = ((*sizelist.offset((i) as isize)) as i32);if (s) != 0 {
let mut c:i32 = *next_code.as_mut_ptr().offset((s) as isize) - ((*(*z).firstcode.as_mut_ptr().offset((s) as isize)) as i32) + ((*(*z).firstsymbol.as_mut_ptr().offset((s) as isize)) as i32);let mut fastv:u16 = ((s << 9 | i) as u16);*(*z).size.as_mut_ptr().offset((c) as isize) = (((s) as u8) as u8);*(*z).value.as_mut_ptr().offset((c) as isize) = (((i) as u16) as u16);if s <= 9 {
let mut j:i32 = stbi__bit_reverse(((*next_code.as_mut_ptr().offset((s) as isize)) as i32), ((s) as i32));while (j < 1 << 9) {
*(*z).fast.as_mut_ptr().offset((j) as isize) = ((fastv) as u16);j += ((1 << s) as i32);}}*next_code.as_mut_ptr().offset((s) as isize) += 1;}}

	return 1;
}

unsafe fn stbi__zget8(z:*mut stbi__zbuf) -> u8 {
	if (*z).zbuffer >= (*z).zbuffer_end {return ((0) as u8);}
	return *((*z).zbuffer = (*z).zbuffer.offset(1));
}

unsafe fn stbi__fill_bits(z:*mut stbi__zbuf){
	while(true) {
(*z).code_buffer |= ((((stbi__zget8(z)) as u32) << (*z).num_bits) as u32);(*z).num_bits += ((8) as i32);if !((*z).num_bits <= 24) {break;}}

}

unsafe fn stbi__zreceive(z:*mut stbi__zbuf, n:i32) -> u32 {
	let mut k:u32 = std::mem::uninitialized();
	if (*z).num_bits < n {stbi__fill_bits(z);}
	k = (((*z).code_buffer & ((1 << n - 1) as u32)) as u32);
	(*z).code_buffer >>= n;
	(*z).num_bits -= ((n) as i32);
	return k;
}

unsafe fn stbi__zhuffman_decode_slowpath(a:*mut stbi__zbuf, z:*mut stbi__zhuffman) -> i32 {
	let mut b:i32 = std::mem::uninitialized();let mut s:i32 = std::mem::uninitialized();let mut k:i32 = std::mem::uninitialized();
	k = ((stbi__bit_reverse(((((*a).code_buffer) as i32) as i32), ((16) as i32))) as i32);
	s = ((9 + 1) as i32);
while () {
s += 1;
if k < *(*z).maxcode.as_mut_ptr().offset((s) as isize) {}}
	if s == 16 {return -1;}
	b = ((k >> 16 - s - ((*(*z).firstcode.as_mut_ptr().offset((s) as isize)) as i32) + ((*(*z).firstsymbol.as_mut_ptr().offset((s) as isize)) as i32)) as i32);
	(*a).code_buffer >>= s;
	(*a).num_bits -= ((s) as i32);
	return ((*(*z).value.as_mut_ptr().offset((b) as isize)) as i32);
}

unsafe fn stbi__zhuffman_decode(a:*mut stbi__zbuf, z:*mut stbi__zhuffman) -> i32 {
	let mut b:i32 = std::mem::uninitialized();let mut s:i32 = std::mem::uninitialized();
	if (*a).num_bits < 16 {stbi__fill_bits(a);}
	b = (((*(*z).fast.as_mut_ptr().offset(((*a).code_buffer & ((1 << 9 - 1) as u32)) as isize)) as i32) as i32);
	if (b) != 0 {
s = ((b >> 9) as i32);(*a).code_buffer >>= s;(*a).num_bits -= ((s) as i32);return b & 511;}
	return stbi__zhuffman_decode_slowpath(a, z);
}

unsafe fn stbi__zexpand(z:*mut stbi__zbuf, zout:*mut i8, n:i32) -> i32 {
	let q:*mut i8;
	let mut cur:i32 = std::mem::uninitialized();let mut limit:i32 = std::mem::uninitialized();let mut old_limit:i32 = std::mem::uninitialized();
	(*z).zout = zout;
	if (*z).z_expandable == 0 {return stbi__err("output buffer limit");}
	cur = ((((*z).zout - (*z).zout_start) as i32) as i32);
	limit = ((old_limit = ((((*z).zout_end - (*z).zout_start) as i32) as i32)) as i32);
	while (cur + n > limit) {limit *= ((2) as i32);}
	q = ((c_runtime::realloc((*z).zout_start, (((limit) as u64) as u64))) as *mut i8);
	if q == (std::ptr::null_mut()) {return stbi__err("outofmem");}
	(*z).zout_start = q;
	(*z).zout = (q).offset((cur) as isize);
	(*z).zout_end = (q).offset((limit) as isize);
	return 1;
}

unsafe fn stbi__parse_huffman_block(a:*mut stbi__zbuf) -> i32 {
	let zout:*mut i8 = (*a).zout;
	;
while () {;

let mut z:i32 = stbi__zhuffman_decode(a, &mut (*a).z_length);if z < 256 {
if z < 0 {return stbi__err("bad huffman code");}if zout >= (*a).zout_end {
if stbi__zexpand(a, zout, ((1) as i32)) == 0 {return 0;}zout = (*a).zout;}*(zout = zout.offset(1)) = (((z) as i8) as i8);} else {
let p:*mut u8;let mut len:i32 = std::mem::uninitialized();let mut dist:i32 = std::mem::uninitialized();if z == 256 {
(*a).zout = zout;return 1;}z -= ((257) as i32);len = ((*stbi__zlength_base.as_mut_ptr().offset((z) as isize)) as i32);if (*stbi__zlength_extra.as_mut_ptr().offset((z) as isize)) != 0 {len += ((stbi__zreceive(a, ((*stbi__zlength_extra.as_mut_ptr().offset((z) as isize)) as i32))) as i32);}z = ((stbi__zhuffman_decode(a, &mut (*a).z_distance)) as i32);if z < 0 {return stbi__err("bad huffman code");}dist = ((*stbi__zdist_base.as_mut_ptr().offset((z) as isize)) as i32);if (*stbi__zdist_extra.as_mut_ptr().offset((z) as isize)) != 0 {dist += ((stbi__zreceive(a, ((*stbi__zdist_extra.as_mut_ptr().offset((z) as isize)) as i32))) as i32);}if zout - (*a).zout_start < ((dist) as i64) {return stbi__err("bad dist");}if (zout).offset((len) as isize) > (*a).zout_end {
if stbi__zexpand(a, zout, ((len) as i32)) == 0 {return 0;}zout = (*a).zout;}p = ((zout - dist) as *mut u8);if dist == 1 {
let mut v:u8 = *p;if (len) != 0 {
while(true) {*(zout = zout.offset(1)) = (((v) as i8) as i8);if !((len -= 1) != 0) {break;}}}} else {
if (len) != 0 {
while(true) {*(zout = zout.offset(1)) = (((*(p = p.offset(1))) as i8) as i8);if !((len -= 1) != 0) {break;}}}}}}

}

unsafe fn stbi__compute_huffman_codes(a:*mut stbi__zbuf) -> i32 {
	let mut z_codelength:stbi__zhuffman = std::mem::uninitialized();
	let mut lencodes:[u8;455] = unsafe {std::mem::uninitialized()};
	let mut codelength_sizes:[u8;19] = unsafe {std::mem::uninitialized()};
	let mut i:i32 = std::mem::uninitialized();let mut n:i32 = std::mem::uninitialized();
	let mut hlit:i32 = ((stbi__zreceive(a, ((5) as i32)) + ((257) as u32)) as i32);
	let mut hdist:i32 = ((stbi__zreceive(a, ((5) as i32)) + ((1) as u32)) as i32);
	let mut hclen:i32 = ((stbi__zreceive(a, ((4) as i32)) + ((4) as u32)) as i32);
	let mut ntot:i32 = hlit + hdist;
	c_runtime::memset(codelength_sizes.as_mut_ptr(), ((0) as i32), ((std::mem::size_of(codelength_sizes)) as u64));
	i = ((0) as i32);
while (i < hclen) {i += 1;

let mut s:i32 = ((stbi__zreceive(a, ((3) as i32))) as i32);*codelength_sizes.as_mut_ptr().offset((*length_dezigzag.as_mut_ptr().offset((i) as isize)) as isize) = (((s) as u8) as u8);}

	if stbi__zbuild_huffman(&mut z_codelength, codelength_sizes.as_mut_ptr(), ((19) as i32)) == 0 {return 0;}
	n = ((0) as i32);
	while (n < ntot) {
let mut c:i32 = stbi__zhuffman_decode(a, &mut z_codelength);if c < 0 || c >= 19 {return stbi__err("bad codelengths");}if c < 16 {*lencodes.as_mut_ptr().offset((n += 1) as isize) = (((c) as u8) as u8);} else {
let mut fill:u8 = ((0) as u8);if c == 16 {
c = (((stbi__zreceive(a, ((2) as i32)) + ((3) as u32)) as i32) as i32);if n == 0 {return stbi__err("bad codelengths");}fill = ((*lencodes.as_mut_ptr().offset((n - 1) as isize)) as u8);} else {if c == 17 {c = (((stbi__zreceive(a, ((3) as i32)) + ((3) as u32)) as i32) as i32);} else {
c = (((stbi__zreceive(a, ((7) as i32)) + ((11) as u32)) as i32) as i32);}}if ntot - n < c {return stbi__err("bad codelengths");}c_runtime::memset((lencodes.as_mut_ptr()).offset((n) as isize), (((fill) as i32) as i32), (((c) as u64) as u64));n += ((c) as i32);}}
	if n != ntot {return stbi__err("bad codelengths");}
	if stbi__zbuild_huffman(&mut (*a).z_length, lencodes.as_mut_ptr(), ((hlit) as i32)) == 0 {return 0;}
	if stbi__zbuild_huffman(&mut (*a).z_distance, (lencodes.as_mut_ptr()).offset((hlit) as isize), ((hdist) as i32)) == 0 {return 0;}
	return 1;
}

unsafe fn stbi__parse_uncompressed_block(a:*mut stbi__zbuf) -> i32 {
	let mut header:[u8;4] = unsafe {std::mem::uninitialized()};
	let mut len:i32 = std::mem::uninitialized();let mut nlen:i32 = std::mem::uninitialized();let mut k:i32 = std::mem::uninitialized();
	if ((*a).num_bits & 7) != 0 {stbi__zreceive(a, (((*a).num_bits & 7) as i32));}
	k = ((0) as i32);
	while ((*a).num_bits > 0) {
*header.as_mut_ptr().offset((k += 1) as isize) = ((((*a).code_buffer & ((255) as u32)) as u8) as u8);(*a).code_buffer >>= 8;(*a).num_bits -= ((8) as i32);}
	while (k < 4) {*header.as_mut_ptr().offset((k += 1) as isize) = ((stbi__zget8(a)) as u8);}
	len = ((((*header.as_mut_ptr().offset((1) as isize)) as i32) * 256 + ((*header.as_mut_ptr().offset((0) as isize)) as i32)) as i32);
	nlen = ((((*header.as_mut_ptr().offset((3) as isize)) as i32) * 256 + ((*header.as_mut_ptr().offset((2) as isize)) as i32)) as i32);
	if nlen != len ^ 0xffff {return stbi__err("zlib corrupt");}
	if ((*a).zbuffer).offset((len) as isize) > (*a).zbuffer_end {return stbi__err("read past buffer");}
	if ((*a).zout).offset((len) as isize) > (*a).zout_end {if stbi__zexpand(a, (*a).zout, ((len) as i32)) == 0 {return 0;}}
	c_runtime::memcpy((*a).zout, (*a).zbuffer, (((len) as u64) as u64));
	(*a).zbuffer += len;
	(*a).zout += len;
	return 1;
}

unsafe fn stbi__parse_zlib_header(a:*mut stbi__zbuf) -> i32 {
	let mut cmf:i32 = ((stbi__zget8(a)) as i32);
	let mut cm:i32 = cmf & 15;
	let mut flg:i32 = ((stbi__zget8(a)) as i32);
	if cmf * 256 + flg % 31 != 0 {return stbi__err("bad zlib header");}
	if (flg & 32) != 0 {return stbi__err("no preset dict");}
	if cm != 8 {return stbi__err("bad compression");}
	return 1;
}

unsafe fn stbi__parse_zlib(a:*mut stbi__zbuf, parse_header:i32) -> i32 {
	let mut _final_:i32 = std::mem::uninitialized();let mut _type_:i32 = std::mem::uninitialized();
	if (parse_header) != 0 {if stbi__parse_zlib_header(a) == 0 {return 0;}}
	(*a).num_bits = ((0) as i32);
	(*a).code_buffer = (((0) as u32) as u32);
	while(true) {
_final_ = (((stbi__zreceive(a, ((1) as i32))) as i32) as i32);_type_ = (((stbi__zreceive(a, ((2) as i32))) as i32) as i32);if _type_ == 0 {
if stbi__parse_uncompressed_block(a) == 0 {return 0;}} else {if _type_ == 3 {
return 0;} else {
if _type_ == 1 {
if stbi__zbuild_huffman(&mut (*a).z_length, stbi__zdefault_length.as_mut_ptr(), ((288) as i32)) == 0 {return 0;}if stbi__zbuild_huffman(&mut (*a).z_distance, stbi__zdefault_distance.as_mut_ptr(), ((32) as i32)) == 0 {return 0;}} else {
if stbi__compute_huffman_codes(a) == 0 {return 0;}}if stbi__parse_huffman_block(a) == 0 {return 0;}}}if !(_final_ == 0) {break;}}

	return 1;
}

unsafe fn stbi__do_zlib(a:*mut stbi__zbuf, obuf:*mut i8, olen:i32, exp:i32, parse_header:i32) -> i32 {
	(*a).zout_start = obuf;
	(*a).zout = obuf;
	(*a).zout_end = (obuf).offset((olen) as isize);
	(*a).z_expandable = ((exp) as i32);
	return stbi__parse_zlib(a, ((parse_header) as i32));
}

unsafe fn stbi_zlib_decode_malloc_guesssize(buffer:*mut i8, len:i32, initial_size:i32, outlen:*mut i32) -> *mut i8 {
	let mut a:stbi__zbuf = std::mem::uninitialized();
	let p:*mut i8 = ((stbi__malloc((((initial_size) as u64) as u64))) as *mut i8);
	if p == (std::ptr::null_mut()) {return (std::ptr::null_mut());}
	a.zbuffer = ((buffer) as *mut u8);
	a.zbuffer_end = (((buffer) as *mut u8)).offset((len) as isize);
	if (stbi__do_zlib(&mut a, p, ((initial_size) as i32), ((1) as i32), ((1) as i32))) != 0 {
if (outlen) != std::ptr::null_mut() {*outlen = (((a.zout - a.zout_start) as i32) as i32);}return a.zout_start;} else {
c_runtime::free(a.zout_start);return (std::ptr::null_mut());}
}

unsafe fn stbi_zlib_decode_malloc(buffer:*mut i8, len:i32, outlen:*mut i32) -> *mut i8 {
	return stbi_zlib_decode_malloc_guesssize(buffer, ((len) as i32), ((16384) as i32), outlen);
}

unsafe fn stbi_zlib_decode_malloc_guesssize_headerflag(buffer:*mut i8, len:i32, initial_size:i32, outlen:*mut i32, parse_header:i32) -> *mut i8 {
	let mut a:stbi__zbuf = std::mem::uninitialized();
	let p:*mut i8 = ((stbi__malloc((((initial_size) as u64) as u64))) as *mut i8);
	if p == (std::ptr::null_mut()) {return (std::ptr::null_mut());}
	a.zbuffer = ((buffer) as *mut u8);
	a.zbuffer_end = (((buffer) as *mut u8)).offset((len) as isize);
	if (stbi__do_zlib(&mut a, p, ((initial_size) as i32), ((1) as i32), ((parse_header) as i32))) != 0 {
if (outlen) != std::ptr::null_mut() {*outlen = (((a.zout - a.zout_start) as i32) as i32);}return a.zout_start;} else {
c_runtime::free(a.zout_start);return (std::ptr::null_mut());}
}

unsafe fn stbi_zlib_decode_buffer(obuffer:*mut i8, olen:i32, ibuffer:*mut i8, ilen:i32) -> i32 {
	let mut a:stbi__zbuf = std::mem::uninitialized();
	a.zbuffer = ((ibuffer) as *mut u8);
	a.zbuffer_end = (((ibuffer) as *mut u8)).offset((ilen) as isize);
	if (stbi__do_zlib(&mut a, obuffer, ((olen) as i32), ((0) as i32), ((1) as i32))) != 0 {return ((a.zout - a.zout_start) as i32);} else {return -1;}
}

unsafe fn stbi_zlib_decode_noheader_malloc(buffer:*mut i8, len:i32, outlen:*mut i32) -> *mut i8 {
	let mut a:stbi__zbuf = std::mem::uninitialized();
	let p:*mut i8 = ((stbi__malloc((((16384) as u64) as u64))) as *mut i8);
	if p == (std::ptr::null_mut()) {return (std::ptr::null_mut());}
	a.zbuffer = ((buffer) as *mut u8);
	a.zbuffer_end = (((buffer) as *mut u8)).offset((len) as isize);
	if (stbi__do_zlib(&mut a, p, ((16384) as i32), ((1) as i32), ((0) as i32))) != 0 {
if (outlen) != std::ptr::null_mut() {*outlen = (((a.zout - a.zout_start) as i32) as i32);}return a.zout_start;} else {
c_runtime::free(a.zout_start);return (std::ptr::null_mut());}
}

unsafe fn stbi_zlib_decode_noheader_buffer(obuffer:*mut i8, olen:i32, ibuffer:*mut i8, ilen:i32) -> i32 {
	let mut a:stbi__zbuf = std::mem::uninitialized();
	a.zbuffer = ((ibuffer) as *mut u8);
	a.zbuffer_end = (((ibuffer) as *mut u8)).offset((ilen) as isize);
	if (stbi__do_zlib(&mut a, obuffer, ((olen) as i32), ((0) as i32), ((0) as i32))) != 0 {return ((a.zout - a.zout_start) as i32);} else {return -1;}
}

unsafe fn stbi__get_chunk_header(s:*mut stbi__context) -> stbi__pngchunk {
	let mut c:stbi__pngchunk = std::mem::uninitialized();
	c.length = ((stbi__get32be(s)) as u32);
	c._type_ = ((stbi__get32be(s)) as u32);
	return c;
}

unsafe fn stbi__check_png_header(s:*mut stbi__context) -> i32 {
	let mut i:i32 = std::mem::uninitialized();
	i = ((0) as i32);
while (i < 8) {
i += 1;
if ((stbi__get8(s)) as i32) != ((*png_sig.as_mut_ptr().offset((i) as isize)) as i32) {return stbi__err("bad png sig");}}
	return 1;
}

unsafe fn stbi__paeth(a:i32, b:i32, c:i32) -> i32 {
	let mut p:i32 = a + b - c;
	let mut pa:i32 = c_runtime::abs(((p - a) as i32));
	let mut pb:i32 = c_runtime::abs(((p - b) as i32));
	let mut pc:i32 = c_runtime::abs(((p - c) as i32));
	if pa <= pb && pa <= pc {return a;}
	if pb <= pc {return b;}
	return c;
}

unsafe fn stbi__create_png_image_raw(a:*mut stbi__png, raw:*mut u8, raw_len:u32, out_n:i32, x:u32, y:u32, depth:i32, color:i32) -> i32 {
    let mut bytes: i32 = if depth == 16 { 2 } else { 1 };
    let s: *mut stbi__context = (*a).s;
    let mut i: u32 = std::mem::uninitialized();
    let mut j: u32 = std::mem::uninitialized();
    let mut stride: u32 = x * ((out_n) as u32) * ((bytes) as u32);
    let mut img_len: u32 = std::mem::uninitialized();
    let mut img_width_bytes: u32 = std::mem::uninitialized();
    let mut k: i32 = std::mem::uninitialized();
    let mut img_n: i32 = s.img_n;
    let mut output_bytes: i32 = out_n * bytes;
    let mut filter_bytes: i32 = img_n * bytes;
    let mut width: i32 = ((x) as i32);
    (*a)._out_ = stbi__malloc_mad3((((x) as i32) as i32), (((y) as i32) as i32), ((output_bytes) as i32), ((0) as i32));
    if (*a)._out_ == std::ptr::null_mut() { return stbi__err("outofmem"); }
    img_width_bytes = ((((img_n) as u32) * x * ((depth) as u32) + ((7) as u32) >> 3) as u32);
    img_len = ((img_width_bytes + ((1) as u32) * y) as u32);
    if raw_len < img_len { return stbi__err("not enough pixels"); }
    j = (((0) as u32) as u32);
    while (j < y) {
        j += 1;

        let cur: *mut u8 = ((*a)._out_).offset((stride * j) as isize);
        let prior: *mut u8;
        let mut filter: i32 = ((*(raw = raw.offset(1))) as i32);
        if filter > 4 { return stbi__err("invalid filter"); }
        if depth < 8 {
            cur += x * ((out_n) as u32) - img_width_bytes;
            filter_bytes = ((1) as i32);
            width = (((img_width_bytes) as i32) as i32);
        }
        prior = cur - stride;
        if j == ((0) as u32) { filter = ((*first_row_filter.as_mut_ptr().offset((filter) as isize)) as i32); }
        k = ((0) as i32);
        while (k < filter_bytes) {
            k += 1;

            {
                if filter == STBI__F_none { *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8); } else if filter == STBI__F_sub { *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8); } else if filter == STBI__F_up { *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + ((*prior.offset((k) as isize)) as i32) & 255) as u8) as u8); } else if filter == STBI__F_avg { *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + ((*prior.offset((k) as isize)) as i32) >> 1 & 255) as u8) as u8); } else if filter == STBI__F_paeth { *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + stbi__paeth(((0) as i32), (((*prior.offset((k) as isize)) as i32) as i32), ((0) as i32)) & 255) as u8) as u8); } else if filter == STBI__F_avg_first { *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8); } else if filter == STBI__F_paeth_first { *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8); }
            }
        }
        if depth == 8 {
            if img_n != out_n { *cur.offset((img_n) as isize) = (((255) as u8) as u8); }
            raw += img_n;
            cur += out_n;
            prior += out_n;
        } else {
            if depth == 16 {
                if img_n != out_n {
                    *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                    *cur.offset((filter_bytes + 1) as isize) = (((255) as u8) as u8);
                }
                raw += filter_bytes;
                cur += output_bytes;
                prior += output_bytes;
            } else {
                raw += 1;
                cur += 1;
                prior += 1;
            }
        }
        if depth < 8 || img_n == out_n {
            let mut nk: i32 = width - 1 * filter_bytes;
            {
                if filter == STBI__F_none { c_runtime::memcpy(cur, raw, (((nk) as u64) as u64)); } else if filter == STBI__F_sub {
                    k = ((0) as i32);
                    while (k < nk) {
                        k += 1;

                        *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + ((*cur.offset((k - filter_bytes) as isize)) as i32) & 255) as u8) as u8);
                    }
                } else if filter == STBI__F_up {
                    k = ((0) as i32);
                    while (k < nk) {
                        k += 1;

                        *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + ((*prior.offset((k) as isize)) as i32) & 255) as u8) as u8);
                    }
                } else if filter == STBI__F_avg {
                    k = ((0) as i32);
                    while (k < nk) {
                        k += 1;

                        *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + ((*prior.offset((k) as isize)) as i32) + ((*cur.offset((k - filter_bytes) as isize)) as i32) >> 1 & 255) as u8) as u8);
                    }
                } else if filter == STBI__F_paeth {
                    k = ((0) as i32);
                    while (k < nk) {
                        k += 1;

                        *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + stbi__paeth((((*cur.offset((k - filter_bytes) as isize)) as i32) as i32), (((*prior.offset((k) as isize)) as i32) as i32), (((*prior.offset((k - filter_bytes) as isize)) as i32) as i32)) & 255) as u8) as u8);
                    }
                } else if filter == STBI__F_avg_first {
                    k = ((0) as i32);
                    while (k < nk) {
                        k += 1;

                        *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + ((*cur.offset((k - filter_bytes) as isize)) as i32) >> 1 & 255) as u8) as u8);
                    }
                } else if filter == STBI__F_paeth_first {
                    k = ((0) as i32);
                    while (k < nk) {
                        k += 1;

                        *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + stbi__paeth((((*cur.offset((k - filter_bytes) as isize)) as i32) as i32), ((0) as i32), ((0) as i32)) & 255) as u8) as u8);
                    }
                }
            }
            raw += nk;
        } else {
            {
                if filter == STBI__F_none {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw += filter_bytes;
                        cur += output_bytes;
                        prior += output_bytes;
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            k += 1;

                            *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8);
                        }
                    }
                } else if filter == STBI__F_sub {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw += filter_bytes;
                        cur += output_bytes;
                        prior += output_bytes;
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            k += 1;

                            *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + ((*cur.offset((k - output_bytes) as isize)) as i32) & 255) as u8) as u8);
                        }
                    }
                } else if filter == STBI__F_up {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw += filter_bytes;
                        cur += output_bytes;
                        prior += output_bytes;
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            k += 1;

                            *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + ((*prior.offset((k) as isize)) as i32) & 255) as u8) as u8);
                        }
                    }
                } else if filter == STBI__F_avg {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw += filter_bytes;
                        cur += output_bytes;
                        prior += output_bytes;
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            k += 1;

                            *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + ((*prior.offset((k) as isize)) as i32) + ((*cur.offset((k - output_bytes) as isize)) as i32) >> 1 & 255) as u8) as u8);
                        }
                    }
                } else if filter == STBI__F_paeth {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw += filter_bytes;
                        cur += output_bytes;
                        prior += output_bytes;
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            k += 1;

                            *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + stbi__paeth((((*cur.offset((k - output_bytes) as isize)) as i32) as i32), (((*prior.offset((k) as isize)) as i32) as i32), (((*prior.offset((k - output_bytes) as isize)) as i32) as i32)) & 255) as u8) as u8);
                        }
                    }
                } else if filter == STBI__F_avg_first {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw += filter_bytes;
                        cur += output_bytes;
                        prior += output_bytes;
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            k += 1;

                            *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + ((*cur.offset((k - output_bytes) as isize)) as i32) >> 1 & 255) as u8) as u8);
                        }
                    }
                } else if filter == STBI__F_paeth_first {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw += filter_bytes;
                        cur += output_bytes;
                        prior += output_bytes;
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            k += 1;

                            *cur.offset((k) as isize) = (((((*raw.offset((k) as isize)) as i32) + stbi__paeth((((*cur.offset((k - output_bytes) as isize)) as i32) as i32), ((0) as i32), ((0) as i32)) & 255) as u8) as u8);
                        }
                    }
                }
            }
            if depth == 16 {
                cur = ((*a)._out_).offset((stride * j) as isize);
                i = (((0) as u32) as u32);
                while (i < x) {
                    i += 1;
                    cur += output_bytes;

                    *cur.offset((filter_bytes + 1) as isize) = (((255) as u8) as u8);
                }
            }
        }
    }

    if depth < 8 {
        j = (((0) as u32) as u32);
        while (j < y) {
            j += 1;

            let cur: *mut u8 = ((*a)._out_).offset((stride * j) as isize);
            let _in_: *mut u8 = (((*a)._out_).offset((stride * j) as isize)).offset((x * ((out_n) as u32)) as isize) - img_width_bytes;
            let mut scale: u8 = ((if color == 0 { ((*stbi__depth_scale_table.as_mut_ptr().offset((depth) as isize)) as i32) } else { 1 }) as u8);
            if depth == 4 {
                k = (((x * ((img_n) as u32)) as i32) as i32);
                while (k >= 2) {
                    k -= ((2) as i32);
                    (_in_ = _in_.offset(1));

                    *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 4) as u8) as u8);
                    *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) & 0x0f) as u8) as u8);
                }
                if k > 0 { *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 4) as u8) as u8); }
            } else {
                if depth == 2 {
                    k = (((x * ((img_n) as u32)) as i32) as i32);
                    while (k >= 4) {
                        k -= ((4) as i32);
                        (_in_ = _in_.offset(1));

                        *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 6) as u8) as u8);
                        *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 4 & 0x03) as u8) as u8);
                        *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 2 & 0x03) as u8) as u8);
                        *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) & 0x03) as u8) as u8);
                    }
                    if k > 0 { *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 6) as u8) as u8); }
                    if k > 1 { *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 4 & 0x03) as u8) as u8); }
                    if k > 2 { *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 2 & 0x03) as u8) as u8); }
                } else {
                    if depth == 1 {
                        k = (((x * ((img_n) as u32)) as i32) as i32);
                        while (k >= 8) {
                            k -= ((8) as i32);
                            (_in_ = _in_.offset(1));

                            *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 7) as u8) as u8);
                            *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 6 & 0x01) as u8) as u8);
                            *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 5 & 0x01) as u8) as u8);
                            *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 4 & 0x01) as u8) as u8);
                            *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 3 & 0x01) as u8) as u8);
                            *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 2 & 0x01) as u8) as u8);
                            *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 1 & 0x01) as u8) as u8);
                            *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) & 0x01) as u8) as u8);
                        }
                        if k > 0 { *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 7) as u8) as u8); }
                        if k > 1 { *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 6 & 0x01) as u8) as u8); }
                        if k > 2 { *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 5 & 0x01) as u8) as u8); }
                        if k > 3 { *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 4 & 0x01) as u8) as u8); }
                        if k > 4 { *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 3 & 0x01) as u8) as u8); }
                        if k > 5 { *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 2 & 0x01) as u8) as u8); }
                        if k > 6 { *(cur = cur.offset(1)) = (((((scale) as i32) * ((*_in_) as i32) >> 1 & 0x01) as u8) as u8); }
                    }
                }
            }
            if img_n != out_n {
                let mut q: i32 = std::mem::uninitialized();
                cur = ((*a)._out_).offset((stride * j) as isize);
                if img_n == 1 {
                    q = (((x - ((1) as u32)) as i32) as i32);
                    while (q >= 0) {
                        q -= 1;

                        *cur.offset((q * 2 + 1) as isize) = (((255) as u8) as u8);
                        *cur.offset((q * 2 + 0) as isize) = ((*cur.offset((q) as isize)) as u8);
                    }
                } else {
                    q = (((x - ((1) as u32)) as i32) as i32);
                    while (q >= 0) {
                        q -= 1;

                        *cur.offset((q * 4 + 3) as isize) = (((255) as u8) as u8);
                        *cur.offset((q * 4 + 2) as isize) = ((*cur.offset((q * 3 + 2) as isize)) as u8);
                        *cur.offset((q * 4 + 1) as isize) = ((*cur.offset((q * 3 + 1) as isize)) as u8);
                        *cur.offset((q * 4 + 0) as isize) = ((*cur.offset((q * 3 + 0) as isize)) as u8);
                    }
                }
            }
        }
    } else {
        if depth == 16 {
            let cur: *mut u8 = (*a)._out_;
            let cur16: *mut u16 = ((cur) as *mut u16);
            i = (((0) as u32) as u32);
            while (i < x * y * ((out_n) as u32)) {
                i += 1;
                (cur16 = cur16.offset(1));
                cur += 2;

                *cur16 = (((((*cur.offset((0) as isize)) as i32) << 8 | ((*cur.offset((1) as isize)) as i32)) as u16) as u16);
            }
        }
    }
    return 1;
}

unsafe fn stbi__create_png_image(a:*mut stbi__png, image_data:*mut u8, image_data_len:u32, out_n:i32, depth:i32, color:i32, interlaced:i32) -> i32 {
	let mut bytes:i32 = if depth == 16{2} else {1};
	let mut out_bytes:i32 = out_n * bytes;
	let _final_:*mut u8;
	let mut p:i32 = std::mem::uninitialized();
	if interlaced == 0 {return stbi__create_png_image_raw(a, image_data, ((image_data_len) as u32), ((out_n) as i32), (((*a).s.img_x) as u32), (((*a).s.img_y) as u32), ((depth) as i32), ((color) as i32));}
	_final_ = stbi__malloc_mad3(((((*a).s.img_x) as i32) as i32), ((((*a).s.img_y) as i32) as i32), ((out_bytes) as i32), ((0) as i32));
	p = ((0) as i32);
while (p < 7) {p += 1;

let mut xorig:[i32;7] = unsafe {std::mem::uninitialized()};let mut yorig:[i32;7] = unsafe {std::mem::uninitialized()};let mut xspc:[i32;7] = unsafe {std::mem::uninitialized()};let mut yspc:[i32;7] = unsafe {std::mem::uninitialized()};let mut i:i32 = std::mem::uninitialized();let mut j:i32 = std::mem::uninitialized();let mut x:i32 = std::mem::uninitialized();let mut y:i32 = std::mem::uninitialized();x = ((((*a).s.img_x - ((*xorig.as_mut_ptr().offset((p) as isize)) as u32) + ((*xspc.as_mut_ptr().offset((p) as isize)) as u32) - ((1) as u32) / ((*xspc.as_mut_ptr().offset((p) as isize)) as u32)) as i32) as i32);y = ((((*a).s.img_y - ((*yorig.as_mut_ptr().offset((p) as isize)) as u32) + ((*yspc.as_mut_ptr().offset((p) as isize)) as u32) - ((1) as u32) / ((*yspc.as_mut_ptr().offset((p) as isize)) as u32)) as i32) as i32);if (x) != 0 && (y) != 0 {
let mut img_len:u32 = (((*a).s.img_n * x * depth + 7 >> 3 + 1 * y) as u32);if stbi__create_png_image_raw(a, image_data, ((image_data_len) as u32), ((out_n) as i32), (((x) as u32) as u32), (((y) as u32) as u32), ((depth) as i32), ((color) as i32)) == 0 {
c_runtime::free(_final_);return 0;}j = ((0) as i32);
while (j < y) {j += 1;

i = ((0) as i32);
while (i < x) {i += 1;

let mut out_y:i32 = j * *yspc.as_mut_ptr().offset((p) as isize) + *yorig.as_mut_ptr().offset((p) as isize);let mut out_x:i32 = i * *xspc.as_mut_ptr().offset((p) as isize) + *xorig.as_mut_ptr().offset((p) as isize);c_runtime::memcpy(((_final_).offset((((out_y) as u32) * (*a).s.img_x * ((out_bytes) as u32)) as isize)).offset((out_x * out_bytes) as isize), ((*a)._out_).offset((j * x + i * out_bytes) as isize), (((out_bytes) as u64) as u64));}
}
c_runtime::free((*a)._out_);image_data += img_len;image_data_len -= ((img_len) as u32);}}

	(*a)._out_ = _final_;
	return 1;
}

unsafe fn stbi__compute_transparency(z:*mut stbi__png, tc:[u8;3], out_n:i32) -> i32 {
	let s:*mut stbi__context = (*z).s;
	let mut i:u32 = std::mem::uninitialized();let mut pixel_count:u32 = s.img_x * s.img_y;
	let p:*mut u8 = (*z)._out_;
	if out_n == 2 {
i = (((0) as u32) as u32);
while (i < pixel_count) {i += 1;

*p.offset((1) as isize) = (((if ((*p.offset((0) as isize)) as i32) == ((*tc.as_mut_ptr().offset((0) as isize)) as i32){0} else {255}) as u8) as u8);p += 2;}
} else {
i = (((0) as u32) as u32);
while (i < pixel_count) {i += 1;

if ((*p.offset((0) as isize)) as i32) == ((*tc.as_mut_ptr().offset((0) as isize)) as i32) && ((*p.offset((1) as isize)) as i32) == ((*tc.as_mut_ptr().offset((1) as isize)) as i32) && ((*p.offset((2) as isize)) as i32) == ((*tc.as_mut_ptr().offset((2) as isize)) as i32) {*p.offset((3) as isize) = (((0) as u8) as u8);}p += 4;}
}
	return 1;
}

unsafe fn stbi__compute_transparency16(z:*mut stbi__png, tc:[u16;3], out_n:i32) -> i32 {
	let s:*mut stbi__context = (*z).s;
	let mut i:u32 = std::mem::uninitialized();let mut pixel_count:u32 = s.img_x * s.img_y;
	let p:*mut u16 = (((*z)._out_) as *mut u16);
	if out_n == 2 {
i = (((0) as u32) as u32);
while (i < pixel_count) {i += 1;

*p.offset((1) as isize) = (((if ((*p.offset((0) as isize)) as i32) == ((*tc.as_mut_ptr().offset((0) as isize)) as i32){0} else {65535}) as u16) as u16);p += 2;}
} else {
i = (((0) as u32) as u32);
while (i < pixel_count) {i += 1;

if ((*p.offset((0) as isize)) as i32) == ((*tc.as_mut_ptr().offset((0) as isize)) as i32) && ((*p.offset((1) as isize)) as i32) == ((*tc.as_mut_ptr().offset((1) as isize)) as i32) && ((*p.offset((2) as isize)) as i32) == ((*tc.as_mut_ptr().offset((2) as isize)) as i32) {*p.offset((3) as isize) = (((0) as u16) as u16);}p += 4;}
}
	return 1;
}

unsafe fn stbi__expand_png_palette(a:*mut stbi__png, palette:*mut u8, len:i32, pal_img_n:i32) -> i32 {
	let mut i:u32 = std::mem::uninitialized();let mut pixel_count:u32 = (*a).s.img_x * (*a).s.img_y;
	let p:*mut u8;let temp_out:*mut u8;let orig:*mut u8 = (*a)._out_;
	p = stbi__malloc_mad2((((pixel_count) as i32) as i32), ((pal_img_n) as i32), ((0) as i32));
	if p == (std::ptr::null_mut()) {return stbi__err("outofmem");}
	temp_out = p;
	if pal_img_n == 3 {
i = (((0) as u32) as u32);
while (i < pixel_count) {i += 1;

let mut n:i32 = ((*orig.offset((i) as isize)) as i32) * 4;*p.offset((0) as isize) = ((*palette.offset((n) as isize)) as u8);*p.offset((1) as isize) = ((*palette.offset((n + 1) as isize)) as u8);*p.offset((2) as isize) = ((*palette.offset((n + 2) as isize)) as u8);p += 3;}
} else {
i = (((0) as u32) as u32);
while (i < pixel_count) {i += 1;

let mut n:i32 = ((*orig.offset((i) as isize)) as i32) * 4;*p.offset((0) as isize) = ((*palette.offset((n) as isize)) as u8);*p.offset((1) as isize) = ((*palette.offset((n + 1) as isize)) as u8);*p.offset((2) as isize) = ((*palette.offset((n + 2) as isize)) as u8);*p.offset((3) as isize) = ((*palette.offset((n + 3) as isize)) as u8);p += 4;}
}
	c_runtime::free((*a)._out_);
	(*a)._out_ = temp_out;
	return 1;
}

unsafe fn stbi_set_unpremultiply_on_load(flag_true_if_should_unpremultiply:i32){
	stbi__unpremultiply_on_load = ((flag_true_if_should_unpremultiply) as i32);
}

unsafe fn stbi_convert_iphone_png_to_rgb(flag_true_if_should_convert:i32){
	stbi__de_iphone_flag = ((flag_true_if_should_convert) as i32);
}

unsafe fn stbi__de_iphone(z:*mut stbi__png){
	let s:*mut stbi__context = (*z).s;
	let mut i:u32 = std::mem::uninitialized();let mut pixel_count:u32 = s.img_x * s.img_y;
	let p:*mut u8 = (*z)._out_;
	if s.img_out_n == 3 {
i = (((0) as u32) as u32);
while (i < pixel_count) {i += 1;

let mut t:u8 = *p.offset((0) as isize);*p.offset((0) as isize) = ((*p.offset((2) as isize)) as u8);*p.offset((2) as isize) = ((t) as u8);p += 3;}
} else {
if (stbi__unpremultiply_on_load) != 0 {
i = (((0) as u32) as u32);
while (i < pixel_count) {i += 1;

let mut a:u8 = *p.offset((3) as isize);let mut t:u8 = *p.offset((0) as isize);if (a) != 0 {
let mut half:u8 = ((((a) as i32) / 2) as u8);*p.offset((0) as isize) = (((((*p.offset((2) as isize)) as i32) * 255 + ((half) as i32) / ((a) as i32)) as u8) as u8);*p.offset((1) as isize) = (((((*p.offset((1) as isize)) as i32) * 255 + ((half) as i32) / ((a) as i32)) as u8) as u8);*p.offset((2) as isize) = (((((t) as i32) * 255 + ((half) as i32) / ((a) as i32)) as u8) as u8);} else {
*p.offset((0) as isize) = ((*p.offset((2) as isize)) as u8);*p.offset((2) as isize) = ((t) as u8);}p += 4;}
} else {
i = (((0) as u32) as u32);
while (i < pixel_count) {i += 1;

let mut t:u8 = *p.offset((0) as isize);*p.offset((0) as isize) = ((*p.offset((2) as isize)) as u8);*p.offset((2) as isize) = ((t) as u8);p += 4;}
}}
}

unsafe fn stbi__parse_png_file(z:*mut stbi__png, scan:i32, req_comp:i32) -> i32 {
	let mut palette:[u8;1024] = unsafe {std::mem::uninitialized()};let mut pal_img_n:u8 = ((0) as u8);
	let mut has_trans:u8 = ((0) as u8);let mut tc:[u8;3] = unsafe {std::mem::uninitialized()};
	let mut tc16:[u16;3] = unsafe {std::mem::uninitialized()};
	let mut ioff:u32 = ((0) as u32);let mut idata_limit:u32 = ((0) as u32);let mut i:u32 = std::mem::uninitialized();let mut pal_len:u32 = ((0) as u32);
	let mut first:i32 = 1;let mut k:i32 = std::mem::uninitialized();let mut interlace:i32 = 0;let mut color:i32 = 0;let mut is_iphone:i32 = 0;
	let s:*mut stbi__context = (*z).s;
	(*z).expanded = (std::ptr::null_mut());
	(*z).idata = (std::ptr::null_mut());
	(*z)._out_ = (std::ptr::null_mut());
	if stbi__check_png_header(s) == 0 {return 0;}
	if scan == STBI__SCAN_type {return 1;}
	;
while () {;

let mut c:stbi__pngchunk = stbi__get_chunk_header(s);{
if c._type_ == (('C' << 24 + 'g' << 16 + 'B' << 8 + 'I') as u32) {is_iphone = ((1) as i32);stbi__skip(s, (((c.length) as i32) as i32));} else if c._type_ == (('I' << 24 + 'H' << 16 + 'D' << 8 + 'R') as u32) {{
let mut comp:i32 = std::mem::uninitialized();let mut filter:i32 = std::mem::uninitialized();if first == 0 {return stbi__err("multiple IHDR");}first = ((0) as i32);if c.length != ((13) as u32) {return stbi__err("bad IHDR len");}s.img_x = ((stbi__get32be(s)) as u32);if s.img_x > ((1 << 24) as u32) {return stbi__err("too large");}s.img_y = ((stbi__get32be(s)) as u32);if s.img_y > ((1 << 24) as u32) {return stbi__err("too large");}(*z).depth = (((stbi__get8(s)) as i32) as i32);if (*z).depth != 1 && (*z).depth != 2 && (*z).depth != 4 && (*z).depth != 8 && (*z).depth != 16 {return stbi__err("1/2/4/8/16-bit only");}color = (((stbi__get8(s)) as i32) as i32);if color > 6 {return stbi__err("bad ctype");}if color == 3 && (*z).depth == 16 {return stbi__err("bad ctype");}if color == 3 {pal_img_n = (((3) as u8) as u8);} else {if (color & 1) != 0 {return stbi__err("bad ctype");}}comp = (((stbi__get8(s)) as i32) as i32);if (comp) != 0 {return stbi__err("bad comp method");}filter = (((stbi__get8(s)) as i32) as i32);if (filter) != 0 {return stbi__err("bad filter method");}interlace = (((stbi__get8(s)) as i32) as i32);if interlace > 1 {return stbi__err("bad interlace method");}if s.img_x == 0 || s.img_y == 0 {return stbi__err("0-pixel image");}if pal_img_n == 0 {
s.img_n = ((if (color & 2) != 0{3} else {1} + if (color & 4) != 0{1} else {0}) as i32);if ((1 << 30) as u32) / s.img_x / ((s.img_n) as u32) < s.img_y {return stbi__err("too large");}if scan == STBI__SCAN_header {return 1;}} else {
s.img_n = ((1) as i32);if ((1 << 30) as u32) / s.img_x / ((4) as u32) < s.img_y {return stbi__err("too large");}}}
} else if c._type_ == (('P' << 24 + 'L' << 16 + 'T' << 8 + 'E') as u32) {{
if (first) != 0 {return stbi__err("first not IHDR");}if c.length > ((256 * 3) as u32) {return stbi__err("invalid PLTE");}pal_len = ((c.length / ((3) as u32)) as u32);if pal_len * ((3) as u32) != c.length {return stbi__err("invalid PLTE");}i = (((0) as u32) as u32);
while (i < pal_len) {i += 1;

*palette.as_mut_ptr().offset((i * ((4) as u32) + ((0) as u32)) as isize) = ((stbi__get8(s)) as u8);*palette.as_mut_ptr().offset((i * ((4) as u32) + ((1) as u32)) as isize) = ((stbi__get8(s)) as u8);*palette.as_mut_ptr().offset((i * ((4) as u32) + ((2) as u32)) as isize) = ((stbi__get8(s)) as u8);*palette.as_mut_ptr().offset((i * ((4) as u32) + ((3) as u32)) as isize) = (((255) as u8) as u8);}
}
} else if c._type_ == (('t' << 24 + 'R' << 16 + 'N' << 8 + 'S') as u32) {{
if (first) != 0 {return stbi__err("first not IHDR");}if ((*z).idata) != std::ptr::null_mut() {return stbi__err("tRNS after IDAT");}if (pal_img_n) != 0 {
if scan == STBI__SCAN_header {
s.img_n = ((4) as i32);return 1;}if pal_len == ((0) as u32) {return stbi__err("tRNS before PLTE");}if c.length > pal_len {return stbi__err("bad tRNS len");}pal_img_n = (((4) as u8) as u8);i = (((0) as u32) as u32);
while (i < c.length) {
i += 1;
*palette.as_mut_ptr().offset((i * ((4) as u32) + ((3) as u32)) as isize) = ((stbi__get8(s)) as u8);}} else {
if s.img_n & 1 == 0 {return stbi__err("tRNS with alpha");}if c.length != ((s.img_n) as u32) * ((2) as u32) {return stbi__err("bad tRNS len");}has_trans = (((1) as u8) as u8);if (*z).depth == 16 {
k = ((0) as i32);
while (k < s.img_n) {
k += 1;
*tc16.as_mut_ptr().offset((k) as isize) = (((stbi__get16be(s)) as u16) as u16);}} else {
k = ((0) as i32);
while (k < s.img_n) {
k += 1;
*tc.as_mut_ptr().offset((k) as isize) = ((((((stbi__get16be(s) & 255) as u8) as i32) * ((*stbi__depth_scale_table.as_mut_ptr().offset(((*z).depth) as isize)) as i32)) as u8) as u8);}}}}
} else if c._type_ == (('I' << 24 + 'D' << 16 + 'A' << 8 + 'T') as u32) {{
if (first) != 0 {return stbi__err("first not IHDR");}if ((pal_img_n) as i32) != 0 && pal_len == 0 {return stbi__err("no PLTE");}if scan == STBI__SCAN_header {
s.img_n = (((pal_img_n) as i32) as i32);return 1;}if ((ioff + c.length) as i32) < ((ioff) as i32) {return 0;}if ioff + c.length > idata_limit {
let mut idata_limit_old:u32 = idata_limit;let p:*mut u8;if idata_limit == ((0) as u32) {idata_limit = ((if c.length > ((4096) as u32){c.length} else {((4096) as u32)}) as u32);}while (ioff + c.length > idata_limit) {idata_limit *= (((2) as u32) as u32);}p = c_runtime::realloc((*z).idata, (((idata_limit) as u64) as u64));if p == (std::ptr::null_mut()) {return stbi__err("outofmem");}(*z).idata = p;}if stbi__getn(s, ((*z).idata).offset((ioff) as isize), (((c.length) as i32) as i32)) == 0 {return stbi__err("outofdata");}ioff += ((c.length) as u32);}
} else if c._type_ == (('I' << 24 + 'E' << 16 + 'N' << 8 + 'D') as u32) {{
let mut raw_len:u32 = std::mem::uninitialized();let mut bpl:u32 = std::mem::uninitialized();if (first) != 0 {return stbi__err("first not IHDR");}if scan != STBI__SCAN_load {return 1;}if (*z).idata == (std::ptr::null_mut()) {return stbi__err("no IDAT");}bpl = ((s.img_x * (((*z).depth) as u32) + ((7) as u32) / ((8) as u32)) as u32);raw_len = ((bpl * s.img_y * ((s.img_n) as u32) + s.img_y) as u32);(*z).expanded = ((stbi_zlib_decode_malloc_guesssize_headerflag((((*z).idata) as *mut i8), (((ioff) as i32) as i32), (((raw_len) as i32) as i32), ((&mut raw_len) as *mut i32), ((!is_iphone) as i32))) as *mut u8);if (*z).expanded == (std::ptr::null_mut()) {return 0;}c_runtime::free((*z).idata);(*z).idata = (std::ptr::null_mut());if req_comp == s.img_n + 1 && req_comp != 3 && pal_img_n == 0 || ((has_trans) as i32) != 0 {s.img_out_n = ((s.img_n + 1) as i32);} else {s.img_out_n = ((s.img_n) as i32);}if stbi__create_png_image(z, (*z).expanded, ((raw_len) as u32), ((s.img_out_n) as i32), (((*z).depth) as i32), ((color) as i32), ((interlace) as i32)) == 0 {return 0;}if (has_trans) != 0 {
if (*z).depth == 16 {
if stbi__compute_transparency16(z, tc16.as_mut_ptr(), ((s.img_out_n) as i32)) == 0 {return 0;}} else {
if stbi__compute_transparency(z, tc.as_mut_ptr(), ((s.img_out_n) as i32)) == 0 {return 0;}}}if (is_iphone) != 0 && (stbi__de_iphone_flag) != 0 && s.img_out_n > 2 {stbi__de_iphone(z);}if (pal_img_n) != 0 {
s.img_n = (((pal_img_n) as i32) as i32);s.img_out_n = (((pal_img_n) as i32) as i32);if req_comp >= 3 {s.img_out_n = ((req_comp) as i32);}if stbi__expand_png_palette(z, palette.as_mut_ptr(), (((pal_len) as i32) as i32), ((s.img_out_n) as i32)) == 0 {return 0;}} else {if (has_trans) != 0 {
s.img_n += 1;}}c_runtime::free((*z).expanded);(*z).expanded = (std::ptr::null_mut());return 1;}
} else { if (first) != 0 {return stbi__err("first not IHDR");}if c._type_ & ((1 << 29) as u32) == ((0) as u32) {
let mut invalid_chunk:[i8;25] = unsafe {std::mem::uninitialized()};return stbi__err(invalid_chunk.as_mut_ptr());}stbi__skip(s, (((c.length) as i32) as i32));}
}stbi__get32be(s);}

}

unsafe fn stbi__do_png(p:*mut stbi__png, x:*mut i32, y:*mut i32, n:*mut i32, req_comp:i32, ri:*mut stbi__result_info) -> *mut u8 {
	let result:*mut u8 = (std::ptr::null_mut());
	if req_comp < 0 || req_comp > 4 {return if (stbi__err("bad req_comp")) != 0{(std::ptr::null_mut())} else {(std::ptr::null_mut())}}
	if (stbi__parse_png_file(p, ((STBI__SCAN_load) as i32), ((req_comp) as i32))) != 0 {
if (*p).depth < 8 {(*ri).bits_per_channel = ((8) as i32);} else {(*ri).bits_per_channel = (((*p).depth) as i32);}result = (*p)._out_;(*p)._out_ = (std::ptr::null_mut());if (req_comp) != 0 && req_comp != (*p).s.img_out_n {
if (*ri).bits_per_channel == 8 {result = stbi__convert_format(result, (((*p).s.img_out_n) as i32), ((req_comp) as i32), (((*p).s.img_x) as u32), (((*p).s.img_y) as u32));} else {result = stbi__convert_format16(((result) as *mut u16), (((*p).s.img_out_n) as i32), ((req_comp) as i32), (((*p).s.img_x) as u32), (((*p).s.img_y) as u32));}(*p).s.img_out_n = ((req_comp) as i32);if result == (std::ptr::null_mut()) {return result;}}*x = ((((*p).s.img_x) as i32) as i32);*y = ((((*p).s.img_y) as i32) as i32);if (n) != std::ptr::null_mut() {*n = (((*p).s.img_n) as i32);}}
	c_runtime::free((*p)._out_);
	(*p)._out_ = (std::ptr::null_mut());
	c_runtime::free((*p).expanded);
	(*p).expanded = (std::ptr::null_mut());
	c_runtime::free((*p).idata);
	(*p).idata = (std::ptr::null_mut());
	return result;
}

unsafe fn stbi__png_load(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32, ri:*mut stbi__result_info) -> *mut u8 {
	let mut p:stbi__png = std::mem::uninitialized();
	p.s = s;
	return stbi__do_png(&mut p, x, y, comp, ((req_comp) as i32), ri);
}

unsafe fn stbi__png_test(s:*mut stbi__context) -> i32 {
	let mut r:i32 = std::mem::uninitialized();
	r = ((stbi__check_png_header(s)) as i32);
	stbi__rewind(s);
	return r;
}

unsafe fn stbi__png_info_raw(p:*mut stbi__png, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	if stbi__parse_png_file(p, ((STBI__SCAN_header) as i32), ((0) as i32)) == 0 {
stbi__rewind((*p).s);return 0;}
	if (x) != std::ptr::null_mut() {*x = ((((*p).s.img_x) as i32) as i32);}
	if (y) != std::ptr::null_mut() {*y = ((((*p).s.img_y) as i32) as i32);}
	if (comp) != std::ptr::null_mut() {*comp = (((*p).s.img_n) as i32);}
	return 1;
}

unsafe fn stbi__png_info(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	let mut p:stbi__png = std::mem::uninitialized();
	p.s = s;
	return stbi__png_info_raw(&mut p, x, y, comp);
}

unsafe fn stbi__info_main(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	if (stbi__png_info(s, x, y, comp)) != 0 {return 1;}
	return stbi__err("unknown image type");
}

unsafe fn stbi_info_from_memory(buffer:*mut u8, len:i32, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	let mut s:stbi__context = std::mem::uninitialized();
	stbi__start_mem(&mut s, buffer, ((len) as i32));
	return stbi__info_main(&mut s, x, y, comp);
}

unsafe fn stbi_info_from_callbacks(c:*mut stbi_io_callbacks, user:*mut u8, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	let mut s:stbi__context = std::mem::uninitialized();
	stbi__start_callbacks(&mut s, c, user);
	return stbi__info_main(&mut s, x, y, comp);
}

static stbi__g_failure_reason: &'static str = "";

pub struct stbi_io_callbacks {
	read: fn(*mut u8, *mut u8, i32) -> i32,
	skip: fn(*mut u8, i32),
	eof: fn(*mut u8) -> i32,
}

struct stbi__resample {
resample: fn(*mut u8, *mut u8, *mut u8, i32, i32) -> *mut u8,
line0: *mut u8,
line1: *mut u8,
hs: i32,
vs: i32,
w_lores: i32,
ystep: i32,
ypos: i32,
}

/*struct stbi__jpeg {
    s: *mut stbi__context,
    huff_dc: [stbi__huffman; 4],
    huff_ac: [stbi__huffman; 4],
    dequant: [[u16; 64]; 4],
    fast_ac: [[i16; 512]; 4],
    img_h_max: i32,
    img_v_max: i32,
    img_mcu_x: i32,
    img_mcu_y: i32,
    img_mcu_w: i32,
    img_mcu_h: i32,
    img_comp: [img_comp; 4],
    code_buffer: u32,
    code_bits: i32,
    marker: u8,
    nomore: i32,
    progressive: i32,
    spec_start: i32,
    spec_end: i32,
    succ_high: i32,
    succ_low: i32,
    eob_run: i32,
    jfif: i32,
    app14_color_transform: i32,
    rgb: i32,
    scan_n: i32,
    order: [i32; 4],
    restart_interval: i32,
    todo: i32,
    /*    idct_block_kernel: &mut IntPtr,
    YCbCr_to_RGB_kernel: &mut IntPtr,
    resample_row_hv_2_kernel: &mut IntPtr,*/
}*/

unsafe fn stbi__tga_test(s: *mut stbi__context) -> i32 {
/*    let res: i32 = (i32)(0);
    let sz: i32;
    let tga_color_type: i32;
    stbi__get8(s);
    tga_color_type = (i32)(stbi__get8(s));
    if tga_color_type > 1 { goto errorEnd; }
    sz = (i32)(stbi__get8(s));
    if tga_color_type == 1 {
        if sz != 1 && sz != 9 { goto errorEnd; }
        stbi__skip(s, 4);
        sz = (i32)(stbi__get8(s));
        if sz != 8 && sz != 15 && sz != 16 && sz != 24 && sz != 32 { goto errorEnd; }
        stbi__skip(s, 4);
    } else {
        if sz != 2 && sz != 3 && sz != 10 && sz != 11 { goto errorEnd; }
        stbi__skip(s, 9);
    }
    if stbi__get16le(s) < 1 { goto errorEnd; }
    if stbi__get16le(s) < 1 { goto errorEnd; }
    sz = (i32)(stbi__get8(s));
    if tga_color_type == 1 && sz != 8 && sz != 16 { goto errorEnd; }
    if sz != 8 && sz != 15 && sz != 16 && sz != 24 && sz != 32 { goto errorEnd; }
    res = (i32)(1);
    errorEnd: ;
    stbi__rewind(s);
    return (i32)(res);*/
}

pub fn stbi__err(s: &str) -> i32 {
    stbi__g_failure_reason = s;
    return 0;
}
