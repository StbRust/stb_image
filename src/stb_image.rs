// Generated by Ur at 10.08.2018 8:54:56

const STBI_default:i32 = 0;
const STBI_grey:i32 = 1;
const STBI_grey_alpha:i32 = 2;
const STBI_rgb:i32 = 3;
const STBI_rgb_alpha:i32 = 4;
const STBI_ORDER_RGB:i32 = 0;
const STBI_ORDER_BGR:i32 = 1;
const STBI__SCAN_load:i32 = 0;
const STBI__SCAN_type:i32 = 1;
const STBI__SCAN_header:i32 = 2;
const STBI__F_none:i32 = 0;
const STBI__F_sub:i32 = 1;
const STBI__F_up:i32 = 2;
const STBI__F_avg:i32 = 3;
const STBI__F_paeth:i32 = 4;
const STBI__F_avg_first:i32 = 5;
const STBI__F_paeth_first:i32 = 6;
const stbi__vertically_flip_on_load:i32 = (i32)(0);
const stbi__h2l_gamma_i:f32 = (f32)(1.0f32 / 2.2f32);
const stbi__h2l_scale_i:f32 = (f32)(1.0f32);
const stbi__bmask:[u32;17] = [ 0, 1, 3, 7, 15, 31, 63, 127, 255, 511, 1023, 2047, 4095, 8191, 16383, 32767, 65535 ];
const stbi__jbias:[i32;16] = [ 0, -1, -3, -7, -15, -31, -63, -127, -255, -511, -1023, -2047, -4095, -8191, -16383, -32767 ];
const stbi__jpeg_dezigzag:[u8;79] = [ 0, 1, 8, 16, 9, 2, 3, 10, 17, 24, 32, 25, 18, 11, 4, 5, 12, 19, 26, 33, 40, 48, 41, 34, 27, 20, 13, 6, 7, 14, 21, 28, 35, 42, 49, 56, 57, 50, 43, 36, 29, 22, 15, 23, 30, 37, 44, 51, 58, 59, 52, 45, 38, 31, 39, 46, 53, 60, 61, 54, 47, 55, 62, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63 ];
const stbi__zlength_base:[i32;31] = [ 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31, 35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0 ];
const stbi__zlength_extra:[i32;31] = [ 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 0, 0, 0 ];
const stbi__zdist_base:[i32;32] = [ 1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193, 257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145, 8193, 12289, 16385, 24577, 0, 0 ];
const stbi__zdist_extra:[i32;30] = [ 0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13 ];
const length_dezigzag:[u8;19] = [ 16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15 ];
const stbi__zdefault_length:[u8;288] = [ 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8 ];
const stbi__zdefault_distance:[u8;32] = [ 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5 ];
const png_sig:[u8;8] = [ 137, 80, 78, 71, 13, 10, 26, 10 ];
const first_row_filter:[i32;5] = [ STBI__F_none, STBI__F_sub, STBI__F_none, STBI__F_avg_first, STBI__F_paeth_first ];
const stbi__depth_scale_table:[u8;9] = [ 0, 0xff, 0x55, 0, 0x11, 0, 0, 0, 0x01 ];
const stbi__unpremultiply_on_load:i32 = (i32)(0);
const stbi__de_iphone_flag:i32 = (i32)(0);
struct stbi__context {
img_x: u32,
img_y: u32,
img_n: i32,
img_out_n: i32,
io: stbi_io_callbacks,
io_user_data: *mut u8,
read_from_callbacks: i32,
buflen: i32,
buffer_start: [u8;128],
img_buffer: *mut u8,
img_buffer_end: *mut u8,
img_buffer_original: *mut u8,
img_buffer_original_end: *mut u8,
}

struct stbi__result_info {
bits_per_channel: i32,
num_channels: i32,
channel_order: i32,
}

struct stbi__huffman {
fast: [u8;512],
code: [ushort;256],
values: [u8;256],
size: [u8;257],
maxcode: [u32;18],
delta: [i32;17],
}

struct img_comp {
id: i32,
h: i32,
v: i32,
tq: i32,
hd: i32,
ha: i32,
dc_pred: i32,
x: i32,
y: i32,
w2: i32,
h2: i32,
data: *mut u8,
raw_data: *mut u8,
raw_coeff: *mut u8,
linebuf: *mut u8,
coeff: *mut short,
coeff_w: i32,
coeff_h: i32,
}

struct stbi__jpeg {
s: *mut stbi__context,
huff_dc: [stbi__huffman;4],
huff_ac: [stbi__huffman;4],
dequant: [[ushort;64];4],
fast_ac: [[short;512];4],
img_h_max: i32,
img_v_max: i32,
img_mcu_x: i32,
img_mcu_y: i32,
img_mcu_w: i32,
img_mcu_h: i32,
img_comp: [img_comp;4],
code_buffer: u32,
code_bits: i32,
marker: u8,
nomore: i32,
progressive: i32,
spec_start: i32,
spec_end: i32,
succ_high: i32,
succ_low: i32,
eob_run: i32,
jfif: i32,
app14_color_transform: i32,
rgb: i32,
scan_n: i32,
order: [i32;4],
restart_interval: i32,
todo: i32,
idct_block_kernel: *mut IntPtr,
YCbCr_to_RGB_kernel: *mut IntPtr,
resample_row_hv_2_kernel: *mut IntPtr,
}

struct stbi__resample {
line0: *mut u8,
line1: *mut u8,
hs: i32,
vs: i32,
w_lores: i32,
ystep: i32,
ypos: i32,
}

struct stbi__zhuffman {
fast: [ushort;512],
firstcode: [ushort;16],
maxcode: [i32;17],
firstsymbol: [ushort;16],
size: [u8;288],
value: [ushort;288],
}

struct stbi__zbuf {
zbuffer: *mut u8,
zbuffer_end: *mut u8,
num_bits: i32,
code_buffer: u32,
zout: *mut i8,
zout_start: *mut i8,
zout_end: *mut i8,
z_expandable: i32,
z_length: stbi__zhuffman,
z_distance: stbi__zhuffman,
}

struct stbi__pngchunk {
length: u32,
_type_: u32,
}

struct stbi__png {
s: *mut stbi__context,
idata: *mut u8,
expanded: *mut u8,
_out_: *mut u8,
depth: i32,
}

struct stbi__bmp_data {
bpp: i32,
offset: i32,
hsz: i32,
mr: u32,
mg: u32,
mb: u32,
ma: u32,
all_a: u32,
}

struct stbi__gif_lzw {
prefix: short,
first: u8,
suffix: u8,
}

struct stbi__gif {
w: i32,
h: i32,
_out_: *mut u8,
old_out: *mut u8,
flags: i32,
bgindex: i32,
ratio: i32,
transparent: i32,
eflags: i32,
delay: i32,
pal: [[u8;4];256],
lpal: [[u8;4];256],
codes: [stbi__gif_lzw;4096],
color_table: *mut u8,
parse: i32,
step: i32,
lflags: i32,
start_x: i32,
start_y: i32,
max_x: i32,
max_y: i32,
cur_x: i32,
cur_y: i32,
line_size: i32,
}

unsafe fn stbi__start_mem(s:*mut stbi__context, buffer:*mut u8, len:i32){
	s.io.read = (*u8)(0);
	s.read_from_callbacks = (i32)(0);
	s.img_buffer = buffer;
	s.img_buffer_original = buffer;
	s.img_buffer_end = buffer[len];
	s.img_buffer_original_end = buffer[len];
}

unsafe fn stbi__start_callbacks(s:*mut stbi__context, c:*mut stbi_io_callbacks, user:*mut u8){
	s.io = (stbi_io_callbacks)(c);
	s.io_user_data = user;
	s.buflen = (i32)(sizeof(s.buffer_start));
	s.read_from_callbacks = (i32)(1);
	s.img_buffer_original = s.buffer_start.as_mut_ptr();
	stbi__refill_buffer(s);
	s.img_buffer_original_end = s.img_buffer_end;
}

unsafe fn stbi__rewind(s:*mut stbi__context){
	s.img_buffer = s.img_buffer_original;
	s.img_buffer_end = s.img_buffer_original_end;
}

unsafe fn stbi_failure_reason() -> *mut i8 {
	return stbi__g_failure_reason;
}

unsafe fn stbi__err(str:*mut i8) -> i32 {
	stbi__g_failure_reason = str;
	return (i32)(0);
}

unsafe fn stbi__malloc(size:ulong) -> *mut u8 {
	return CRuntime.malloc(size);
}

unsafe fn stbi__addsizes_valid(a:i32, b:i32) -> i32 {
	if b < 0 {return (i32)(0);}
	return (i32)(a <= 2147483647 - b);
}

unsafe fn stbi__mul2sizes_valid(a:i32, b:i32) -> i32 {
	if a < 0 || b < 0 {return (i32)(0);}
	if b == 0 {return (i32)(1);}
	return (i32)(a <= 2147483647 / b);
}

unsafe fn stbi__mad2sizes_valid(a:i32, b:i32, add:i32) -> i32 {
	return (i32)(stbi__mul2sizes_valid(a, b) && stbi__addsizes_valid(a * b, add));
}

unsafe fn stbi__mad3sizes_valid(a:i32, b:i32, c:i32, add:i32) -> i32 {
	return (i32)(stbi__mul2sizes_valid(a, b) && stbi__mul2sizes_valid(a * b, c) && stbi__addsizes_valid(a * b * c, add));
}

unsafe fn stbi__mad4sizes_valid(a:i32, b:i32, c:i32, d:i32, add:i32) -> i32 {
	return (i32)(stbi__mul2sizes_valid(a, b) && stbi__mul2sizes_valid(a * b, c) && stbi__mul2sizes_valid(a * b * c, d) && stbi__addsizes_valid(a * b * c * d, add));
}

unsafe fn stbi__malloc_mad2(a:i32, b:i32, add:i32) -> *mut u8 {
	if !stbi__mad2sizes_valid(a, b, add) {return (*u8)(0);}
	return stbi__malloc(a * b + add);
}

unsafe fn stbi__malloc_mad3(a:i32, b:i32, c:i32, add:i32) -> *mut u8 {
	if !stbi__mad3sizes_valid(a, b, c, add) {return (*u8)(0);}
	return stbi__malloc(a * b * c + add);
}

unsafe fn stbi__malloc_mad4(a:i32, b:i32, c:i32, d:i32, add:i32) -> *mut u8 {
	if !stbi__mad4sizes_valid(a, b, c, d, add) {return (*u8)(0);}
	return stbi__malloc(a * b * c * d + add);
}

unsafe fn stbi_image_free(retval_from_stbi_load:*mut u8){
	CRuntime.free(retval_from_stbi_load);
}

unsafe fn stbi_set_flip_vertically_on_load(flag_true_if_should_flip:i32){
	stbi__vertically_flip_on_load = (i32)(flag_true_if_should_flip);
}

unsafe fn stbi__load_main(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32, ri:*mut stbi__result_info, bpc:i32) -> *mut u8 {
	ri.bits_per_channel = (i32)(8);
	ri.channel_order = (i32)(STBI_ORDER_RGB);
	ri.num_channels = (i32)(0);
	if stbi__jpeg_test(s) {return stbi__jpeg_load(s, x, y, comp, req_comp, ri);}
	if stbi__png_test(s) {return stbi__png_load(s, x, y, comp, req_comp, ri);}
	if stbi__bmp_test(s) {return stbi__bmp_load(s, x, y, comp, req_comp, ri);}
	if stbi__gif_test(s) {return stbi__gif_load(s, x, y, comp, req_comp, ri);}
	if stbi__psd_test(s) {return stbi__psd_load(s, x, y, comp, req_comp, ri, bpc);}
	if stbi__tga_test(s) {return stbi__tga_load(s, x, y, comp, req_comp, ri);}
	return stbi__err("unknown image type".as_mut_ptr());
}

unsafe fn stbi__convert_16_to_8(orig:*mut ushort, w:i32, h:i32, channels:i32) -> *mut u8 {
	let i:i32;
	let img_len:i32 = (i32)(w * h * channels);
	let reduced:*mut u8;
	reduced = stbi__malloc(img_len);
	if reduced == (*u8)(0) {return stbi__err("outofmem".as_mut_ptr());}
	i = (i32)(0);
while (i < img_len) {
i += 1;
reduced[i] = (u8)(orig[i] >> 8 & 0xFF);}
	CRuntime.free(orig);
	return reduced;
}

unsafe fn stbi__convert_8_to_16(orig:*mut u8, w:i32, h:i32, channels:i32) -> *mut ushort {
	let i:i32;
	let img_len:i32 = (i32)(w * h * channels);
	let enlarged:*mut ushort;
	enlarged = (*ushort)(stbi__malloc(img_len * 2));
	if enlarged == (*u8)(0) {return (*ushort)(stbi__err("outofmem".as_mut_ptr()));}
	i = (i32)(0);
while (i < img_len) {
i += 1;
enlarged[i] = (ushort)(orig[i] << 8 + orig[i]);}
	CRuntime.free(orig);
	return enlarged;
}

unsafe fn stbi__vertical_flip(image:*mut u8, w:i32, h:i32, bytes_per_pixel:i32){
	let row:i32;
	let bytes_per_row:ulong = (ulong)(w * bytes_per_pixel);
	let temp:[u8;2048];
	let bytes:*mut u8 = image;
	row = (i32)(0);
while (row < h >> 1) {
row += 1;
{
let row0:*mut u8 = bytes[row * bytes_per_row];let row1:*mut u8 = bytes[h - row - 1 * bytes_per_row];let bytes_left:ulong = (ulong)(bytes_per_row);while (bytes_left) {
let bytes_copy:ulong = (ulong)(if bytes_left < 2048{bytes_left} else {2048});CRuntime.memcpy(temp.as_mut_ptr(), row0, bytes_copy);CRuntime.memcpy(row0, row1, bytes_copy);CRuntime.memcpy(row1, temp.as_mut_ptr(), bytes_copy);row0 += bytes_copy;row1 += bytes_copy;bytes_left -= (ulong)(bytes_copy);}}
}
}

unsafe fn stbi__load_and_postprocess_8bit(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32) -> *mut u8 {
	let ri:stbi__result_info;
	let result:*mut u8 = stbi__load_main(s, x, y, comp, req_comp, ri, 8);
	if result == (*u8)(0) {return (*u8)(0);}
	if ri.bits_per_channel != 8 {
result = stbi__convert_16_to_8((*ushort)(result), x, y, if req_comp == 0{comp} else {req_comp});ri.bits_per_channel = (i32)(8);}
	if stbi__vertically_flip_on_load {
let channels:i32 = (i32)(if req_comp{req_comp} else {comp});stbi__vertical_flip(result, x, y, channels);}
	return result;
}

unsafe fn stbi__load_and_postprocess_16bit(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32) -> *mut ushort {
	let ri:stbi__result_info;
	let result:*mut u8 = stbi__load_main(s, x, y, comp, req_comp, ri, 16);
	if result == (*u8)(0) {return (*u8)(0);}
	if ri.bits_per_channel != 16 {
result = stbi__convert_8_to_16(result, x, y, if req_comp == 0{comp} else {req_comp});ri.bits_per_channel = (i32)(16);}
	if stbi__vertically_flip_on_load {
let channels:i32 = (i32)(if req_comp{req_comp} else {comp});stbi__vertical_flip(result, x, y, channels * 2);}
	return (*ushort)(result);
}

unsafe fn stbi_load_16_from_memory(buffer:*mut u8, len:i32, x:*mut i32, y:*mut i32, channels_in_file:*mut i32, desired_channels:i32) -> *mut ushort {
	let s:stbi__context;
	stbi__start_mem(s, buffer, len);
	return stbi__load_and_postprocess_16bit(s, x, y, channels_in_file, desired_channels);
}

unsafe fn stbi_load_16_from_callbacks(clbk:*mut stbi_io_callbacks, user:*mut u8, x:*mut i32, y:*mut i32, channels_in_file:*mut i32, desired_channels:i32) -> *mut ushort {
	let s:stbi__context;
	stbi__start_callbacks(s, clbk, user);
	return stbi__load_and_postprocess_16bit(s, x, y, channels_in_file, desired_channels);
}

unsafe fn stbi_load_from_memory(buffer:*mut u8, len:i32, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32) -> *mut u8 {
	let s:stbi__context;
	stbi__start_mem(s, buffer, len);
	return stbi__load_and_postprocess_8bit(s, x, y, comp, req_comp);
}

unsafe fn stbi_load_from_callbacks(clbk:*mut stbi_io_callbacks, user:*mut u8, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32) -> *mut u8 {
	let s:stbi__context;
	stbi__start_callbacks(s, clbk, user);
	return stbi__load_and_postprocess_8bit(s, x, y, comp, req_comp);
}

unsafe fn stbi_is_hdr_from_memory(buffer:*mut u8, len:i32) -> i32 {
	return (i32)(0);
}

unsafe fn stbi_is_hdr_from_callbacks(clbk:*mut stbi_io_callbacks, user:*mut u8) -> i32 {
	return (i32)(0);
}

unsafe fn stbi_hdr_to_ldr_gamma(gamma:f32){
	stbi__h2l_gamma_i = (f32)(1 / gamma);
}

unsafe fn stbi_hdr_to_ldr_scale(scale:f32){
	stbi__h2l_scale_i = (f32)(1 / scale);
}

unsafe fn stbi__refill_buffer(s:*mut stbi__context){
	let n:i32 = (i32)(s.io.read(s.io_user_data, (*i8)(s.buffer_start.as_mut_ptr()), s.buflen));
	if n == 0 {
s.read_from_callbacks = (i32)(0);s.img_buffer = s.buffer_start.as_mut_ptr();s.img_buffer_end = s.buffer_start.as_mut_ptr()[1];s.img_buffer = (u8)(0);} else {
s.img_buffer = s.buffer_start.as_mut_ptr();s.img_buffer_end = s.buffer_start.as_mut_ptr()[n];}
}

unsafe fn stbi__get8(s:*mut stbi__context) -> u8 {
	if s.img_buffer < s.img_buffer_end {return (u8)(s.img_buffer += 1);}
	if s.read_from_callbacks {
stbi__refill_buffer(s);return (u8)(s.img_buffer += 1);}
	return (u8)(0);
}

unsafe fn stbi__at_eof(s:*mut stbi__context) -> i32 {
	if s.io.read {
if !s.io.eof(s.io_user_data) {return (i32)(0);}if s.read_from_callbacks == 0 {return (i32)(1);}}
	return (i32)(s.img_buffer >= s.img_buffer_end);
}

unsafe fn stbi__skip(s:*mut stbi__context, n:i32){
	if n < 0 {
s.img_buffer = s.img_buffer_end;return;}
	if s.io.read {
let blen:i32 = (i32)(s.img_buffer_end - s.img_buffer);if blen < n {
s.img_buffer = s.img_buffer_end;s.io.skip(s.io_user_data, n - blen);return;}}
	s.img_buffer += n;
}

unsafe fn stbi__getn(s:*mut stbi__context, buffer:*mut u8, n:i32) -> i32 {
	if s.io.read {
let blen:i32 = (i32)(s.img_buffer_end - s.img_buffer);if blen < n {
let res:i32;let count:i32;CRuntime.memcpy(buffer, s.img_buffer, blen);count = (i32)(s.io.read(s.io_user_data, (*i8)(buffer)[blen], n - blen));res = (i32)(count == n - blen);s.img_buffer = s.img_buffer_end;return (i32)(res);}}
	if s.img_buffer[n] <= s.img_buffer_end {
CRuntime.memcpy(buffer, s.img_buffer, n);s.img_buffer += n;return (i32)(1);} else {return (i32)(0);}
}

unsafe fn stbi__get16be(s:*mut stbi__context) -> i32 {
	let z:i32 = (i32)(stbi__get8(s));
	return (i32)(z << 8 + stbi__get8(s));
}

unsafe fn stbi__get32be(s:*mut stbi__context) -> u32 {
	let z:u32 = (u32)(stbi__get16be(s));
	return (u32)(z << 16 + stbi__get16be(s));
}

unsafe fn stbi__get16le(s:*mut stbi__context) -> i32 {
	let z:i32 = (i32)(stbi__get8(s));
	return (i32)(z + stbi__get8(s) << 8);
}

unsafe fn stbi__get32le(s:*mut stbi__context) -> u32 {
	let z:u32 = (u32)(stbi__get16le(s));
	return (u32)(z + stbi__get16le(s) << 16);
}

unsafe fn stbi__compute_y(r:i32, g:i32, b:i32) -> u8 {
	return (u8)(r * 77 + g * 150 + 29 * b >> 8);
}

unsafe fn stbi__convert_format(data:*mut u8, img_n:i32, req_comp:i32, x:u32, y:u32) -> *mut u8 {
    let i: i32;
    let j: i32;
    let good: *mut u8;
    if req_comp == img_n { return data; }
    good = stbi__malloc_mad3(req_comp, x, y, 0);
    if good == (*u8)(0) {
        CRuntime.free(data);
        return stbi__err("outofmem".as_mut_ptr());
    }
    j = (i32)(0);
    while (j < (i32)(y)) {
        j += 1;
        {
            let src: *mut u8 = data[j * x * img_n];
            let dest: *mut u8 = good[j * x * req_comp];
            match img_n * 8 + req_comp {
                1 *8 + 2 => {i = (i32)(x - 1);
                while (i > = 0) {
                i -= 1, src += 1, dest += 2;
                {
                dest[0] = (u8)(src[0]); dest[1] = (u8)(255);}
                }}, ;
                1 *8 + 3 => {i = (i32)(x - 1);
                while (i > = 0) {
                i -= 1, src += 1, dest += 3;
                {
                dest[0] = (u8)(dest[1] = (u8)(dest[2] = (u8)(src[0])));}
                }}, ;
                1 *8 + 4 => {i = (i32)(x - 1);
                while (i > = 0) {
                i -= 1, src += 1, dest += 4;
                {
                dest[0] = (u8)(dest[1] = (u8)(dest[2] = (u8)(src[0]))); dest[3] = (u8)(255);}
                }}, ;
                2 *8 + 1 => {i = (i32)(x - 1);
                while (i > = 0) {
                i -= 1, src += 2, dest += 1;
                {
                dest[0] = (u8)(src[0]);}
                }}, ;
                2 *8 + 3 => {i = (i32)(x - 1);
                while (i > = 0) {
                i -= 1, src += 2, dest += 3;
                {
                dest[0] = (u8)(dest[1] = (u8)(dest[2] = (u8)(src[0])));}
                }}, ;
                2 *8 + 4 => {i = (i32)(x - 1);
                while (i > = 0) {
                i -= 1, src += 2, dest += 4;
                {
                dest[0] = (u8)(dest[1] = (u8)(dest[2] = (u8)(src[0]))); dest[3] = (u8)(src[1]);}
                }}, ;
                3 *8 + 4 => {i = (i32)(x - 1);
                while (i > = 0) {
                i -= 1, src += 3, dest += 4;
                {
                dest[0] = (u8)(src[0]); dest[1] = (u8)(src[1]);dest[2] = (u8)(src[2]); dest[3] = (u8)(255);}
                }}, ;
                3 *8 + 1 => {i = (i32)(x - 1);
                while (i > = 0) {
                i -= 1, src += 3, dest += 1;
                {
                dest[0] = (u8)(stbi__compute_y(src[0], src[1], src[2]));}
                }}, ;
                3 *8 + 2 => {i = (i32)(x - 1);
                while (i > = 0) {
                i -= 1, src += 3, dest += 2;
                {
                dest[0] = (u8)(stbi__compute_y(src[0], src[1], src[2])); dest[1] = (u8)(255);}
                }}, ;
                4 *8 + 1 => {i = (i32)(x - 1);
                while (i > = 0) {
                i -= 1, src += 4, dest += 1;
                {
                dest[0] = (u8)(stbi__compute_y(src[0], src[1], src[2]));}
                }}, ;
                4 *8 + 2 => {i = (i32)(x - 1);
                while (i > = 0) {
                i -= 1, src += 4, dest += 2;
                {
                dest[0] = (u8)(stbi__compute_y(src[0], src[1], src[2])); dest[1] = (u8)(src[3]);}
                }}, ;
                4 *8 + 3 => {i = (i32)(x - 1);
                while (i > = 0) {
                i -= 1, src += 4, dest += 3;
                {
                dest[0] = (u8)(src[0]); dest[1] = (u8)(src[1]);dest[2] = (u8)(src[2]);}
                }}, ;
                default: return
                stbi__err("0".as_mut_ptr());
            }
        }
    }
    CRuntime.free(data);
    return good;
}

unsafe fn stbi__compute_y_16(r:i32, g:i32, b:i32) -> ushort {
	return (ushort)(r * 77 + g * 150 + 29 * b >> 8);
}

unsafe fn stbi__convert_format16(data:*mut ushort, img_n:i32, req_comp:i32, x:u32, y:u32) -> *mut ushort {
	let i:i32;let j:i32;
	let good:*mut ushort;
	if req_comp == img_n {return data;}
	good = (*ushort)(stbi__malloc(req_comp * x * y * 2));
	if good == (*u8)(0) {
CRuntime.free(data);return (*ushort)(stbi__err("outofmem".as_mut_ptr()));}
	j = (i32)(0);
while (j < (i32)(y)) {
j += 1;
{
let src:*mut ushort = data[j * x * img_n];let dest:*mut ushort = good[j * x * req_comp];match img_n * 8 + req_comp{
1 * 8 + 2 => {i = (i32)(x - 1);
while (i >= 0) {
i -= 1 , src += 1 , dest += 2;
{
dest[0] = (ushort)(src[0]);dest[1] = (ushort)(0xffff);}
}},;1 * 8 + 3 => {i = (i32)(x - 1);
while (i >= 0) {
i -= 1 , src += 1 , dest += 3;
{
dest[0] = (ushort)(dest[1] = (ushort)(dest[2] = (ushort)(src[0])));}
}},;1 * 8 + 4 => {i = (i32)(x - 1);
while (i >= 0) {
i -= 1 , src += 1 , dest += 4;
{
dest[0] = (ushort)(dest[1] = (ushort)(dest[2] = (ushort)(src[0])));dest[3] = (ushort)(0xffff);}
}},;2 * 8 + 1 => {i = (i32)(x - 1);
while (i >= 0) {
i -= 1 , src += 2 , dest += 1;
{
dest[0] = (ushort)(src[0]);}
}},;2 * 8 + 3 => {i = (i32)(x - 1);
while (i >= 0) {
i -= 1 , src += 2 , dest += 3;
{
dest[0] = (ushort)(dest[1] = (ushort)(dest[2] = (ushort)(src[0])));}
}},;2 * 8 + 4 => {i = (i32)(x - 1);
while (i >= 0) {
i -= 1 , src += 2 , dest += 4;
{
dest[0] = (ushort)(dest[1] = (ushort)(dest[2] = (ushort)(src[0])));dest[3] = (ushort)(src[1]);}
}},;3 * 8 + 4 => {i = (i32)(x - 1);
while (i >= 0) {
i -= 1 , src += 3 , dest += 4;
{
dest[0] = (ushort)(src[0]);dest[1] = (ushort)(src[1]);dest[2] = (ushort)(src[2]);dest[3] = (ushort)(0xffff);}
}},;3 * 8 + 1 => {i = (i32)(x - 1);
while (i >= 0) {
i -= 1 , src += 3 , dest += 1;
{
dest[0] = (ushort)(stbi__compute_y_16(src[0], src[1], src[2]));}
}},;3 * 8 + 2 => {i = (i32)(x - 1);
while (i >= 0) {
i -= 1 , src += 3 , dest += 2;
{
dest[0] = (ushort)(stbi__compute_y_16(src[0], src[1], src[2]));dest[1] = (ushort)(0xffff);}
}},;4 * 8 + 1 => {i = (i32)(x - 1);
while (i >= 0) {
i -= 1 , src += 4 , dest += 1;
{
dest[0] = (ushort)(stbi__compute_y_16(src[0], src[1], src[2]));}
}},;4 * 8 + 2 => {i = (i32)(x - 1);
while (i >= 0) {
i -= 1 , src += 4 , dest += 2;
{
dest[0] = (ushort)(stbi__compute_y_16(src[0], src[1], src[2]));dest[1] = (ushort)(src[3]);}
}},;4 * 8 + 3 => {i = (i32)(x - 1);
while (i >= 0) {
i -= 1 , src += 4 , dest += 3;
{
dest[0] = (ushort)(src[0]);dest[1] = (ushort)(src[1]);dest[2] = (ushort)(src[2]);}
}},;default: return (*ushort)(stbi__err("0".as_mut_ptr()));}
}
}
	CRuntime.free(data);
	return good;
}

unsafe fn stbi__build_huffman(h:*mut stbi__huffman, count:*mut i32) -> i32 {
	let i:i32;let j:i32;let k:i32 = (i32)(0);let code:i32;
	i = (i32)(0);
while (i < 16) {
i += 1;
j = (i32)(0);
while (j < count[i]) {
j += 1;
h.size.as_mut_ptr()[k += 1] = (u8)(i + 1);}}
	h.size.as_mut_ptr()[k] = (u8)(0);
	code = (i32)(0);
	k = (i32)(0);
	j = (i32)(1);
while (j <= 16) {
j += 1;
{
h.delta.as_mut_ptr()[j] = (i32)(k - code);if h.size.as_mut_ptr()[k] == j {
while (h.size.as_mut_ptr()[k] == j) {h.code.as_mut_ptr()[k += 1] = (ushort)(code += 1);}if code - 1 >= 1 << j {return (i32)(stbi__err("bad code lengths".as_mut_ptr()));}}h.maxcode.as_mut_ptr()[j] = (u32)(code << 16 - j);code <<= 1;}
}
	h.maxcode.as_mut_ptr()[j] = (u32)(0xffffffff);
	CRuntime.memset(h.fast.as_mut_ptr(), 255, 1 << 9);
	i = (i32)(0);
while (i < k) {
i += 1;
{
let s:i32 = (i32)(h.size.as_mut_ptr()[i]);if s <= 9 {
let c:i32 = (i32)(h.code.as_mut_ptr()[i] << 9 - s);let m:i32 = (i32)(1 << 9 - s);j = (i32)(0);
while (j < m) {
j += 1;
{
h.fast.as_mut_ptr()[c + j] = (u8)(i);}
}}}
}
	return (i32)(1);
}

unsafe fn stbi__build_fast_ac(fast_ac:*mut short, h:*mut stbi__huffman){
	let i:i32;
	i = (i32)(0);
while (i < 1 << 9) {
i += 1;
{
let fast:u8 = (u8)(h.fast.as_mut_ptr()[i]);fast_ac[i] = (short)(0);if fast < 255 {
let rs:i32 = (i32)(h.values.as_mut_ptr()[fast]);let run:i32 = (i32)(rs >> 4 & 15);let magbits:i32 = (i32)(rs & 15);let len:i32 = (i32)(h.size.as_mut_ptr()[fast]);if magbits && len + magbits <= 9 {
let k:i32 = (i32)(i << len & 1 << 9 - 1 >> 9 - magbits);let m:i32 = (i32)(1 << magbits - 1);if k < m {k += (i32)(~0U << magbits + 1);}if k >= -128 && k <= 127 {fast_ac[i] = (short)(k << 8 + run << 4 + len + magbits);}}}}
}
}

unsafe fn stbi__grow_buffer_unsafe(j:*mut stbi__jpeg){
	do {
let b:i32 = (i32)(if j.nomore{0} else {stbi__get8(j.s)});if b == 0xff {
let c:i32 = (i32)(stbi__get8(j.s));while (c == 0xff) {c = (i32)(stbi__get8(j.s));}if c != 0 {
j.marker = (u8)(c);j.nomore = (i32)(1);return;}}j.code_buffer |= (u32)(b << 24 - j.code_bits);j.code_bits += (i32)(8);}
 while (j.code_bits <= 24);
}

unsafe fn stbi__jpeg_huff_decode(j:*mut stbi__jpeg, h:*mut stbi__huffman) -> i32 {
	let temp:u32;
	let c:i32;let k:i32;
	if j.code_bits < 16 {stbi__grow_buffer_unsafe(j);}
	c = (i32)(j.code_buffer >> 32 - 9 & 1 << 9 - 1);
	k = (i32)(h.fast.as_mut_ptr()[c]);
	if k < 255 {
let s:i32 = (i32)(h.size.as_mut_ptr()[k]);if s > j.code_bits {return (i32)(-1);}j.code_buffer <<= s;j.code_bits -= (i32)(s);return (i32)(h.values.as_mut_ptr()[k]);}
	temp = (u32)(j.code_buffer >> 16);
	k = (i32)(9 + 1);
while () {
k += 1;
if temp < h.maxcode.as_mut_ptr()[k] {,;}}
	if k == 17 {
j.code_bits -= (i32)(16);return (i32)(-1);}
	if k > j.code_bits {return (i32)(-1);}
	c = (i32)(j.code_buffer >> 32 - k & stbi__bmask.as_mut_ptr()[k] + h.delta.as_mut_ptr()[k]);
	j.code_bits -= (i32)(k);
	j.code_buffer <<= k;
	return (i32)(h.values.as_mut_ptr()[c]);
}

unsafe fn stbi__extend_receive(j:*mut stbi__jpeg, n:i32) -> i32 {
	let k:u32;
	let sgn:i32;
	if j.code_bits < n {stbi__grow_buffer_unsafe(j);}
	sgn = (i32)((i32)(j.code_buffer) >> 31);
	k = (u32)(CRuntime._lrotl(j.code_buffer, n));
	j.code_buffer = (u32)(k & ~stbi__bmask.as_mut_ptr()[n]);
	k &= (u32)(stbi__bmask.as_mut_ptr()[n]);
	j.code_bits -= (i32)(n);
	return (i32)(k + stbi__jbias.as_mut_ptr()[n] & ~sgn);
}

unsafe fn stbi__jpeg_get_bits(j:*mut stbi__jpeg, n:i32) -> i32 {
	let k:u32;
	if j.code_bits < n {stbi__grow_buffer_unsafe(j);}
	k = (u32)(CRuntime._lrotl(j.code_buffer, n));
	j.code_buffer = (u32)(k & ~stbi__bmask.as_mut_ptr()[n]);
	k &= (u32)(stbi__bmask.as_mut_ptr()[n]);
	j.code_bits -= (i32)(n);
	return (i32)(k);
}

unsafe fn stbi__jpeg_get_bit(j:*mut stbi__jpeg) -> i32 {
	let k:u32;
	if j.code_bits < 1 {stbi__grow_buffer_unsafe(j);}
	k = (u32)(j.code_buffer);
	j.code_buffer <<= 1;
	j.code_bits -= 1;
	return (i32)(k & 0x80000000);
}

unsafe fn stbi__jpeg_decode_block(j:*mut stbi__jpeg, data:[short;64], hdc:*mut stbi__huffman, hac:*mut stbi__huffman, fac:*mut short, b:i32, dequant:*mut ushort) -> i32 {
	let diff:i32;let dc:i32;let k:i32;
	let t:i32;
	if j.code_bits < 16 {stbi__grow_buffer_unsafe(j);}
	t = (i32)(stbi__jpeg_huff_decode(j, hdc));
	if t < 0 {return (i32)(stbi__err("bad huffman code".as_mut_ptr()));}
	CRuntime.memset(data.as_mut_ptr().as_mut_ptr(), 0, 64 * sizeof(data.as_mut_ptr()[0]));
	diff = (i32)(if t{stbi__extend_receive(j, t)} else {0});
	dc = (i32)(j.img_comp.as_mut_ptr()[b].dc_pred + diff);
	j.img_comp.as_mut_ptr()[b].dc_pred = (i32)(dc);
	data.as_mut_ptr()[0] = (short)(dc * dequant[0]);
	k = (i32)(1);
	do {
let zig:u32;let c:i32;let r:i32;let s:i32;if j.code_bits < 16 {stbi__grow_buffer_unsafe(j);}c = (i32)(j.code_buffer >> 32 - 9 & 1 << 9 - 1);r = (i32)(fac[c]);if r {
k += (i32)(r >> 4 & 15);s = (i32)(r & 15);j.code_buffer <<= s;j.code_bits -= (i32)(s);zig = (u32)(stbi__jpeg_dezigzag.as_mut_ptr()[k += 1]);data.as_mut_ptr()[zig] = (short)(r >> 8 * dequant[zig]);} else {
let rs:i32 = (i32)(stbi__jpeg_huff_decode(j, hac));if rs < 0 {return (i32)(stbi__err("bad huffman code".as_mut_ptr()));}s = (i32)(rs & 15);r = (i32)(rs >> 4);if s == 0 {
if rs != 0xf0 {,;}k += (i32)(16);} else {
k += (i32)(r);zig = (u32)(stbi__jpeg_dezigzag.as_mut_ptr()[k += 1]);data.as_mut_ptr()[zig] = (short)(stbi__extend_receive(j, s) * dequant[zig]);}}}
 while (k < 64);
	return (i32)(1);
}

unsafe fn stbi__jpeg_decode_block_prog_dc(j:*mut stbi__jpeg, data:[short;64], hdc:*mut stbi__huffman, b:i32) -> i32 {
	let diff:i32;let dc:i32;
	let t:i32;
	if j.spec_end != 0 {return (i32)(stbi__err("can't merge dc and ac".as_mut_ptr()));}
	if j.code_bits < 16 {stbi__grow_buffer_unsafe(j);}
	if j.succ_high == 0 {
CRuntime.memset(data.as_mut_ptr().as_mut_ptr(), 0, 64 * sizeof(data.as_mut_ptr()[0]));t = (i32)(stbi__jpeg_huff_decode(j, hdc));diff = (i32)(if t{stbi__extend_receive(j, t)} else {0});dc = (i32)(j.img_comp.as_mut_ptr()[b].dc_pred + diff);j.img_comp.as_mut_ptr()[b].dc_pred = (i32)(dc);data.as_mut_ptr()[0] = (short)(dc << j.succ_low);} else {
if stbi__jpeg_get_bit(j) {data.as_mut_ptr()[0] += (short)(1 << j.succ_low);}}
	return (i32)(1);
}

unsafe fn stbi__jpeg_decode_block_prog_ac(j:*mut stbi__jpeg, data:[short;64], hac:*mut stbi__huffman, fac:*mut short) -> i32 {
	let k:i32;
	if j.spec_start == 0 {return (i32)(stbi__err("can't merge dc and ac".as_mut_ptr()));}
	if j.succ_high == 0 {
let shift:i32 = (i32)(j.succ_low);if j.eob_run {
j.eob_run -= 1;return (i32)(1);}k = (i32)(j.spec_start);do {
let zig:u32;let c:i32;let r:i32;let s:i32;if j.code_bits < 16 {stbi__grow_buffer_unsafe(j);}c = (i32)(j.code_buffer >> 32 - 9 & 1 << 9 - 1);r = (i32)(fac[c]);if r {
k += (i32)(r >> 4 & 15);s = (i32)(r & 15);j.code_buffer <<= s;j.code_bits -= (i32)(s);zig = (u32)(stbi__jpeg_dezigzag.as_mut_ptr()[k += 1]);data.as_mut_ptr()[zig] = (short)(r >> 8 << shift);} else {
let rs:i32 = (i32)(stbi__jpeg_huff_decode(j, hac));if rs < 0 {return (i32)(stbi__err("bad huffman code".as_mut_ptr()));}s = (i32)(rs & 15);r = (i32)(rs >> 4);if s == 0 {
if r < 15 {
j.eob_run = (i32)(1 << r);if r {j.eob_run += (i32)(stbi__jpeg_get_bits(j, r));}j.eob_run -= 1;,;}k += (i32)(16);} else {
k += (i32)(r);zig = (u32)(stbi__jpeg_dezigzag.as_mut_ptr()[k += 1]);data.as_mut_ptr()[zig] = (short)(stbi__extend_receive(j, s) << shift);}}}
 while (k <= j.spec_end);} else {
let bit:short = (short)(1 << j.succ_low);if j.eob_run {
j.eob_run -= 1;k = (i32)(j.spec_start);
while (k <= j.spec_end) {
k += 1;
{
let p:*mut short = data.as_mut_ptr()[stbi__jpeg_dezigzag.as_mut_ptr()[k]];if p != 0 {if stbi__jpeg_get_bit(j) {if p & bit == 0 {
if p > 0 {p += (short)(bit);} else {p -= (short)(bit);}}}}}
}} else {
k = (i32)(j.spec_start);do {
let r:i32;let s:i32;let rs:i32 = (i32)(stbi__jpeg_huff_decode(j, hac));if rs < 0 {return (i32)(stbi__err("bad huffman code".as_mut_ptr()));}s = (i32)(rs & 15);r = (i32)(rs >> 4);if s == 0 {
if r < 15 {
j.eob_run = (i32)(1 << r - 1);if r {j.eob_run += (i32)(stbi__jpeg_get_bits(j, r));}r = (i32)(64);} else {
}} else {
if s != 1 {return (i32)(stbi__err("bad huffman code".as_mut_ptr()));}if stbi__jpeg_get_bit(j) {s = (i32)(bit);} else {s = (i32)(-bit);}}while (k <= j.spec_end) {
let p:*mut short = data.as_mut_ptr()[stbi__jpeg_dezigzag.as_mut_ptr()[k += 1]];if p != 0 {
if stbi__jpeg_get_bit(j) {if p & bit == 0 {
if p > 0 {p += (short)(bit);} else {p -= (short)(bit);}}}} else {
if r == 0 {
p = (short)(s);,;}r -= 1;}}}
 while (k <= j.spec_end);}}
	return (i32)(1);
}

unsafe fn stbi__clamp(x:i32) -> u8 {
	if (u32)(x) > 255 {
if x < 0 {return (u8)(0);}if x > 255 {return (u8)(255);}}
	return (u8)(x);
}

unsafe fn stbi__idct_block(_out_:*mut u8, out_stride:i32, data:[short;64]){
	let i:i32;let val:[i32;64];let v:*mut i32 = val.as_mut_ptr();
	let o:*mut u8;
	let d:*mut short = ((short*)data.as_mut_ptr());
	i = (i32)(0);
while (i < 8) {
i += 1 , d += 1 , v += 1;
{
if d[8] == 0 && d[16] == 0 && d[24] == 0 && d[32] == 0 && d[40] == 0 && d[48] == 0 && d[56] == 0 {
let dcterm:i32 = (i32)(d[0] << 2);v[0] = (i32)(v[8] = (i32)(v[16] = (i32)(v[24] = (i32)(v[32] = (i32)(v[40] = (i32)(v[48] = (i32)(v[56] = (i32)(dcterm))))))));} else {
let t0:i32;let t1:i32;let t2:i32;let t3:i32;let p1:i32;let p2:i32;let p3:i32;let p4:i32;let p5:i32;let x0:i32;let x1:i32;let x2:i32;let x3:i32;p2 = (i32)(d[16]);p3 = (i32)(d[48]);p1 = (i32)(p2 + p3 * (i32)(0.5411961f32 * 4096 + 0.5));t2 = (i32)(p1 + p3 * (i32)(-1.847759065f32 * 4096 + 0.5));t3 = (i32)(p1 + p2 * (i32)(0.765366865f32 * 4096 + 0.5));p2 = (i32)(d[0]);p3 = (i32)(d[32]);t0 = (i32)(p2 + p3 << 12);t1 = (i32)(p2 - p3 << 12);x0 = (i32)(t0 + t3);x3 = (i32)(t0 - t3);x1 = (i32)(t1 + t2);x2 = (i32)(t1 - t2);t0 = (i32)(d[56]);t1 = (i32)(d[40]);t2 = (i32)(d[24]);t3 = (i32)(d[8]);p3 = (i32)(t0 + t2);p4 = (i32)(t1 + t3);p1 = (i32)(t0 + t3);p2 = (i32)(t1 + t2);p5 = (i32)(p3 + p4 * (i32)(1.175875602f32 * 4096 + 0.5));t0 = (i32)(t0 * (i32)(0.298631336f32 * 4096 + 0.5));t1 = (i32)(t1 * (i32)(2.053119869f32 * 4096 + 0.5));t2 = (i32)(t2 * (i32)(3.072711026f32 * 4096 + 0.5));t3 = (i32)(t3 * (i32)(1.501321110f32 * 4096 + 0.5));p1 = (i32)(p5 + p1 * (i32)(-0.899976223f32 * 4096 + 0.5));p2 = (i32)(p5 + p2 * (i32)(-2.562915447f32 * 4096 + 0.5));p3 = (i32)(p3 * (i32)(-1.961570560f32 * 4096 + 0.5));p4 = (i32)(p4 * (i32)(-0.390180644f32 * 4096 + 0.5));t3 += (i32)(p1 + p4);t2 += (i32)(p2 + p3);t1 += (i32)(p2 + p4);t0 += (i32)(p1 + p3);x0 += (i32)(512);x1 += (i32)(512);x2 += (i32)(512);x3 += (i32)(512);v[0] = (i32)(x0 + t3 >> 10);v[56] = (i32)(x0 - t3 >> 10);v[8] = (i32)(x1 + t2 >> 10);v[48] = (i32)(x1 - t2 >> 10);v[16] = (i32)(x2 + t1 >> 10);v[40] = (i32)(x2 - t1 >> 10);v[24] = (i32)(x3 + t0 >> 10);v[32] = (i32)(x3 - t0 >> 10);}}
}
	i = (i32)(0) , v = val.as_mut_ptr() , o = _out_;
while (i < 8) {
i += 1 , v += 8 , o += out_stride;
{
let t0:i32;let t1:i32;let t2:i32;let t3:i32;let p1:i32;let p2:i32;let p3:i32;let p4:i32;let p5:i32;let x0:i32;let x1:i32;let x2:i32;let x3:i32;p2 = (i32)(v[2]);p3 = (i32)(v[6]);p1 = (i32)(p2 + p3 * (i32)(0.5411961f32 * 4096 + 0.5));t2 = (i32)(p1 + p3 * (i32)(-1.847759065f32 * 4096 + 0.5));t3 = (i32)(p1 + p2 * (i32)(0.765366865f32 * 4096 + 0.5));p2 = (i32)(v[0]);p3 = (i32)(v[4]);t0 = (i32)(p2 + p3 << 12);t1 = (i32)(p2 - p3 << 12);x0 = (i32)(t0 + t3);x3 = (i32)(t0 - t3);x1 = (i32)(t1 + t2);x2 = (i32)(t1 - t2);t0 = (i32)(v[7]);t1 = (i32)(v[5]);t2 = (i32)(v[3]);t3 = (i32)(v[1]);p3 = (i32)(t0 + t2);p4 = (i32)(t1 + t3);p1 = (i32)(t0 + t3);p2 = (i32)(t1 + t2);p5 = (i32)(p3 + p4 * (i32)(1.175875602f32 * 4096 + 0.5));t0 = (i32)(t0 * (i32)(0.298631336f32 * 4096 + 0.5));t1 = (i32)(t1 * (i32)(2.053119869f32 * 4096 + 0.5));t2 = (i32)(t2 * (i32)(3.072711026f32 * 4096 + 0.5));t3 = (i32)(t3 * (i32)(1.501321110f32 * 4096 + 0.5));p1 = (i32)(p5 + p1 * (i32)(-0.899976223f32 * 4096 + 0.5));p2 = (i32)(p5 + p2 * (i32)(-2.562915447f32 * 4096 + 0.5));p3 = (i32)(p3 * (i32)(-1.961570560f32 * 4096 + 0.5));p4 = (i32)(p4 * (i32)(-0.390180644f32 * 4096 + 0.5));t3 += (i32)(p1 + p4);t2 += (i32)(p2 + p3);t1 += (i32)(p2 + p4);t0 += (i32)(p1 + p3);x0 += (i32)(65536 + 128 << 17);x1 += (i32)(65536 + 128 << 17);x2 += (i32)(65536 + 128 << 17);x3 += (i32)(65536 + 128 << 17);o[0] = (u8)(stbi__clamp(x0 + t3 >> 17));o[7] = (u8)(stbi__clamp(x0 - t3 >> 17));o[1] = (u8)(stbi__clamp(x1 + t2 >> 17));o[6] = (u8)(stbi__clamp(x1 - t2 >> 17));o[2] = (u8)(stbi__clamp(x2 + t1 >> 17));o[5] = (u8)(stbi__clamp(x2 - t1 >> 17));o[3] = (u8)(stbi__clamp(x3 + t0 >> 17));o[4] = (u8)(stbi__clamp(x3 - t0 >> 17));}
}
}

unsafe fn stbi__get_marker(j:*mut stbi__jpeg) -> u8 {
	let x:u8;
	if j.marker != 0xff {
x = (u8)(j.marker);j.marker = (u8)(0xff);return (u8)(x);}
	x = (u8)(stbi__get8(j.s));
	if x != 0xff {return (u8)(0xff);}
	while (x == 0xff) {x = (u8)(stbi__get8(j.s));}
	return (u8)(x);
}

unsafe fn stbi__jpeg_reset(j:*mut stbi__jpeg){
	j.code_bits = (i32)(0);
	j.code_buffer = (u32)(0);
	j.nomore = (i32)(0);
	j.img_comp.as_mut_ptr()[0].dc_pred = (i32)(j.img_comp.as_mut_ptr()[1].dc_pred = (i32)(j.img_comp.as_mut_ptr()[2].dc_pred = (i32)(j.img_comp.as_mut_ptr()[3].dc_pred = (i32)(0))));
	j.marker = (u8)(0xff);
	j.todo = (i32)(if j.restart_interval{j.restart_interval} else {0x7fffffff});
	j.eob_run = (i32)(0);
}

unsafe fn stbi__parse_entropy_coded_data(z:*mut stbi__jpeg) -> i32 {
	stbi__jpeg_reset(z);
	if !z.progressive {
if z.scan_n == 1 {
let i:i32;let j:i32;let data:[short;64];let n:i32 = (i32)(z.order.as_mut_ptr()[0]);let w:i32 = (i32)(z.img_comp.as_mut_ptr()[n].x + 7 >> 3);let h:i32 = (i32)(z.img_comp.as_mut_ptr()[n].y + 7 >> 3);j = (i32)(0);
while (j < h) {
j += 1;
{
i = (i32)(0);
while (i < w) {
i += 1;
{
let ha:i32 = (i32)(z.img_comp.as_mut_ptr()[n].ha);if !stbi__jpeg_decode_block(z, data.as_mut_ptr(), z.huff_dc.as_mut_ptr()[z.img_comp.as_mut_ptr()[n].hd], z.huff_ac.as_mut_ptr()[ha], z.fast_ac.as_mut_ptr()[ha].as_mut_ptr(), n, z.dequant.as_mut_ptr()[z.img_comp.as_mut_ptr()[n].tq].as_mut_ptr()) {return (i32)(0);}z.idct_block_kernel(z.img_comp.as_mut_ptr()[n].data[z.img_comp.as_mut_ptr()[n].w2 * j * 8][i * 8], z.img_comp.as_mut_ptr()[n].w2, data.as_mut_ptr());if z.todo -= 1 <= 0 {
if z.code_bits < 24 {stbi__grow_buffer_unsafe(z);}if !z.marker >= 0xd0 && z.marker <= 0xd7 {return (i32)(1);}stbi__jpeg_reset(z);}}
}}
}return (i32)(1);} else {
let i:i32;let j:i32;let k:i32;let x:i32;let y:i32;let data:[short;64];j = (i32)(0);
while (j < z.img_mcu_y) {
j += 1;
{
i = (i32)(0);
while (i < z.img_mcu_x) {
i += 1;
{
k = (i32)(0);
while (k < z.scan_n) {
k += 1;
{
let n:i32 = (i32)(z.order.as_mut_ptr()[k]);y = (i32)(0);
while (y < z.img_comp.as_mut_ptr()[n].v) {
y += 1;
{
x = (i32)(0);
while (x < z.img_comp.as_mut_ptr()[n].h) {
x += 1;
{
let x2:i32 = (i32)(i * z.img_comp.as_mut_ptr()[n].h + x * 8);let y2:i32 = (i32)(j * z.img_comp.as_mut_ptr()[n].v + y * 8);let ha:i32 = (i32)(z.img_comp.as_mut_ptr()[n].ha);if !stbi__jpeg_decode_block(z, data.as_mut_ptr(), z.huff_dc.as_mut_ptr()[z.img_comp.as_mut_ptr()[n].hd], z.huff_ac.as_mut_ptr()[ha], z.fast_ac.as_mut_ptr()[ha].as_mut_ptr(), n, z.dequant.as_mut_ptr()[z.img_comp.as_mut_ptr()[n].tq].as_mut_ptr()) {return (i32)(0);}z.idct_block_kernel(z.img_comp.as_mut_ptr()[n].data[z.img_comp.as_mut_ptr()[n].w2 * y2][x2], z.img_comp.as_mut_ptr()[n].w2, data.as_mut_ptr());}
}}
}}
}if z.todo -= 1 <= 0 {
if z.code_bits < 24 {stbi__grow_buffer_unsafe(z);}if !z.marker >= 0xd0 && z.marker <= 0xd7 {return (i32)(1);}stbi__jpeg_reset(z);}}
}}
}return (i32)(1);}} else {
if z.scan_n == 1 {
let i:i32;let j:i32;let n:i32 = (i32)(z.order.as_mut_ptr()[0]);let w:i32 = (i32)(z.img_comp.as_mut_ptr()[n].x + 7 >> 3);let h:i32 = (i32)(z.img_comp.as_mut_ptr()[n].y + 7 >> 3);j = (i32)(0);
while (j < h) {
j += 1;
{
i = (i32)(0);
while (i < w) {
i += 1;
{
let data:*mut short = z.img_comp.as_mut_ptr()[n].coeff[64 * i + j * z.img_comp.as_mut_ptr()[n].coeff_w];if z.spec_start == 0 {
if !stbi__jpeg_decode_block_prog_dc(z, data, z.huff_dc.as_mut_ptr()[z.img_comp.as_mut_ptr()[n].hd], n) {return (i32)(0);}} else {
let ha:i32 = (i32)(z.img_comp.as_mut_ptr()[n].ha);if !stbi__jpeg_decode_block_prog_ac(z, data, z.huff_ac.as_mut_ptr()[ha], z.fast_ac.as_mut_ptr()[ha].as_mut_ptr()) {return (i32)(0);}}if z.todo -= 1 <= 0 {
if z.code_bits < 24 {stbi__grow_buffer_unsafe(z);}if !z.marker >= 0xd0 && z.marker <= 0xd7 {return (i32)(1);}stbi__jpeg_reset(z);}}
}}
}return (i32)(1);} else {
let i:i32;let j:i32;let k:i32;let x:i32;let y:i32;j = (i32)(0);
while (j < z.img_mcu_y) {
j += 1;
{
i = (i32)(0);
while (i < z.img_mcu_x) {
i += 1;
{
k = (i32)(0);
while (k < z.scan_n) {
k += 1;
{
let n:i32 = (i32)(z.order.as_mut_ptr()[k]);y = (i32)(0);
while (y < z.img_comp.as_mut_ptr()[n].v) {
y += 1;
{
x = (i32)(0);
while (x < z.img_comp.as_mut_ptr()[n].h) {
x += 1;
{
let x2:i32 = (i32)(i * z.img_comp.as_mut_ptr()[n].h + x);let y2:i32 = (i32)(j * z.img_comp.as_mut_ptr()[n].v + y);let data:*mut short = z.img_comp.as_mut_ptr()[n].coeff[64 * x2 + y2 * z.img_comp.as_mut_ptr()[n].coeff_w];if !stbi__jpeg_decode_block_prog_dc(z, data, z.huff_dc.as_mut_ptr()[z.img_comp.as_mut_ptr()[n].hd], n) {return (i32)(0);}}
}}
}}
}if z.todo -= 1 <= 0 {
if z.code_bits < 24 {stbi__grow_buffer_unsafe(z);}if !z.marker >= 0xd0 && z.marker <= 0xd7 {return (i32)(1);}stbi__jpeg_reset(z);}}
}}
}return (i32)(1);}}
}

unsafe fn stbi__jpeg_dequantize(data:*mut short, dequant:*mut ushort){
	let i:i32;
	i = (i32)(0);
while (i < 64) {
i += 1;
data[i] *= (short)(dequant[i]);}
}

unsafe fn stbi__jpeg_finish(z:*mut stbi__jpeg){
	if z.progressive {
let i:i32;let j:i32;let n:i32;n = (i32)(0);
while (n < z.s.img_n) {
n += 1;
{
let w:i32 = (i32)(z.img_comp.as_mut_ptr()[n].x + 7 >> 3);let h:i32 = (i32)(z.img_comp.as_mut_ptr()[n].y + 7 >> 3);j = (i32)(0);
while (j < h) {
j += 1;
{
i = (i32)(0);
while (i < w) {
i += 1;
{
let data:*mut short = z.img_comp.as_mut_ptr()[n].coeff[64 * i + j * z.img_comp.as_mut_ptr()[n].coeff_w];stbi__jpeg_dequantize(data, z.dequant.as_mut_ptr()[z.img_comp.as_mut_ptr()[n].tq].as_mut_ptr());z.idct_block_kernel(z.img_comp.as_mut_ptr()[n].data[z.img_comp.as_mut_ptr()[n].w2 * j * 8][i * 8], z.img_comp.as_mut_ptr()[n].w2, data);}
}}
}}
}}
}

unsafe fn stbi__process_marker(z:*mut stbi__jpeg, m:i32) -> i32 {
	let L:i32;
	match m{
0xff => {return (i32)(stbi__err("expected marker".as_mut_ptr()))}0xDD => {if stbi__get16be(z.s) != 4 {return (i32)(stbi__err("bad DRI len".as_mut_ptr()));}}z.restart_interval = (i32)(stbi__get16be(z.s));return (i32)(1);0xDB => {L = (i32)(stbi__get16be(z.s) - 2)}while (L > 0) {
let q:i32 = (i32)(stbi__get8(z.s));let p:i32 = (i32)(q >> 4);let sixteen:i32 = (i32)(p != 0);let t:i32 = (i32)(q & 15);let i:i32;if p != 0 && p != 1 {return (i32)(stbi__err("bad DQT type".as_mut_ptr()));}if t > 3 {return (i32)(stbi__err("bad DQT table".as_mut_ptr()));}i = (i32)(0);
while (i < 64) {
i += 1;
z.dequant.as_mut_ptr()[t].as_mut_ptr()[stbi__jpeg_dezigzag.as_mut_ptr()[i]] = (ushort)(if sixteen{stbi__get16be(z.s)} else {stbi__get8(z.s)});}L -= (i32)(if sixteen{129} else {65});}return (i32)(L == 0);0xC4 => {L = (i32)(stbi__get16be(z.s) - 2)}while (L > 0) {
let v:*mut u8;let sizes:[i32;16];let i:i32;let n:i32 = (i32)(0);let q:i32 = (i32)(stbi__get8(z.s));let tc:i32 = (i32)(q >> 4);let th:i32 = (i32)(q & 15);if tc > 1 || th > 3 {return (i32)(stbi__err("bad DHT header".as_mut_ptr()));}i = (i32)(0);
while (i < 16) {
i += 1;
{
sizes.as_mut_ptr()[i] = (i32)(stbi__get8(z.s));n += (i32)(sizes.as_mut_ptr()[i]);}
}L -= (i32)(17);if tc == 0 {
if !stbi__build_huffman(z.huff_dc.as_mut_ptr()[th], sizes.as_mut_ptr()) {return (i32)(0);}v = z.huff_dc.as_mut_ptr()[th].values.as_mut_ptr();} else {
if !stbi__build_huffman(z.huff_ac.as_mut_ptr()[th], sizes.as_mut_ptr()) {return (i32)(0);}v = z.huff_ac.as_mut_ptr()[th].values.as_mut_ptr();}i = (i32)(0);
while (i < n) {
i += 1;
v[i] = (u8)(stbi__get8(z.s));}if tc != 0 {stbi__build_fast_ac(z.fast_ac.as_mut_ptr()[th].as_mut_ptr(), z.huff_ac.as_mut_ptr()[th]);}L -= (i32)(n);}return (i32)(L == 0);}

	if m >= 0xE0 && m <= 0xEF || m == 0xFE {
L = (i32)(stbi__get16be(z.s));if L < 2 {
if m == 0xFE {return (i32)(stbi__err("bad COM len".as_mut_ptr()));} else {return (i32)(stbi__err("bad APP len".as_mut_ptr()));}}L -= (i32)(2);if m == 0xE0 && L >= 5 {
let tag:[u8;5] = stackalloc u8[5];
tag[0] = (u8)('J');
tag[1] = (u8)('F');
tag[2] = (u8)('I');
tag[3] = (u8)('F');
tag[4] = (u8)('\0');
let ok:i32 = (i32)(1);let i:i32;i = (i32)(0);
while (i < 5) {
i += 1;
if stbi__get8(z.s) != tag.as_mut_ptr()[i] {ok = (i32)(0);}}L -= (i32)(5);if ok {z.jfif = (i32)(1);}} else {if m == 0xEE && L >= 12 {
let tag:[u8;6] = stackalloc u8[6];
tag[0] = (u8)('A');
tag[1] = (u8)('d');
tag[2] = (u8)('o');
tag[3] = (u8)('b');
tag[4] = (u8)('e');
tag[5] = (u8)('\0');
let ok:i32 = (i32)(1);let i:i32;i = (i32)(0);
while (i < 6) {
i += 1;
if stbi__get8(z.s) != tag.as_mut_ptr()[i] {ok = (i32)(0);}}L -= (i32)(6);if ok {
stbi__get8(z.s);stbi__get16be(z.s);stbi__get16be(z.s);z.app14_color_transform = (i32)(stbi__get8(z.s));L -= (i32)(6);}}}stbi__skip(z.s, L);return (i32)(1);}
	return (i32)(stbi__err("unknown marker".as_mut_ptr()));
}

unsafe fn stbi__process_scan_header(z:*mut stbi__jpeg) -> i32 {
	let i:i32;
	let Ls:i32 = (i32)(stbi__get16be(z.s));
	z.scan_n = (i32)(stbi__get8(z.s));
	if z.scan_n < 1 || z.scan_n > 4 || z.scan_n > z.s.img_n {return (i32)(stbi__err("bad SOS component count".as_mut_ptr()));}
	if Ls != 6 + 2 * z.scan_n {return (i32)(stbi__err("bad SOS len".as_mut_ptr()));}
	i = (i32)(0);
while (i < z.scan_n) {
i += 1;
{
let id:i32 = (i32)(stbi__get8(z.s));let which:i32;let q:i32 = (i32)(stbi__get8(z.s));which = (i32)(0);
while (which < z.s.img_n) {
which += 1;
if z.img_comp.as_mut_ptr()[which].id == id {,;}}if which == z.s.img_n {return (i32)(0);}z.img_comp.as_mut_ptr()[which].hd = (i32)(q >> 4);if z.img_comp.as_mut_ptr()[which].hd > 3 {return (i32)(stbi__err("bad DC huff".as_mut_ptr()));}z.img_comp.as_mut_ptr()[which].ha = (i32)(q & 15);if z.img_comp.as_mut_ptr()[which].ha > 3 {return (i32)(stbi__err("bad AC huff".as_mut_ptr()));}z.order.as_mut_ptr()[i] = (i32)(which);}
}
	{
let aa:i32;z.spec_start = (i32)(stbi__get8(z.s));z.spec_end = (i32)(stbi__get8(z.s));aa = (i32)(stbi__get8(z.s));z.succ_high = (i32)(aa >> 4);z.succ_low = (i32)(aa & 15);if z.progressive {
if z.spec_start > 63 || z.spec_end > 63 || z.spec_start > z.spec_end || z.succ_high > 13 || z.succ_low > 13 {return (i32)(stbi__err("bad SOS".as_mut_ptr()));}} else {
if z.spec_start != 0 {return (i32)(stbi__err("bad SOS".as_mut_ptr()));}if z.succ_high != 0 || z.succ_low != 0 {return (i32)(stbi__err("bad SOS".as_mut_ptr()));}z.spec_end = (i32)(63);}}

	return (i32)(1);
}

unsafe fn stbi__free_jpeg_components(z:*mut stbi__jpeg, ncomp:i32, why:i32) -> i32 {
	let i:i32;
	i = (i32)(0);
while (i < ncomp) {
i += 1;
{
if z.img_comp.as_mut_ptr()[i].raw_data {
CRuntime.free(z.img_comp.as_mut_ptr()[i].raw_data);z.img_comp.as_mut_ptr()[i].raw_data = (*u8)(0);z.img_comp.as_mut_ptr()[i].data = (*u8)(0);}if z.img_comp.as_mut_ptr()[i].raw_coeff {
CRuntime.free(z.img_comp.as_mut_ptr()[i].raw_coeff);z.img_comp.as_mut_ptr()[i].raw_coeff = null;z.img_comp.as_mut_ptr()[i].coeff = null;}if z.img_comp.as_mut_ptr()[i].linebuf {
CRuntime.free(z.img_comp.as_mut_ptr()[i].linebuf);z.img_comp.as_mut_ptr()[i].linebuf = (*u8)(0);}}
}
	return (i32)(why);
}

unsafe fn stbi__process_frame_header(z:*mut stbi__jpeg, scan:i32) -> i32 {
	let s:*mut stbi__context = z.s;
	let Lf:i32;let p:i32;let i:i32;let q:i32;let h_max:i32 = (i32)(1);let v_max:i32 = (i32)(1);let c:i32;
	Lf = (i32)(stbi__get16be(s));
	if Lf < 11 {return (i32)(stbi__err("bad SOF len".as_mut_ptr()));}
	p = (i32)(stbi__get8(s));
	if p != 8 {return (i32)(stbi__err("only 8-bit".as_mut_ptr()));}
	s.img_y = (u32)(stbi__get16be(s));
	if s.img_y == 0 {return (i32)(stbi__err("no header height".as_mut_ptr()));}
	s.img_x = (u32)(stbi__get16be(s));
	if s.img_x == 0 {return (i32)(stbi__err("0 width".as_mut_ptr()));}
	c = (i32)(stbi__get8(s));
	if c != 3 && c != 1 && c != 4 {return (i32)(stbi__err("bad component count".as_mut_ptr()));}
	s.img_n = (i32)(c);
	i = (i32)(0);
while (i < c) {
i += 1;
{
z.img_comp.as_mut_ptr()[i].data = (*u8)(0);z.img_comp.as_mut_ptr()[i].linebuf = (*u8)(0);}
}
	if Lf != 8 + 3 * s.img_n {return (i32)(stbi__err("bad SOF len".as_mut_ptr()));}
	z.rgb = (i32)(0);
	i = (i32)(0);
while (i < s.img_n) {
i += 1;
{
let rgb:[u8;3] = stackalloc u8[3];
rgb[0] = (u8)('R');
rgb[1] = (u8)('G');
rgb[2] = (u8)('B');
z.img_comp.as_mut_ptr()[i].id = (i32)(stbi__get8(s));if s.img_n == 3 && z.img_comp.as_mut_ptr()[i].id == rgb.as_mut_ptr()[i] {z.rgb += 1;}q = (i32)(stbi__get8(s));z.img_comp.as_mut_ptr()[i].h = (i32)(q >> 4);if !z.img_comp.as_mut_ptr()[i].h || z.img_comp.as_mut_ptr()[i].h > 4 {return (i32)(stbi__err("bad H".as_mut_ptr()));}z.img_comp.as_mut_ptr()[i].v = (i32)(q & 15);if !z.img_comp.as_mut_ptr()[i].v || z.img_comp.as_mut_ptr()[i].v > 4 {return (i32)(stbi__err("bad V".as_mut_ptr()));}z.img_comp.as_mut_ptr()[i].tq = (i32)(stbi__get8(s));if z.img_comp.as_mut_ptr()[i].tq > 3 {return (i32)(stbi__err("bad TQ".as_mut_ptr()));}}
}
	if scan != STBI__SCAN_load {return (i32)(1);}
	if !stbi__mad3sizes_valid(s.img_x, s.img_y, s.img_n, 0) {return (i32)(stbi__err("too large".as_mut_ptr()));}
	i = (i32)(0);
while (i < s.img_n) {
i += 1;
{
if z.img_comp.as_mut_ptr()[i].h > h_max {h_max = (i32)(z.img_comp.as_mut_ptr()[i].h);}if z.img_comp.as_mut_ptr()[i].v > v_max {v_max = (i32)(z.img_comp.as_mut_ptr()[i].v);}}
}
	z.img_h_max = (i32)(h_max);
	z.img_v_max = (i32)(v_max);
	z.img_mcu_w = (i32)(h_max * 8);
	z.img_mcu_h = (i32)(v_max * 8);
	z.img_mcu_x = (i32)(s.img_x + z.img_mcu_w - 1 / z.img_mcu_w);
	z.img_mcu_y = (i32)(s.img_y + z.img_mcu_h - 1 / z.img_mcu_h);
	i = (i32)(0);
while (i < s.img_n) {
i += 1;
{
z.img_comp.as_mut_ptr()[i].x = (i32)(s.img_x * z.img_comp.as_mut_ptr()[i].h + h_max - 1 / h_max);z.img_comp.as_mut_ptr()[i].y = (i32)(s.img_y * z.img_comp.as_mut_ptr()[i].v + v_max - 1 / v_max);z.img_comp.as_mut_ptr()[i].w2 = (i32)(z.img_mcu_x * z.img_comp.as_mut_ptr()[i].h * 8);z.img_comp.as_mut_ptr()[i].h2 = (i32)(z.img_mcu_y * z.img_comp.as_mut_ptr()[i].v * 8);z.img_comp.as_mut_ptr()[i].coeff = null;z.img_comp.as_mut_ptr()[i].raw_coeff = null;z.img_comp.as_mut_ptr()[i].linebuf = (*u8)(0);z.img_comp.as_mut_ptr()[i].raw_data = stbi__malloc_mad2(z.img_comp.as_mut_ptr()[i].w2, z.img_comp.as_mut_ptr()[i].h2, 15);if z.img_comp.as_mut_ptr()[i].raw_data == (*u8)(0) {return (i32)(stbi__free_jpeg_components(z, i + 1, stbi__err("outofmem".as_mut_ptr())));}z.img_comp.as_mut_ptr()[i].data = (*u8)((ulong)(z.img_comp.as_mut_ptr()[i].raw_data) + 15 & ~15);if z.progressive {
z.img_comp.as_mut_ptr()[i].coeff_w = (i32)(z.img_comp.as_mut_ptr()[i].w2 / 8);z.img_comp.as_mut_ptr()[i].coeff_h = (i32)(z.img_comp.as_mut_ptr()[i].h2 / 8);z.img_comp.as_mut_ptr()[i].raw_coeff = stbi__malloc_mad3(z.img_comp.as_mut_ptr()[i].w2, z.img_comp.as_mut_ptr()[i].h2, 2, 15);if z.img_comp.as_mut_ptr()[i].raw_coeff == (*u8)(0) {return (i32)(stbi__free_jpeg_components(z, i + 1, stbi__err("outofmem".as_mut_ptr())));}z.img_comp.as_mut_ptr()[i].coeff = (*short)((ulong)(z.img_comp.as_mut_ptr()[i].raw_coeff) + 15 & ~15);}}
}
	return (i32)(1);
}

unsafe fn stbi__decode_jpeg_header(z:*mut stbi__jpeg, scan:i32) -> i32 {
	let m:i32;
	z.jfif = (i32)(0);
	z.app14_color_transform = (i32)(-1);
	z.marker = (u8)(0xff);
	m = (i32)(stbi__get_marker(z));
	if !m == 0xd8 {return (i32)(stbi__err("no SOI".as_mut_ptr()));}
	if scan == STBI__SCAN_type {return (i32)(1);}
	m = (i32)(stbi__get_marker(z));
	while (!m == 0xc0 || m == 0xc1 || m == 0xc2) {
if !stbi__process_marker(z, m) {return (i32)(0);}m = (i32)(stbi__get_marker(z));while (m == 0xff) {
if stbi__at_eof(z.s) {return (i32)(stbi__err("no SOF".as_mut_ptr()));}m = (i32)(stbi__get_marker(z));}}
	z.progressive = (i32)(m == 0xc2);
	if !stbi__process_frame_header(z, scan) {return (i32)(0);}
	return (i32)(1);
}

unsafe fn stbi__decode_jpeg_image(j:*mut stbi__jpeg) -> i32 {
	let m:i32;
	m = (i32)(0);
while (m < 4) {
m += 1;
{
j.img_comp.as_mut_ptr()[m].raw_data = (*u8)(0);j.img_comp.as_mut_ptr()[m].raw_coeff = (*u8)(0);}
}
	j.restart_interval = (i32)(0);
	if !stbi__decode_jpeg_header(j, STBI__SCAN_load) {return (i32)(0);}
	m = (i32)(stbi__get_marker(j));
	while (!m == 0xd9) {
if m == 0xda {
if !stbi__process_scan_header(j) {return (i32)(0);}if !stbi__parse_entropy_coded_data(j) {return (i32)(0);}if j.marker == 0xff {
while (!stbi__at_eof(j.s)) {
let x:i32 = (i32)(stbi__get8(j.s));if x == 255 {
j.marker = (u8)(stbi__get8(j.s));,;}}}} else {if m == 0xdc {
let Ld:i32 = (i32)(stbi__get16be(j.s));let NL:u32 = (u32)(stbi__get16be(j.s));if Ld != 4 {stbi__err("bad DNL len".as_mut_ptr());}if NL != j.s.img_y {stbi__err("bad DNL height".as_mut_ptr());}} else {
if !stbi__process_marker(j, m) {return (i32)(0);}}}m = (i32)(stbi__get_marker(j));}
	if j.progressive {stbi__jpeg_finish(j);}
	return (i32)(1);
}

unsafe fn resample_row_1(_out_:*mut u8, in_near:*mut u8, in_far:*mut u8, w:i32, hs:i32) -> *mut u8 {
	return in_near;
}

unsafe fn stbi__resample_row_v_2(_out_:*mut u8, in_near:*mut u8, in_far:*mut u8, w:i32, hs:i32) -> *mut u8 {
	let i:i32;
	i = (i32)(0);
while (i < w) {
i += 1;
_out_[i] = (u8)(3 * in_near[i] + in_far[i] + 2 >> 2);}
	return _out_;
}

unsafe fn stbi__resample_row_h_2(_out_:*mut u8, in_near:*mut u8, in_far:*mut u8, w:i32, hs:i32) -> *mut u8 {
	let i:i32;
	let input:*mut u8 = in_near;
	if w == 1 {
_out_[0] = (u8)(_out_[1] = (u8)(input[0]));return _out_;}
	_out_[0] = (u8)(input[0]);
	_out_[1] = (u8)(input[0] * 3 + input[1] + 2 >> 2);
	i = (i32)(1);
while (i < w - 1) {
i += 1;
{
let n:i32 = (i32)(3 * input[i] + 2);_out_[i * 2 + 0] = (u8)(n + input[i - 1] >> 2);_out_[i * 2 + 1] = (u8)(n + input[i + 1] >> 2);}
}
	_out_[i * 2 + 0] = (u8)(input[w - 2] * 3 + input[w - 1] + 2 >> 2);
	_out_[i * 2 + 1] = (u8)(input[w - 1]);
	return _out_;
}

unsafe fn stbi__resample_row_hv_2(_out_:*mut u8, in_near:*mut u8, in_far:*mut u8, w:i32, hs:i32) -> *mut u8 {
	let i:i32;let t0:i32;let t1:i32;
	if w == 1 {
_out_[0] = (u8)(_out_[1] = (u8)(3 * in_near[0] + in_far[0] + 2 >> 2));return _out_;}
	t1 = (i32)(3 * in_near[0] + in_far[0]);
	_out_[0] = (u8)(t1 + 2 >> 2);
	i = (i32)(1);
while (i < w) {
i += 1;
{
t0 = (i32)(t1);t1 = (i32)(3 * in_near[i] + in_far[i]);_out_[i * 2 - 1] = (u8)(3 * t0 + t1 + 8 >> 4);_out_[i * 2] = (u8)(3 * t1 + t0 + 8 >> 4);}
}
	_out_[w * 2 - 1] = (u8)(t1 + 2 >> 2);
	return _out_;
}

unsafe fn stbi__resample_row_generic(_out_:*mut u8, in_near:*mut u8, in_far:*mut u8, w:i32, hs:i32) -> *mut u8 {
	let i:i32;let j:i32;
	i = (i32)(0);
while (i < w) {
i += 1;
j = (i32)(0);
while (j < hs) {
j += 1;
_out_[i * hs + j] = (u8)(in_near[i]);}}
	return _out_;
}

unsafe fn stbi__YCbCr_to_RGB_row(_out_:*mut u8, y:*mut u8, pcb:*mut u8, pcr:*mut u8, count:i32, step:i32){
	let i:i32;
	i = (i32)(0);
while (i < count) {
i += 1;
{
let y_fixed:i32 = (i32)(y[i] << 20 + 1 << 19);let r:i32;let g:i32;let b:i32;let cr:i32 = (i32)(pcr[i] - 128);let cb:i32 = (i32)(pcb[i] - 128);r = (i32)(y_fixed + cr * (i32)(1.40200f32 * 4096.0f32 + 0.5f32) << 8);g = (i32)(y_fixed + cr * -(i32)(0.71414f32 * 4096.0f32 + 0.5f32) << 8 + cb * -(i32)(0.34414f32 * 4096.0f32 + 0.5f32) << 8 & 0xffff0000);b = (i32)(y_fixed + cb * (i32)(1.77200f32 * 4096.0f32 + 0.5f32) << 8);r >>= 20;g >>= 20;b >>= 20;if (u32)(r) > 255 {
if r < 0 {r = (i32)(0);} else {r = (i32)(255);}}if (u32)(g) > 255 {
if g < 0 {g = (i32)(0);} else {g = (i32)(255);}}if (u32)(b) > 255 {
if b < 0 {b = (i32)(0);} else {b = (i32)(255);}}_out_[0] = (u8)(r);_out_[1] = (u8)(g);_out_[2] = (u8)(b);_out_[3] = (u8)(255);_out_ += step;}
}
}

unsafe fn stbi__setup_jpeg(j:*mut stbi__jpeg){
	j.idct_block_kernel = stbi__idct_block;
	j.YCbCr_to_RGB_kernel = stbi__YCbCr_to_RGB_row;
	j.resample_row_hv_2_kernel = stbi__resample_row_hv_2;
}

unsafe fn stbi__cleanup_jpeg(j:*mut stbi__jpeg){
	stbi__free_jpeg_components(j, j.s.img_n, 0);
}

unsafe fn stbi__blinn_8x8(x:u8, y:u8) -> u8 {
	let t:u32 = (u32)(x * y + 128);
	return (u8)(t + t >> 8 >> 8);
}

unsafe fn load_jpeg_image(z:*mut stbi__jpeg, out_x:*mut i32, out_y:*mut i32, comp:*mut i32, req_comp:i32) -> *mut u8 {
	let n:i32;let decode_n:i32;let is_rgb:i32;
	z.s.img_n = (i32)(0);
	if req_comp < 0 || req_comp > 4 {return stbi__err("bad req_comp".as_mut_ptr());}
	if !stbi__decode_jpeg_image(z) {
stbi__cleanup_jpeg(z);return (*u8)(0);}
	n = (i32)(if req_comp{req_comp} else {if z.s.img_n >= 3{3} else {1}});
	is_rgb = (i32)(z.s.img_n == 3 && z.rgb == 3 || z.app14_color_transform == 0 && !z.jfif);
	if z.s.img_n == 3 && n < 3 && !is_rgb {decode_n = (i32)(1);} else {decode_n = (i32)(z.s.img_n);}
	{
let k:i32;let i:u32;let j:u32;let output:*mut u8;let coutput:[u8;4];let res_comp:[stbi__resample;4];k = (i32)(0);
while (k < decode_n) {
k += 1;
{
let r:*mut stbi__resample = res_comp.as_mut_ptr()[k];z.img_comp.as_mut_ptr()[k].linebuf = stbi__malloc(z.s.img_x + 3);if !z.img_comp.as_mut_ptr()[k].linebuf {
stbi__cleanup_jpeg(z);return stbi__err("outofmem".as_mut_ptr());}r.hs = (i32)(z.img_h_max / z.img_comp.as_mut_ptr()[k].h);r.vs = (i32)(z.img_v_max / z.img_comp.as_mut_ptr()[k].v);r.ystep = (i32)(r.vs >> 1);r.w_lores = (i32)(z.s.img_x + r.hs - 1 / r.hs);r.ypos = (i32)(0);r.line0 = r.line1 = z.img_comp.as_mut_ptr()[k].data;if r.hs == 1 && r.vs == 1 {r.resample = resample_row_1;} else {if r.hs == 1 && r.vs == 2 {r.resample = stbi__resample_row_v_2;} else {if r.hs == 2 && r.vs == 1 {r.resample = stbi__resample_row_h_2;} else {if r.hs == 2 && r.vs == 2 {r.resample = z.resample_row_hv_2_kernel;} else {r.resample = stbi__resample_row_generic;}}}}}
}output = stbi__malloc_mad3(n, z.s.img_x, z.s.img_y, 1);if !output {
stbi__cleanup_jpeg(z);return stbi__err("outofmem".as_mut_ptr());}j = (u32)(0);
while (j < z.s.img_y) {
j += 1;
{
let _out_:*mut u8 = output[n * z.s.img_x * j];k = (i32)(0);
while (k < decode_n) {
k += 1;
{
let r:*mut stbi__resample = res_comp.as_mut_ptr()[k];let y_bot:i32 = (i32)(r.ystep >= r.vs >> 1?1:0);coutput.as_mut_ptr()[k] = r.resample(z.img_comp.as_mut_ptr()[k].linebuf, if y_bot{r.line1} else {r.line0}, if y_bot{r.line0} else {r.line1}, r.w_lores, r.hs);if r.ystep += 1 >= r.vs {
r.ystep = (i32)(0);r.line0 = r.line1;if r.ypos += 1 < z.img_comp.as_mut_ptr()[k].y {r.line1 += z.img_comp.as_mut_ptr()[k].w2;}}}
}if n >= 3 {
let y:*mut u8 = coutput.as_mut_ptr()[0];if z.s.img_n == 3 {
if is_rgb {
i = (u32)(0);
while (i < z.s.img_x) {
i += 1;
{
_out_[0] = (u8)(y[i]);_out_[1] = (u8)(coutput.as_mut_ptr()[1][i]);_out_[2] = (u8)(coutput.as_mut_ptr()[2][i]);_out_[3] = (u8)(255);_out_ += n;}
}} else {
z.YCbCr_to_RGB_kernel(_out_, y, coutput.as_mut_ptr()[1], coutput.as_mut_ptr()[2], z.s.img_x, n);}} else {if z.s.img_n == 4 {
if z.app14_color_transform == 0 {
i = (u32)(0);
while (i < z.s.img_x) {
i += 1;
{
let m:u8 = (u8)(coutput.as_mut_ptr()[3][i]);_out_[0] = (u8)(stbi__blinn_8x8(coutput.as_mut_ptr()[0][i], m));_out_[1] = (u8)(stbi__blinn_8x8(coutput.as_mut_ptr()[1][i], m));_out_[2] = (u8)(stbi__blinn_8x8(coutput.as_mut_ptr()[2][i], m));_out_[3] = (u8)(255);_out_ += n;}
}} else {if z.app14_color_transform == 2 {
z.YCbCr_to_RGB_kernel(_out_, y, coutput.as_mut_ptr()[1], coutput.as_mut_ptr()[2], z.s.img_x, n);i = (u32)(0);
while (i < z.s.img_x) {
i += 1;
{
let m:u8 = (u8)(coutput.as_mut_ptr()[3][i]);_out_[0] = (u8)(stbi__blinn_8x8(255 - _out_[0], m));_out_[1] = (u8)(stbi__blinn_8x8(255 - _out_[1], m));_out_[2] = (u8)(stbi__blinn_8x8(255 - _out_[2], m));_out_ += n;}
}} else {
z.YCbCr_to_RGB_kernel(_out_, y, coutput.as_mut_ptr()[1], coutput.as_mut_ptr()[2], z.s.img_x, n);}}} else {i = (u32)(0);
while (i < z.s.img_x) {
i += 1;
{
_out_[0] = (u8)(_out_[1] = (u8)(_out_[2] = (u8)(y[i])));_out_[3] = (u8)(255);_out_ += n;}
}}}} else {
if is_rgb {
if n == 1 {i = (u32)(0);
while (i < z.s.img_x) {
i += 1;
_out_ += 1 = (u8)(stbi__compute_y(coutput.as_mut_ptr()[0][i], coutput.as_mut_ptr()[1][i], coutput.as_mut_ptr()[2][i]));}} else {
i = (u32)(0);
while (i < z.s.img_x) {
i += 1 , _out_ += 2;
{
_out_[0] = (u8)(stbi__compute_y(coutput.as_mut_ptr()[0][i], coutput.as_mut_ptr()[1][i], coutput.as_mut_ptr()[2][i]));_out_[1] = (u8)(255);}
}}} else {if z.s.img_n == 4 && z.app14_color_transform == 0 {
i = (u32)(0);
while (i < z.s.img_x) {
i += 1;
{
let m:u8 = (u8)(coutput.as_mut_ptr()[3][i]);let r:u8 = (u8)(stbi__blinn_8x8(coutput.as_mut_ptr()[0][i], m));let g:u8 = (u8)(stbi__blinn_8x8(coutput.as_mut_ptr()[1][i], m));let b:u8 = (u8)(stbi__blinn_8x8(coutput.as_mut_ptr()[2][i], m));_out_[0] = (u8)(stbi__compute_y(r, g, b));_out_[1] = (u8)(255);_out_ += n;}
}} else {if z.s.img_n == 4 && z.app14_color_transform == 2 {
i = (u32)(0);
while (i < z.s.img_x) {
i += 1;
{
_out_[0] = (u8)(stbi__blinn_8x8(255 - coutput.as_mut_ptr()[0][i], coutput.as_mut_ptr()[3][i]));_out_[1] = (u8)(255);_out_ += n;}
}} else {
let y:*mut u8 = coutput.as_mut_ptr()[0];if n == 1 {i = (u32)(0);
while (i < z.s.img_x) {
i += 1;
_out_[i] = (u8)(y[i]);}} else {i = (u32)(0);
while (i < z.s.img_x) {
i += 1;
_out_ += 1 = (u8)(y[i]);_out_ += 1 = (u8)(255);}}}}}}}
}stbi__cleanup_jpeg(z);out_x = (i32)(z.s.img_x);out_y = (i32)(z.s.img_y);if comp {comp = (i32)(if z.s.img_n >= 3{3} else {1});}return output;}

}

unsafe fn stbi__jpeg_load(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32, ri:*mut stbi__result_info) -> *mut u8 {
	let result:*mut u8;
	let j:*mut stbi__jpeg = (*stbi__jpeg)(stbi__malloc(sizeof(stbi__jpeg)));
	j.s = s;
	stbi__setup_jpeg(j);
	result = load_jpeg_image(j, x, y, comp, req_comp);
	
	return result;
}

unsafe fn stbi__jpeg_test(s:*mut stbi__context) -> i32 {
	let r:i32;
	let j:*mut stbi__jpeg = (*stbi__jpeg)(stbi__malloc(sizeof(stbi__jpeg)));
	j.s = s;
	stbi__setup_jpeg(j);
	r = (i32)(stbi__decode_jpeg_header(j, STBI__SCAN_type));
	stbi__rewind(s);
	
	return (i32)(r);
}

unsafe fn stbi__jpeg_info_raw(j:*mut stbi__jpeg, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	if !stbi__decode_jpeg_header(j, STBI__SCAN_header) {
stbi__rewind(j.s);return (i32)(0);}
	if x {x = (i32)(j.s.img_x);}
	if y {y = (i32)(j.s.img_y);}
	if comp {comp = (i32)(if j.s.img_n >= 3{3} else {1});}
	return (i32)(1);
}

unsafe fn stbi__jpeg_info(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	let result:i32;
	let j:*mut stbi__jpeg = (*stbi__jpeg)(stbi__malloc(sizeof(stbi__jpeg)));
	j.s = s;
	result = (i32)(stbi__jpeg_info_raw(j, x, y, comp));
	
	return (i32)(result);
}

unsafe fn stbi__bitreverse16(n:i32) -> i32 {
	n = (i32)(n & 0xAAAA >> 1 | n & 0x5555 << 1);
	n = (i32)(n & 0xCCCC >> 2 | n & 0x3333 << 2);
	n = (i32)(n & 0xF0F0 >> 4 | n & 0x0F0F << 4);
	n = (i32)(n & 0xFF00 >> 8 | n & 0x00FF << 8);
	return (i32)(n);
}

unsafe fn stbi__bit_reverse(v:i32, bits:i32) -> i32 {
	return (i32)(stbi__bitreverse16(v) >> 16 - bits);
}

unsafe fn stbi__zbuild_huffman(z:*mut stbi__zhuffman, sizelist:*mut u8, num:i32) -> i32 {
	let i:i32;let k:i32 = (i32)(0);
	let code:i32;let next_code:[i32;16];let sizes:[i32;17];
	CRuntime.memset(sizes.as_mut_ptr(), 0, sizeof(sizes));
	CRuntime.memset(z.fast.as_mut_ptr(), 0, sizeof(z.fast));
	i = (i32)(0);
while (i < num) {
i += 1;
sizes.as_mut_ptr()[sizelist[i]] += 1;}
	sizes.as_mut_ptr()[0] = (i32)(0);
	i = (i32)(1);
while (i < 16) {
i += 1;
if sizes.as_mut_ptr()[i] > 1 << i {return (i32)(stbi__err("bad sizes".as_mut_ptr()));}}
	code = (i32)(0);
	i = (i32)(1);
while (i < 16) {
i += 1;
{
next_code.as_mut_ptr()[i] = (i32)(code);z.firstcode.as_mut_ptr()[i] = (ushort)(code);z.firstsymbol.as_mut_ptr()[i] = (ushort)(k);code = (i32)(code + sizes.as_mut_ptr()[i]);if sizes.as_mut_ptr()[i] {if code - 1 >= 1 << i {return (i32)(stbi__err("bad codelengths".as_mut_ptr()));}}z.maxcode.as_mut_ptr()[i] = (i32)(code << 16 - i);code <<= 1;k += (i32)(sizes.as_mut_ptr()[i]);}
}
	z.maxcode.as_mut_ptr()[16] = (i32)(0x10000);
	i = (i32)(0);
while (i < num) {
i += 1;
{
let s:i32 = (i32)(sizelist[i]);if s {
let c:i32 = (i32)(next_code.as_mut_ptr()[s] - z.firstcode.as_mut_ptr()[s] + z.firstsymbol.as_mut_ptr()[s]);let fastv:ushort = (ushort)(s << 9 | i);z.size.as_mut_ptr()[c] = (u8)(s);z.value.as_mut_ptr()[c] = (ushort)(i);if s <= 9 {
let j:i32 = (i32)(stbi__bit_reverse(next_code.as_mut_ptr()[s], s));while (j < 1 << 9) {
z.fast.as_mut_ptr()[j] = (ushort)(fastv);j += (i32)(1 << s);}}next_code.as_mut_ptr()[s] += 1;}}
}
	return (i32)(1);
}

unsafe fn stbi__zget8(z:*mut stbi__zbuf) -> u8 {
	if z.zbuffer >= z.zbuffer_end {return (u8)(0);}
	return (u8)(z.zbuffer += 1);
}

unsafe fn stbi__fill_bits(z:*mut stbi__zbuf){
	do {
z.code_buffer |= (u32)((u32)(stbi__zget8(z)) << z.num_bits);z.num_bits += (i32)(8);}
 while (z.num_bits <= 24);
}

unsafe fn stbi__zreceive(z:*mut stbi__zbuf, n:i32) -> u32 {
	let k:u32;
	if z.num_bits < n {stbi__fill_bits(z);}
	k = (u32)(z.code_buffer & 1 << n - 1);
	z.code_buffer >>= n;
	z.num_bits -= (i32)(n);
	return (u32)(k);
}

unsafe fn stbi__zhuffman_decode_slowpath(a:*mut stbi__zbuf, z:*mut stbi__zhuffman) -> i32 {
	let b:i32;let s:i32;let k:i32;
	k = (i32)(stbi__bit_reverse(a.code_buffer, 16));
	s = (i32)(9 + 1);
while () {
s += 1;
if k < z.maxcode.as_mut_ptr()[s] {,;}}
	if s == 16 {return (i32)(-1);}
	b = (i32)(k >> 16 - s - z.firstcode.as_mut_ptr()[s] + z.firstsymbol.as_mut_ptr()[s]);
	a.code_buffer >>= s;
	a.num_bits -= (i32)(s);
	return (i32)(z.value.as_mut_ptr()[b]);
}

unsafe fn stbi__zhuffman_decode(a:*mut stbi__zbuf, z:*mut stbi__zhuffman) -> i32 {
	let b:i32;let s:i32;
	if a.num_bits < 16 {stbi__fill_bits(a);}
	b = (i32)(z.fast.as_mut_ptr()[a.code_buffer & 1 << 9 - 1]);
	if b {
s = (i32)(b >> 9);a.code_buffer >>= s;a.num_bits -= (i32)(s);return (i32)(b & 511);}
	return (i32)(stbi__zhuffman_decode_slowpath(a, z));
}

unsafe fn stbi__zexpand(z:*mut stbi__zbuf, zout:*mut i8, n:i32) -> i32 {
	let q:*mut i8;
	let cur:i32;let limit:i32;let old_limit:i32;
	z.zout = zout;
	if !z.z_expandable {return (i32)(stbi__err("output buffer limit".as_mut_ptr()));}
	cur = (i32)(z.zout - z.zout_start);
	limit = (i32)(old_limit = (i32)(z.zout_end - z.zout_start));
	while (cur + n > limit) {limit *= (i32)(2);}
	q = (*i8)(CRuntime.realloc(z.zout_start, limit));
	if q == (*u8)(0) {return (i32)(stbi__err("outofmem".as_mut_ptr()));}
	z.zout_start = q;
	z.zout = q[cur];
	z.zout_end = q[limit];
	return (i32)(1);
}

unsafe fn stbi__parse_huffman_block(a:*mut stbi__zbuf) -> i32 {
	let zout:*mut i8 = a.zout;
	;
while () {
;
{
let z:i32 = (i32)(stbi__zhuffman_decode(a, a.z_length));if z < 256 {
if z < 0 {return (i32)(stbi__err("bad huffman code".as_mut_ptr()));}if zout >= a.zout_end {
if !stbi__zexpand(a, zout, 1) {return (i32)(0);}zout = a.zout;}zout += 1 = (i8)(z);} else {
let p:*mut u8;let len:i32;let dist:i32;if z == 256 {
a.zout = zout;return (i32)(1);}z -= (i32)(257);len = (i32)(stbi__zlength_base.as_mut_ptr()[z]);if stbi__zlength_extra.as_mut_ptr()[z] {len += (i32)(stbi__zreceive(a, stbi__zlength_extra.as_mut_ptr()[z]));}z = (i32)(stbi__zhuffman_decode(a, a.z_distance));if z < 0 {return (i32)(stbi__err("bad huffman code".as_mut_ptr()));}dist = (i32)(stbi__zdist_base.as_mut_ptr()[z]);if stbi__zdist_extra.as_mut_ptr()[z] {dist += (i32)(stbi__zreceive(a, stbi__zdist_extra.as_mut_ptr()[z]));}if zout - a.zout_start < dist {return (i32)(stbi__err("bad dist".as_mut_ptr()));}if zout[len] > a.zout_end {
if !stbi__zexpand(a, zout, len) {return (i32)(0);}zout = a.zout;}p = (*u8)(zout - dist);if dist == 1 {
let v:u8 = (u8)(p);if len {
do zout += 1 = (i8)(v); while (len -= 1);}} else {
if len {
do zout += 1 = (i8)(p += 1); while (len -= 1);}}}}
}
}

unsafe fn stbi__compute_huffman_codes(a:*mut stbi__zbuf) -> i32 {
	let z_codelength:stbi__zhuffman;
	let lencodes:[u8;455];
	let codelength_sizes:[u8;19];
	let i:i32;let n:i32;
	let hlit:i32 = (i32)(stbi__zreceive(a, 5) + 257);
	let hdist:i32 = (i32)(stbi__zreceive(a, 5) + 1);
	let hclen:i32 = (i32)(stbi__zreceive(a, 4) + 4);
	let ntot:i32 = (i32)(hlit + hdist);
	CRuntime.memset(codelength_sizes.as_mut_ptr(), 0, sizeof(codelength_sizes));
	i = (i32)(0);
while (i < hclen) {
i += 1;
{
let s:i32 = (i32)(stbi__zreceive(a, 3));codelength_sizes.as_mut_ptr()[length_dezigzag.as_mut_ptr()[i]] = (u8)(s);}
}
	if !stbi__zbuild_huffman(z_codelength, codelength_sizes.as_mut_ptr(), 19) {return (i32)(0);}
	n = (i32)(0);
	while (n < ntot) {
let c:i32 = (i32)(stbi__zhuffman_decode(a, z_codelength));if c < 0 || c >= 19 {return (i32)(stbi__err("bad codelengths".as_mut_ptr()));}if c < 16 {lencodes.as_mut_ptr()[n += 1] = (u8)(c);} else {
let fill:u8 = (u8)(0);if c == 16 {
c = (i32)(stbi__zreceive(a, 2) + 3);if n == 0 {return (i32)(stbi__err("bad codelengths".as_mut_ptr()));}fill = (u8)(lencodes.as_mut_ptr()[n - 1]);} else {if c == 17 {c = (i32)(stbi__zreceive(a, 3) + 3);} else {
c = (i32)(stbi__zreceive(a, 7) + 11);}}if ntot - n < c {return (i32)(stbi__err("bad codelengths".as_mut_ptr()));}CRuntime.memset(lencodes.as_mut_ptr()[n], fill, c);n += (i32)(c);}}
	if n != ntot {return (i32)(stbi__err("bad codelengths".as_mut_ptr()));}
	if !stbi__zbuild_huffman(a.z_length, lencodes.as_mut_ptr(), hlit) {return (i32)(0);}
	if !stbi__zbuild_huffman(a.z_distance, lencodes.as_mut_ptr()[hlit], hdist) {return (i32)(0);}
	return (i32)(1);
}

unsafe fn stbi__parse_uncompressed_block(a:*mut stbi__zbuf) -> i32 {
	let header:[u8;4];
	let len:i32;let nlen:i32;let k:i32;
	if a.num_bits & 7 {stbi__zreceive(a, a.num_bits & 7);}
	k = (i32)(0);
	while (a.num_bits > 0) {
header.as_mut_ptr()[k += 1] = (u8)(a.code_buffer & 255);a.code_buffer >>= 8;a.num_bits -= (i32)(8);}
	while (k < 4) {header.as_mut_ptr()[k += 1] = (u8)(stbi__zget8(a));}
	len = (i32)(header.as_mut_ptr()[1] * 256 + header.as_mut_ptr()[0]);
	nlen = (i32)(header.as_mut_ptr()[3] * 256 + header.as_mut_ptr()[2]);
	if nlen != len ^ 0xffff {return (i32)(stbi__err("zlib corrupt".as_mut_ptr()));}
	if a.zbuffer[len] > a.zbuffer_end {return (i32)(stbi__err("read past buffer".as_mut_ptr()));}
	if a.zout[len] > a.zout_end {if !stbi__zexpand(a, a.zout, len) {return (i32)(0);}}
	CRuntime.memcpy(a.zout, a.zbuffer, len);
	a.zbuffer += len;
	a.zout += len;
	return (i32)(1);
}

unsafe fn stbi__parse_zlib_header(a:*mut stbi__zbuf) -> i32 {
	let cmf:i32 = (i32)(stbi__zget8(a));
	let cm:i32 = (i32)(cmf & 15);
	let flg:i32 = (i32)(stbi__zget8(a));
	if cmf * 256 + flg % 31 != 0 {return (i32)(stbi__err("bad zlib header".as_mut_ptr()));}
	if flg & 32 {return (i32)(stbi__err("no preset dict".as_mut_ptr()));}
	if cm != 8 {return (i32)(stbi__err("bad compression".as_mut_ptr()));}
	return (i32)(1);
}

unsafe fn stbi__parse_zlib(a:*mut stbi__zbuf, parse_header:i32) -> i32 {
	let final:i32;let _type_:i32;
	if parse_header {if !stbi__parse_zlib_header(a) {return (i32)(0);}}
	a.num_bits = (i32)(0);
	a.code_buffer = (u32)(0);
	do {
final = (i32)(stbi__zreceive(a, 1));_type_ = (i32)(stbi__zreceive(a, 2));if _type_ == 0 {
if !stbi__parse_uncompressed_block(a) {return (i32)(0);}} else {if _type_ == 3 {
return (i32)(0);} else {
if _type_ == 1 {
if !stbi__zbuild_huffman(a.z_length, stbi__zdefault_length.as_mut_ptr(), 288) {return (i32)(0);}if !stbi__zbuild_huffman(a.z_distance, stbi__zdefault_distance.as_mut_ptr(), 32) {return (i32)(0);}} else {
if !stbi__compute_huffman_codes(a) {return (i32)(0);}}if !stbi__parse_huffman_block(a) {return (i32)(0);}}}}
 while (!final);
	return (i32)(1);
}

unsafe fn stbi__do_zlib(a:*mut stbi__zbuf, obuf:*mut i8, olen:i32, exp:i32, parse_header:i32) -> i32 {
	a.zout_start = obuf;
	a.zout = obuf;
	a.zout_end = obuf[olen];
	a.z_expandable = (i32)(exp);
	return (i32)(stbi__parse_zlib(a, parse_header));
}

unsafe fn stbi_zlib_decode_malloc_guesssize(buffer:*mut i8, len:i32, initial_size:i32, outlen:*mut i32) -> *mut i8 {
	let a:stbi__zbuf;
	let p:*mut i8 = (*i8)(stbi__malloc(initial_size));
	if p == (*u8)(0) {return (*u8)(0);}
	a.zbuffer = (*u8)(buffer);
	a.zbuffer_end = (*u8)(buffer)[len];
	if stbi__do_zlib(a, p, initial_size, 1, 1) {
if outlen {outlen = (i32)(a.zout - a.zout_start);}return a.zout_start;} else {
CRuntime.free(a.zout_start);return (*u8)(0);}
}

unsafe fn stbi_zlib_decode_malloc(buffer:*mut i8, len:i32, outlen:*mut i32) -> *mut i8 {
	return stbi_zlib_decode_malloc_guesssize(buffer, len, 16384, outlen);
}

unsafe fn stbi_zlib_decode_malloc_guesssize_headerflag(buffer:*mut i8, len:i32, initial_size:i32, outlen:*mut i32, parse_header:i32) -> *mut i8 {
	let a:stbi__zbuf;
	let p:*mut i8 = (*i8)(stbi__malloc(initial_size));
	if p == (*u8)(0) {return (*u8)(0);}
	a.zbuffer = (*u8)(buffer);
	a.zbuffer_end = (*u8)(buffer)[len];
	if stbi__do_zlib(a, p, initial_size, 1, parse_header) {
if outlen {outlen = (i32)(a.zout - a.zout_start);}return a.zout_start;} else {
CRuntime.free(a.zout_start);return (*u8)(0);}
}

unsafe fn stbi_zlib_decode_buffer(obuffer:*mut i8, olen:i32, ibuffer:*mut i8, ilen:i32) -> i32 {
	let a:stbi__zbuf;
	a.zbuffer = (*u8)(ibuffer);
	a.zbuffer_end = (*u8)(ibuffer)[ilen];
	if stbi__do_zlib(a, obuffer, olen, 0, 1) {return (i32)(a.zout - a.zout_start);} else {return (i32)(-1);}
}

unsafe fn stbi_zlib_decode_noheader_malloc(buffer:*mut i8, len:i32, outlen:*mut i32) -> *mut i8 {
	let a:stbi__zbuf;
	let p:*mut i8 = (*i8)(stbi__malloc(16384));
	if p == (*u8)(0) {return (*u8)(0);}
	a.zbuffer = (*u8)(buffer);
	a.zbuffer_end = (*u8)(buffer)[len];
	if stbi__do_zlib(a, p, 16384, 1, 0) {
if outlen {outlen = (i32)(a.zout - a.zout_start);}return a.zout_start;} else {
CRuntime.free(a.zout_start);return (*u8)(0);}
}

unsafe fn stbi_zlib_decode_noheader_buffer(obuffer:*mut i8, olen:i32, ibuffer:*mut i8, ilen:i32) -> i32 {
	let a:stbi__zbuf;
	a.zbuffer = (*u8)(ibuffer);
	a.zbuffer_end = (*u8)(ibuffer)[ilen];
	if stbi__do_zlib(a, obuffer, olen, 0, 0) {return (i32)(a.zout - a.zout_start);} else {return (i32)(-1);}
}

unsafe fn stbi__get_chunk_header(s:*mut stbi__context) -> stbi__pngchunk {
	let c:stbi__pngchunk;
	c.length = (u32)(stbi__get32be(s));
	c._type_ = (u32)(stbi__get32be(s));
	return (stbi__pngchunk)(c);
}

unsafe fn stbi__check_png_header(s:*mut stbi__context) -> i32 {
	let i:i32;
	i = (i32)(0);
while (i < 8) {
i += 1;
if stbi__get8(s) != png_sig.as_mut_ptr()[i] {return (i32)(stbi__err("bad png sig".as_mut_ptr()));}}
	return (i32)(1);
}

unsafe fn stbi__paeth(a:i32, b:i32, c:i32) -> i32 {
	let p:i32 = (i32)(a + b - c);
	let pa:i32 = (i32)(CRuntime.abs(p - a));
	let pb:i32 = (i32)(CRuntime.abs(p - b));
	let pc:i32 = (i32)(CRuntime.abs(p - c));
	if pa <= pb && pa <= pc {return (i32)(a);}
	if pb <= pc {return (i32)(b);}
	return (i32)(c);
}

unsafe fn stbi__create_png_image_raw(a:*mut stbi__png, raw:*mut u8, raw_len:u32, out_n:i32, x:u32, y:u32, depth:i32, color:i32) -> i32 {
	let bytes:i32 = (i32)(if depth == 16{2} else {1});
	let s:*mut stbi__context = a.s;
	let i:u32;let j:u32;let stride:u32 = (u32)(x * out_n * bytes);
	let img_len:u32;let img_width_bytes:u32;
	let k:i32;
	let img_n:i32 = (i32)(s.img_n);
	let output_bytes:i32 = (i32)(out_n * bytes);
	let filter_bytes:i32 = (i32)(img_n * bytes);
	let width:i32 = (i32)(x);
	a._out_ = stbi__malloc_mad3(x, y, output_bytes, 0);
	if !a._out_ {return (i32)(stbi__err("outofmem".as_mut_ptr()));}
	img_width_bytes = (u32)(img_n * x * depth + 7 >> 3);
	img_len = (u32)(img_width_bytes + 1 * y);
	if raw_len < img_len {return (i32)(stbi__err("not enough pixels".as_mut_ptr()));}
	j = (u32)(0);
while (j < y) {
j += 1;
{
let cur:*mut u8 = a._out_[stride * j];let prior:*mut u8;let filter:i32 = (i32)(raw += 1);if filter > 4 {return (i32)(stbi__err("invalid filter".as_mut_ptr()));}if depth < 8 {
cur += x * out_n - img_width_bytes;filter_bytes = (i32)(1);width = (i32)(img_width_bytes);}prior = cur - stride;if j == 0 {filter = (i32)(first_row_filter.as_mut_ptr()[filter]);}k = (i32)(0);
while (k < filter_bytes) {
k += 1;
{
match filter{
STBI__F_none => {cur[k] = (u8)(raw[k])},;STBI__F_sub => {cur[k] = (u8)(raw[k])},;STBI__F_up => {cur[k] = (u8)(raw[k] + prior[k] & 255)},;STBI__F_avg => {cur[k] = (u8)(raw[k] + prior[k] >> 1 & 255)},;STBI__F_paeth => {cur[k] = (u8)(raw[k] + stbi__paeth(0, prior[k], 0) & 255)},;STBI__F_avg_first => {cur[k] = (u8)(raw[k])},;STBI__F_paeth_first => {cur[k] = (u8)(raw[k])},;}
}
}if depth == 8 {
if img_n != out_n {cur[img_n] = (u8)(255);}raw += img_n;cur += out_n;prior += out_n;} else {if depth == 16 {
if img_n != out_n {
cur[filter_bytes] = (u8)(255);cur[filter_bytes + 1] = (u8)(255);}raw += filter_bytes;cur += output_bytes;prior += output_bytes;} else {
raw += 1;cur += 1;prior += 1;}}if depth < 8 || img_n == out_n {
let nk:i32 = (i32)(width - 1 * filter_bytes);match filter{
STBI__F_none => {CRuntime.memcpy(cur, raw, nk)},;STBI__F_sub => {k = (i32)(0);
while (k < nk) {
k += 1;
{
cur[k] = (u8)(raw[k] + cur[k - filter_bytes] & 255);}
}},;STBI__F_up => {k = (i32)(0);
while (k < nk) {
k += 1;
{
cur[k] = (u8)(raw[k] + prior[k] & 255);}
}},;STBI__F_avg => {k = (i32)(0);
while (k < nk) {
k += 1;
{
cur[k] = (u8)(raw[k] + prior[k] + cur[k - filter_bytes] >> 1 & 255);}
}},;STBI__F_paeth => {k = (i32)(0);
while (k < nk) {
k += 1;
{
cur[k] = (u8)(raw[k] + stbi__paeth(cur[k - filter_bytes], prior[k], prior[k - filter_bytes]) & 255);}
}},;STBI__F_avg_first => {k = (i32)(0);
while (k < nk) {
k += 1;
{
cur[k] = (u8)(raw[k] + cur[k - filter_bytes] >> 1 & 255);}
}},;STBI__F_paeth_first => {k = (i32)(0);
while (k < nk) {
k += 1;
{
cur[k] = (u8)(raw[k] + stbi__paeth(cur[k - filter_bytes], 0, 0) & 255);}
}},;}
raw += nk;} else {
match filter{
STBI__F_none => {i = (u32)(x - 1);
while (i >= 1) {
i -= 1 , cur[filter_bytes] = (u8)(255) , raw += filter_bytes , cur += output_bytes , prior += output_bytes;
k = (i32)(0);
while (k < filter_bytes) {
k += 1;
{
cur[k] = (u8)(raw[k]);}
}}},;STBI__F_sub => {i = (u32)(x - 1);
while (i >= 1) {
i -= 1 , cur[filter_bytes] = (u8)(255) , raw += filter_bytes , cur += output_bytes , prior += output_bytes;
k = (i32)(0);
while (k < filter_bytes) {
k += 1;
{
cur[k] = (u8)(raw[k] + cur[k - output_bytes] & 255);}
}}},;STBI__F_up => {i = (u32)(x - 1);
while (i >= 1) {
i -= 1 , cur[filter_bytes] = (u8)(255) , raw += filter_bytes , cur += output_bytes , prior += output_bytes;
k = (i32)(0);
while (k < filter_bytes) {
k += 1;
{
cur[k] = (u8)(raw[k] + prior[k] & 255);}
}}},;STBI__F_avg => {i = (u32)(x - 1);
while (i >= 1) {
i -= 1 , cur[filter_bytes] = (u8)(255) , raw += filter_bytes , cur += output_bytes , prior += output_bytes;
k = (i32)(0);
while (k < filter_bytes) {
k += 1;
{
cur[k] = (u8)(raw[k] + prior[k] + cur[k - output_bytes] >> 1 & 255);}
}}},;STBI__F_paeth => {i = (u32)(x - 1);
while (i >= 1) {
i -= 1 , cur[filter_bytes] = (u8)(255) , raw += filter_bytes , cur += output_bytes , prior += output_bytes;
k = (i32)(0);
while (k < filter_bytes) {
k += 1;
{
cur[k] = (u8)(raw[k] + stbi__paeth(cur[k - output_bytes], prior[k], prior[k - output_bytes]) & 255);}
}}},;STBI__F_avg_first => {i = (u32)(x - 1);
while (i >= 1) {
i -= 1 , cur[filter_bytes] = (u8)(255) , raw += filter_bytes , cur += output_bytes , prior += output_bytes;
k = (i32)(0);
while (k < filter_bytes) {
k += 1;
{
cur[k] = (u8)(raw[k] + cur[k - output_bytes] >> 1 & 255);}
}}},;STBI__F_paeth_first => {i = (u32)(x - 1);
while (i >= 1) {
i -= 1 , cur[filter_bytes] = (u8)(255) , raw += filter_bytes , cur += output_bytes , prior += output_bytes;
k = (i32)(0);
while (k < filter_bytes) {
k += 1;
{
cur[k] = (u8)(raw[k] + stbi__paeth(cur[k - output_bytes], 0, 0) & 255);}
}}},;}
if depth == 16 {
cur = a._out_[stride * j];i = (u32)(0);
while (i < x) {
i += 1 , cur += output_bytes;
{
cur[filter_bytes + 1] = (u8)(255);}
}}}}
}
	if depth < 8 {
j = (u32)(0);
while (j < y) {
j += 1;
{
let cur:*mut u8 = a._out_[stride * j];let _in_:*mut u8 = a._out_[stride * j][x * out_n] - img_width_bytes;let scale:u8 = (u8)(if color == 0{stbi__depth_scale_table.as_mut_ptr()[depth]} else {1});if depth == 4 {
k = (i32)(x * img_n);
while (k >= 2) {
k -= (i32)(2) , _in_ += 1;
{
cur += 1 = (u8)(scale * _in_ >> 4);cur += 1 = (u8)(scale * _in_ & 0x0f);}
}if k > 0 {cur += 1 = (u8)(scale * _in_ >> 4);}} else {if depth == 2 {
k = (i32)(x * img_n);
while (k >= 4) {
k -= (i32)(4) , _in_ += 1;
{
cur += 1 = (u8)(scale * _in_ >> 6);cur += 1 = (u8)(scale * _in_ >> 4 & 0x03);cur += 1 = (u8)(scale * _in_ >> 2 & 0x03);cur += 1 = (u8)(scale * _in_ & 0x03);}
}if k > 0 {cur += 1 = (u8)(scale * _in_ >> 6);}if k > 1 {cur += 1 = (u8)(scale * _in_ >> 4 & 0x03);}if k > 2 {cur += 1 = (u8)(scale * _in_ >> 2 & 0x03);}} else {if depth == 1 {
k = (i32)(x * img_n);
while (k >= 8) {
k -= (i32)(8) , _in_ += 1;
{
cur += 1 = (u8)(scale * _in_ >> 7);cur += 1 = (u8)(scale * _in_ >> 6 & 0x01);cur += 1 = (u8)(scale * _in_ >> 5 & 0x01);cur += 1 = (u8)(scale * _in_ >> 4 & 0x01);cur += 1 = (u8)(scale * _in_ >> 3 & 0x01);cur += 1 = (u8)(scale * _in_ >> 2 & 0x01);cur += 1 = (u8)(scale * _in_ >> 1 & 0x01);cur += 1 = (u8)(scale * _in_ & 0x01);}
}if k > 0 {cur += 1 = (u8)(scale * _in_ >> 7);}if k > 1 {cur += 1 = (u8)(scale * _in_ >> 6 & 0x01);}if k > 2 {cur += 1 = (u8)(scale * _in_ >> 5 & 0x01);}if k > 3 {cur += 1 = (u8)(scale * _in_ >> 4 & 0x01);}if k > 4 {cur += 1 = (u8)(scale * _in_ >> 3 & 0x01);}if k > 5 {cur += 1 = (u8)(scale * _in_ >> 2 & 0x01);}if k > 6 {cur += 1 = (u8)(scale * _in_ >> 1 & 0x01);}}}}if img_n != out_n {
let q:i32;cur = a._out_[stride * j];if img_n == 1 {
q = (i32)(x - 1);
while (q >= 0) {
q -= 1;
{
cur[q * 2 + 1] = (u8)(255);cur[q * 2 + 0] = (u8)(cur[q]);}
}} else {
q = (i32)(x - 1);
while (q >= 0) {
q -= 1;
{
cur[q * 4 + 3] = (u8)(255);cur[q * 4 + 2] = (u8)(cur[q * 3 + 2]);cur[q * 4 + 1] = (u8)(cur[q * 3 + 1]);cur[q * 4 + 0] = (u8)(cur[q * 3 + 0]);}
}}}}
}} else {if depth == 16 {
let cur:*mut u8 = a._out_;let cur16:*mut ushort = (*ushort)(cur);i = (u32)(0);
while (i < x * y * out_n) {
i += 1 , cur16 += 1 , cur += 2;
{
cur16 = (ushort)(cur[0] << 8 | cur[1]);}
}}}
	return (i32)(1);
}

unsafe fn stbi__create_png_image(a:*mut stbi__png, image_data:*mut u8, image_data_len:u32, out_n:i32, depth:i32, color:i32, interlaced:i32) -> i32 {
	let bytes:i32 = (i32)(if depth == 16{2} else {1});
	let out_bytes:i32 = (i32)(out_n * bytes);
	let final:*mut u8;
	let p:i32;
	if !interlaced {return (i32)(stbi__create_png_image_raw(a, image_data, image_data_len, out_n, a.s.img_x, a.s.img_y, depth, color));}
	final = stbi__malloc_mad3(a.s.img_x, a.s.img_y, out_bytes, 0);
	p = (i32)(0);
while (p < 7) {
p += 1;
{
let xorig:[i32;7] = stackalloc i32[7];
xorig[0] = (i32)(0);
xorig[1] = (i32)(4);
xorig[2] = (i32)(0);
xorig[3] = (i32)(2);
xorig[4] = (i32)(0);
xorig[5] = (i32)(1);
xorig[6] = (i32)(0);
let yorig:[i32;7] = stackalloc i32[7];
yorig[0] = (i32)(0);
yorig[1] = (i32)(0);
yorig[2] = (i32)(4);
yorig[3] = (i32)(0);
yorig[4] = (i32)(2);
yorig[5] = (i32)(0);
yorig[6] = (i32)(1);
let xspc:[i32;7] = stackalloc i32[7];
xspc[0] = (i32)(8);
xspc[1] = (i32)(8);
xspc[2] = (i32)(4);
xspc[3] = (i32)(4);
xspc[4] = (i32)(2);
xspc[5] = (i32)(2);
xspc[6] = (i32)(1);
let yspc:[i32;7] = stackalloc i32[7];
yspc[0] = (i32)(8);
yspc[1] = (i32)(8);
yspc[2] = (i32)(8);
yspc[3] = (i32)(4);
yspc[4] = (i32)(4);
yspc[5] = (i32)(2);
yspc[6] = (i32)(2);
let i:i32;let j:i32;let x:i32;let y:i32;x = (i32)(a.s.img_x - xorig.as_mut_ptr()[p] + xspc.as_mut_ptr()[p] - 1 / xspc.as_mut_ptr()[p]);y = (i32)(a.s.img_y - yorig.as_mut_ptr()[p] + yspc.as_mut_ptr()[p] - 1 / yspc.as_mut_ptr()[p]);if x && y {
let img_len:u32 = (u32)(a.s.img_n * x * depth + 7 >> 3 + 1 * y);if !stbi__create_png_image_raw(a, image_data, image_data_len, out_n, x, y, depth, color) {
CRuntime.free(final);return (i32)(0);}j = (i32)(0);
while (j < y) {
j += 1;
{
i = (i32)(0);
while (i < x) {
i += 1;
{
let out_y:i32 = (i32)(j * yspc.as_mut_ptr()[p] + yorig.as_mut_ptr()[p]);let out_x:i32 = (i32)(i * xspc.as_mut_ptr()[p] + xorig.as_mut_ptr()[p]);CRuntime.memcpy(final[out_y * a.s.img_x * out_bytes][out_x * out_bytes], a._out_[j * x + i * out_bytes], out_bytes);}
}}
}CRuntime.free(a._out_);image_data += img_len;image_data_len -= (u32)(img_len);}}
}
	a._out_ = final;
	return (i32)(1);
}

unsafe fn stbi__compute_transparency(z:*mut stbi__png, tc:[u8;3], out_n:i32) -> i32 {
	let s:*mut stbi__context = z.s;
	let i:u32;let pixel_count:u32 = (u32)(s.img_x * s.img_y);
	let p:*mut u8 = z._out_;
	if out_n == 2 {
i = (u32)(0);
while (i < pixel_count) {
i += 1;
{
p[1] = (u8)(if p[0] == tc.as_mut_ptr()[0]{0} else {255});p += 2;}
}} else {
i = (u32)(0);
while (i < pixel_count) {
i += 1;
{
if p[0] == tc.as_mut_ptr()[0] && p[1] == tc.as_mut_ptr()[1] && p[2] == tc.as_mut_ptr()[2] {p[3] = (u8)(0);}p += 4;}
}}
	return (i32)(1);
}

unsafe fn stbi__compute_transparency16(z:*mut stbi__png, tc:[ushort;3], out_n:i32) -> i32 {
	let s:*mut stbi__context = z.s;
	let i:u32;let pixel_count:u32 = (u32)(s.img_x * s.img_y);
	let p:*mut ushort = (*ushort)(z._out_);
	if out_n == 2 {
i = (u32)(0);
while (i < pixel_count) {
i += 1;
{
p[1] = (ushort)(if p[0] == tc.as_mut_ptr()[0]{0} else {65535});p += 2;}
}} else {
i = (u32)(0);
while (i < pixel_count) {
i += 1;
{
if p[0] == tc.as_mut_ptr()[0] && p[1] == tc.as_mut_ptr()[1] && p[2] == tc.as_mut_ptr()[2] {p[3] = (ushort)(0);}p += 4;}
}}
	return (i32)(1);
}

unsafe fn stbi__expand_png_palette(a:*mut stbi__png, palette:*mut u8, len:i32, pal_img_n:i32) -> i32 {
	let i:u32;let pixel_count:u32 = (u32)(a.s.img_x * a.s.img_y);
	let p:*mut u8;let temp_out:*mut u8;let orig:*mut u8 = a._out_;
	p = stbi__malloc_mad2(pixel_count, pal_img_n, 0);
	if p == (*u8)(0) {return (i32)(stbi__err("outofmem".as_mut_ptr()));}
	temp_out = p;
	if pal_img_n == 3 {
i = (u32)(0);
while (i < pixel_count) {
i += 1;
{
let n:i32 = (i32)(orig[i] * 4);p[0] = (u8)(palette[n]);p[1] = (u8)(palette[n + 1]);p[2] = (u8)(palette[n + 2]);p += 3;}
}} else {
i = (u32)(0);
while (i < pixel_count) {
i += 1;
{
let n:i32 = (i32)(orig[i] * 4);p[0] = (u8)(palette[n]);p[1] = (u8)(palette[n + 1]);p[2] = (u8)(palette[n + 2]);p[3] = (u8)(palette[n + 3]);p += 4;}
}}
	CRuntime.free(a._out_);
	a._out_ = temp_out;
	return (i32)(1);
}

unsafe fn stbi_set_unpremultiply_on_load(flag_true_if_should_unpremultiply:i32){
	stbi__unpremultiply_on_load = (i32)(flag_true_if_should_unpremultiply);
}

unsafe fn stbi_convert_iphone_png_to_rgb(flag_true_if_should_convert:i32){
	stbi__de_iphone_flag = (i32)(flag_true_if_should_convert);
}

unsafe fn stbi__de_iphone(z:*mut stbi__png){
	let s:*mut stbi__context = z.s;
	let i:u32;let pixel_count:u32 = (u32)(s.img_x * s.img_y);
	let p:*mut u8 = z._out_;
	if s.img_out_n == 3 {
i = (u32)(0);
while (i < pixel_count) {
i += 1;
{
let t:u8 = (u8)(p[0]);p[0] = (u8)(p[2]);p[2] = (u8)(t);p += 3;}
}} else {
if stbi__unpremultiply_on_load {
i = (u32)(0);
while (i < pixel_count) {
i += 1;
{
let a:u8 = (u8)(p[3]);let t:u8 = (u8)(p[0]);if a {
let half:u8 = (u8)(a / 2);p[0] = (u8)(p[2] * 255 + half / a);p[1] = (u8)(p[1] * 255 + half / a);p[2] = (u8)(t * 255 + half / a);} else {
p[0] = (u8)(p[2]);p[2] = (u8)(t);}p += 4;}
}} else {
i = (u32)(0);
while (i < pixel_count) {
i += 1;
{
let t:u8 = (u8)(p[0]);p[0] = (u8)(p[2]);p[2] = (u8)(t);p += 4;}
}}}
}

unsafe fn stbi__parse_png_file(z:*mut stbi__png, scan:i32, req_comp:i32) -> i32 {
	let palette:[u8;1024];let pal_img_n:u8 = (u8)(0);
	let has_trans:u8 = (u8)(0);let tc:[u8;3];
	let tc16:[ushort;3];
	let ioff:u32 = (u32)(0);let idata_limit:u32 = (u32)(0);let i:u32;let pal_len:u32 = (u32)(0);
	let first:i32 = (i32)(1);let k:i32;let interlace:i32 = (i32)(0);let color:i32 = (i32)(0);let is_iphone:i32 = (i32)(0);
	let s:*mut stbi__context = z.s;
	z.expanded = (*u8)(0);
	z.idata = (*u8)(0);
	z._out_ = (*u8)(0);
	if !stbi__check_png_header(s) {return (i32)(0);}
	if scan == STBI__SCAN_type {return (i32)(1);}
	;
while () {
;
{
let c:stbi__pngchunk = (stbi__pngchunk)(stbi__get_chunk_header(s));match c._type_{
'C' << 24 + 'g' << 16 + 'B' << 8 + 'I' => {is_iphone = (i32)(1)}stbi__skip(s, c.length);,;'I' << 24 + 'H' << 16 + 'D' << 8 + 'R' => {
let comp:i32;let filter:i32;if !first {return (i32)(stbi__err("multiple IHDR".as_mut_ptr()));}first = (i32)(0);if c.length != 13 {return (i32)(stbi__err("bad IHDR len".as_mut_ptr()));}s.img_x = (u32)(stbi__get32be(s));if s.img_x > 1 << 24 {return (i32)(stbi__err("too large".as_mut_ptr()));}s.img_y = (u32)(stbi__get32be(s));if s.img_y > 1 << 24 {return (i32)(stbi__err("too large".as_mut_ptr()));}z.depth = (i32)(stbi__get8(s));if z.depth != 1 && z.depth != 2 && z.depth != 4 && z.depth != 8 && z.depth != 16 {return (i32)(stbi__err("1/2/4/8/16-bit only".as_mut_ptr()));}color = (i32)(stbi__get8(s));if color > 6 {return (i32)(stbi__err("bad ctype".as_mut_ptr()));}if color == 3 && z.depth == 16 {return (i32)(stbi__err("bad ctype".as_mut_ptr()));}if color == 3 {pal_img_n = (u8)(3);} else {if color & 1 {return (i32)(stbi__err("bad ctype".as_mut_ptr()));}}comp = (i32)(stbi__get8(s));if comp {return (i32)(stbi__err("bad comp method".as_mut_ptr()));}filter = (i32)(stbi__get8(s));if filter {return (i32)(stbi__err("bad filter method".as_mut_ptr()));}interlace = (i32)(stbi__get8(s));if interlace > 1 {return (i32)(stbi__err("bad interlace method".as_mut_ptr()));}if !s.img_x || !s.img_y {return (i32)(stbi__err("0-pixel image".as_mut_ptr()));}if !pal_img_n {
s.img_n = (i32)(if color & 2{3} else {1} + if color & 4{1} else {0});if 1 << 30 / s.img_x / s.img_n < s.img_y {return (i32)(stbi__err("too large".as_mut_ptr()));}if scan == STBI__SCAN_header {return (i32)(1);}} else {
s.img_n = (i32)(1);if 1 << 30 / s.img_x / 4 < s.img_y {return (i32)(stbi__err("too large".as_mut_ptr()));}},;}'P' << 24 + 'L' << 16 + 'T' << 8 + 'E' => {
if first {return (i32)(stbi__err("first not IHDR".as_mut_ptr()));}if c.length > 256 * 3 {return (i32)(stbi__err("invalid PLTE".as_mut_ptr()));}pal_len = (u32)(c.length / 3);if pal_len * 3 != c.length {return (i32)(stbi__err("invalid PLTE".as_mut_ptr()));}i = (u32)(0);
while (i < pal_len) {
i += 1;
{
palette.as_mut_ptr()[i * 4 + 0] = (u8)(stbi__get8(s));palette.as_mut_ptr()[i * 4 + 1] = (u8)(stbi__get8(s));palette.as_mut_ptr()[i * 4 + 2] = (u8)(stbi__get8(s));palette.as_mut_ptr()[i * 4 + 3] = (u8)(255);}
},;}'t' << 24 + 'R' << 16 + 'N' << 8 + 'S' => {
if first {return (i32)(stbi__err("first not IHDR".as_mut_ptr()));}if z.idata {return (i32)(stbi__err("tRNS after IDAT".as_mut_ptr()));}if pal_img_n {
if scan == STBI__SCAN_header {
s.img_n = (i32)(4);return (i32)(1);}if pal_len == 0 {return (i32)(stbi__err("tRNS before PLTE".as_mut_ptr()));}if c.length > pal_len {return (i32)(stbi__err("bad tRNS len".as_mut_ptr()));}pal_img_n = (u8)(4);i = (u32)(0);
while (i < c.length) {
i += 1;
palette.as_mut_ptr()[i * 4 + 3] = (u8)(stbi__get8(s));}} else {
if !s.img_n & 1 {return (i32)(stbi__err("tRNS with alpha".as_mut_ptr()));}if c.length != (u32)(s.img_n) * 2 {return (i32)(stbi__err("bad tRNS len".as_mut_ptr()));}has_trans = (u8)(1);if z.depth == 16 {
k = (i32)(0);
while (k < s.img_n) {
k += 1;
tc16.as_mut_ptr()[k] = (ushort)(stbi__get16be(s));}} else {
k = (i32)(0);
while (k < s.img_n) {
k += 1;
tc.as_mut_ptr()[k] = (u8)((u8)(stbi__get16be(s) & 255) * stbi__depth_scale_table.as_mut_ptr()[z.depth]);}}},;}'I' << 24 + 'D' << 16 + 'A' << 8 + 'T' => {
if first {return (i32)(stbi__err("first not IHDR".as_mut_ptr()));}if pal_img_n && !pal_len {return (i32)(stbi__err("no PLTE".as_mut_ptr()));}if scan == STBI__SCAN_header {
s.img_n = (i32)(pal_img_n);return (i32)(1);}if (i32)(ioff + c.length) < (i32)(ioff) {return (i32)(0);}if ioff + c.length > idata_limit {
let idata_limit_old:u32 = (u32)(idata_limit);let p:*mut u8;if idata_limit == 0 {idata_limit = (u32)(if c.length > 4096{c.length} else {4096});}while (ioff + c.length > idata_limit) {idata_limit *= (u32)(2);}p = CRuntime.realloc(z.idata, idata_limit);if p == (*u8)(0) {return (i32)(stbi__err("outofmem".as_mut_ptr()));}z.idata = p;}if !stbi__getn(s, z.idata[ioff], c.length) {return (i32)(stbi__err("outofdata".as_mut_ptr()));}ioff += (u32)(c.length);,;}'I' << 24 + 'E' << 16 + 'N' << 8 + 'D' => {
let raw_len:u32;let bpl:u32;if first {return (i32)(stbi__err("first not IHDR".as_mut_ptr()));}if scan != STBI__SCAN_load {return (i32)(1);}if z.idata == (*u8)(0) {return (i32)(stbi__err("no IDAT".as_mut_ptr()));}bpl = (u32)(s.img_x * z.depth + 7 / 8);raw_len = (u32)(bpl * s.img_y * s.img_n + s.img_y);z.expanded = (*u8)(stbi_zlib_decode_malloc_guesssize_headerflag((*i8)(z.idata), ioff, raw_len, (*i32)(raw_len), !is_iphone));if z.expanded == (*u8)(0) {return (i32)(0);}CRuntime.free(z.idata);z.idata = (*u8)(0);if req_comp == s.img_n + 1 && req_comp != 3 && !pal_img_n || has_trans {s.img_out_n = (i32)(s.img_n + 1);} else {s.img_out_n = (i32)(s.img_n);}if !stbi__create_png_image(z, z.expanded, raw_len, s.img_out_n, z.depth, color, interlace) {return (i32)(0);}if has_trans {
if z.depth == 16 {
if !stbi__compute_transparency16(z, tc16.as_mut_ptr(), s.img_out_n) {return (i32)(0);}} else {
if !stbi__compute_transparency(z, tc.as_mut_ptr(), s.img_out_n) {return (i32)(0);}}}if is_iphone && stbi__de_iphone_flag && s.img_out_n > 2 {stbi__de_iphone(z);}if pal_img_n {
s.img_n = (i32)(pal_img_n);s.img_out_n = (i32)(pal_img_n);if req_comp >= 3 {s.img_out_n = (i32)(req_comp);}if !stbi__expand_png_palette(z, palette.as_mut_ptr(), pal_len, s.img_out_n) {return (i32)(0);}} else {if has_trans {
s.img_n += 1;}}CRuntime.free(z.expanded);z.expanded = (*u8)(0);return (i32)(1);}default: if first {return (i32)(stbi__err("first not IHDR".as_mut_ptr()));}if c._type_ & 1 << 29 == 0 {
let invalid_chunk:[i8;25] = "XXXX PNG chunk not known";return (i32)(stbi__err(invalid_chunk.as_mut_ptr()));}stbi__skip(s, c.length);,;}
stbi__get32be(s);}
}
}

unsafe fn stbi__do_png(p:*mut stbi__png, x:*mut i32, y:*mut i32, n:*mut i32, req_comp:i32, ri:*mut stbi__result_info) -> *mut u8 {
	let result:*mut u8 = (*u8)(0);
	if req_comp < 0 || req_comp > 4 {return stbi__err("bad req_comp".as_mut_ptr());}
	if stbi__parse_png_file(p, STBI__SCAN_load, req_comp) {
if p.depth < 8 {ri.bits_per_channel = (i32)(8);} else {ri.bits_per_channel = (i32)(p.depth);}result = p._out_;p._out_ = (*u8)(0);if req_comp && req_comp != p.s.img_out_n {
if ri.bits_per_channel == 8 {result = stbi__convert_format(result, p.s.img_out_n, req_comp, p.s.img_x, p.s.img_y);} else {result = stbi__convert_format16((*ushort)(result), p.s.img_out_n, req_comp, p.s.img_x, p.s.img_y);}p.s.img_out_n = (i32)(req_comp);if result == (*u8)(0) {return result;}}x = (i32)(p.s.img_x);y = (i32)(p.s.img_y);if n {n = (i32)(p.s.img_n);}}
	CRuntime.free(p._out_);
	p._out_ = (*u8)(0);
	CRuntime.free(p.expanded);
	p.expanded = (*u8)(0);
	CRuntime.free(p.idata);
	p.idata = (*u8)(0);
	return result;
}

unsafe fn stbi__png_load(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32, ri:*mut stbi__result_info) -> *mut u8 {
	let p:stbi__png;
	p.s = s;
	return stbi__do_png(p, x, y, comp, req_comp, ri);
}

unsafe fn stbi__png_test(s:*mut stbi__context) -> i32 {
	let r:i32;
	r = (i32)(stbi__check_png_header(s));
	stbi__rewind(s);
	return (i32)(r);
}

unsafe fn stbi__png_info_raw(p:*mut stbi__png, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	if !stbi__parse_png_file(p, STBI__SCAN_header, 0) {
stbi__rewind(p.s);return (i32)(0);}
	if x {x = (i32)(p.s.img_x);}
	if y {y = (i32)(p.s.img_y);}
	if comp {comp = (i32)(p.s.img_n);}
	return (i32)(1);
}

unsafe fn stbi__png_info(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	let p:stbi__png;
	p.s = s;
	return (i32)(stbi__png_info_raw(p, x, y, comp));
}

unsafe fn stbi__bmp_test_raw(s:*mut stbi__context) -> i32 {
	let r:i32;
	let sz:i32;
	if stbi__get8(s) != 'B' {return (i32)(0);}
	if stbi__get8(s) != 'M' {return (i32)(0);}
	stbi__get32le(s);
	stbi__get16le(s);
	stbi__get16le(s);
	stbi__get32le(s);
	sz = (i32)(stbi__get32le(s));
	r = (i32)(sz == 12 || sz == 40 || sz == 56 || sz == 108 || sz == 124);
	return (i32)(r);
}

unsafe fn stbi__bmp_test(s:*mut stbi__context) -> i32 {
	let r:i32 = (i32)(stbi__bmp_test_raw(s));
	stbi__rewind(s);
	return (i32)(r);
}

unsafe fn stbi__high_bit(z:u32) -> i32 {
	let n:i32 = (i32)(0);
	if z == 0 {return (i32)(-1);}
	if z >= 0x10000 {
n += (i32)(16);z >>= 16;}
	if z >= 0x00100 {
n += (i32)(8);z >>= 8;}
	if z >= 0x00010 {
n += (i32)(4);z >>= 4;}
	if z >= 0x00004 {
n += (i32)(2);z >>= 2;}
	if z >= 0x00002 {
n += (i32)(1);z >>= 1;}
	return (i32)(n);
}

unsafe fn stbi__bitcount(a:u32) -> i32 {
	a = (u32)(a & 0x55555555 + a >> 1 & 0x55555555);
	a = (u32)(a & 0x33333333 + a >> 2 & 0x33333333);
	a = (u32)(a + a >> 4 & 0x0f0f0f0f);
	a = (u32)(a + a >> 8);
	a = (u32)(a + a >> 16);
	return (i32)(a & 0xff);
}

unsafe fn stbi__shiftsigned(v:i32, shift:i32, bits:i32) -> i32 {
	let result:i32;
	let z:i32 = (i32)(0);
	if shift < 0 {v <<= -shift;} else {v >>= shift;}
	result = (i32)(v);
	z = (i32)(bits);
	while (z < 8) {
result += (i32)(v >> z);z += (i32)(bits);}
	return (i32)(result);
}

unsafe fn stbi__bmp_parse_header(s:*mut stbi__context, info:*mut stbi__bmp_data) -> *mut u8 {
	let hsz:i32;
	if stbi__get8(s) != 'B' || stbi__get8(s) != 'M' {return stbi__err("not BMP".as_mut_ptr());}
	stbi__get32le(s);
	stbi__get16le(s);
	stbi__get16le(s);
	info.offset = (i32)(stbi__get32le(s));
	info.hsz = (i32)(hsz = (i32)(stbi__get32le(s)));
	info.mr = (u32)(info.mg = (u32)(info.mb = (u32)(info.ma = (u32)(0))));
	if hsz != 12 && hsz != 40 && hsz != 56 && hsz != 108 && hsz != 124 {return stbi__err("unknown BMP".as_mut_ptr());}
	if hsz == 12 {
s.img_x = (u32)(stbi__get16le(s));s.img_y = (u32)(stbi__get16le(s));} else {
s.img_x = (u32)(stbi__get32le(s));s.img_y = (u32)(stbi__get32le(s));}
	if stbi__get16le(s) != 1 {return stbi__err("bad BMP".as_mut_ptr());}
	info.bpp = (i32)(stbi__get16le(s));
	if info.bpp == 1 {return stbi__err("monochrome".as_mut_ptr());}
	if hsz != 12 {
let compress:i32 = (i32)(stbi__get32le(s));if compress == 1 || compress == 2 {return stbi__err("BMP RLE".as_mut_ptr());}stbi__get32le(s);stbi__get32le(s);stbi__get32le(s);stbi__get32le(s);stbi__get32le(s);if hsz == 40 || hsz == 56 {
if hsz == 56 {
stbi__get32le(s);stbi__get32le(s);stbi__get32le(s);stbi__get32le(s);}if info.bpp == 16 || info.bpp == 32 {
if compress == 0 {
if info.bpp == 32 {
info.mr = (u32)(0xffu << 16);info.mg = (u32)(0xffu << 8);info.mb = (u32)(0xffu << 0);info.ma = (u32)(0xffu << 24);info.all_a = (u32)(0);} else {
info.mr = (u32)(31u << 10);info.mg = (u32)(31u << 5);info.mb = (u32)(31u << 0);}} else {if compress == 3 {
info.mr = (u32)(stbi__get32le(s));info.mg = (u32)(stbi__get32le(s));info.mb = (u32)(stbi__get32le(s));if info.mr == info.mg && info.mg == info.mb {
return stbi__err("bad BMP".as_mut_ptr());}} else {return stbi__err("bad BMP".as_mut_ptr());}}}} else {
let i:i32;if hsz != 108 && hsz != 124 {return stbi__err("bad BMP".as_mut_ptr());}info.mr = (u32)(stbi__get32le(s));info.mg = (u32)(stbi__get32le(s));info.mb = (u32)(stbi__get32le(s));info.ma = (u32)(stbi__get32le(s));stbi__get32le(s);i = (i32)(0);
while (i < 12) {
i += 1;
stbi__get32le(s);}if hsz == 124 {
stbi__get32le(s);stbi__get32le(s);stbi__get32le(s);stbi__get32le(s);}}}
	return (*u8)(1);
}

unsafe fn stbi__bmp_load(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32, ri:*mut stbi__result_info) -> *mut u8 {
	let _out_:*mut u8;
	let mr:u32 = (u32)(0);let mg:u32 = (u32)(0);let mb:u32 = (u32)(0);let ma:u32 = (u32)(0);let all_a:u32;
	let pal:[u8;256];
	let psize:i32 = (i32)(0);let i:i32;let j:i32;let width:i32;
	let flip_vertically:i32;let pad:i32;let target:i32;
	let info:stbi__bmp_data;
	info.all_a = (u32)(255);
	if stbi__bmp_parse_header(s, info) == (*u8)(0) {return (*u8)(0);}
	flip_vertically = (i32)((i32)(s.img_y) > 0);
	s.img_y = (u32)(CRuntime.abs((i32)(s.img_y)));
	mr = (u32)(info.mr);
	mg = (u32)(info.mg);
	mb = (u32)(info.mb);
	ma = (u32)(info.ma);
	all_a = (u32)(info.all_a);
	if info.hsz == 12 {
if info.bpp < 24 {psize = (i32)(info.offset - 14 - 24 / 3);}} else {
if info.bpp < 16 {psize = (i32)(info.offset - 14 - info.hsz >> 2);}}
	s.img_n = (i32)(if ma{4} else {3});
	if req_comp && req_comp >= 3 {target = (i32)(req_comp);} else {target = (i32)(s.img_n);}
	if !stbi__mad3sizes_valid(target, s.img_x, s.img_y, 0) {return stbi__err("too large".as_mut_ptr());}
	_out_ = stbi__malloc_mad3(target, s.img_x, s.img_y, 0);
	if !_out_ {return stbi__err("outofmem".as_mut_ptr());}
	if info.bpp < 16 {
let z:i32 = (i32)(0);if psize == 0 || psize > 256 {
CRuntime.free(_out_);return stbi__err("invalid".as_mut_ptr());}i = (i32)(0);
while (i < psize) {
i += 1;
{
pal.as_mut_ptr()[i].as_mut_ptr()[2] = (u8)(stbi__get8(s));pal.as_mut_ptr()[i].as_mut_ptr()[1] = (u8)(stbi__get8(s));pal.as_mut_ptr()[i].as_mut_ptr()[0] = (u8)(stbi__get8(s));if info.hsz != 12 {stbi__get8(s);}pal.as_mut_ptr()[i].as_mut_ptr()[3] = (u8)(255);}
}stbi__skip(s, info.offset - 14 - info.hsz - psize * if info.hsz == 12{3} else {4});if info.bpp == 4 {width = (i32)(s.img_x + 1 >> 1);} else {if info.bpp == 8 {width = (i32)(s.img_x);} else {
CRuntime.free(_out_);return stbi__err("bad bpp".as_mut_ptr());}}pad = (i32)(-width & 3);j = (i32)(0);
while (j < (i32)(s.img_y)) {
j += 1;
{
i = (i32)(0);
while (i < (i32)(s.img_x)) {
i += (i32)(2);
{
let v:i32 = (i32)(stbi__get8(s));let v2:i32 = (i32)(0);if info.bpp == 4 {
v2 = (i32)(v & 15);v >>= 4;}_out_[z += 1] = (u8)(pal.as_mut_ptr()[v].as_mut_ptr()[0]);_out_[z += 1] = (u8)(pal.as_mut_ptr()[v].as_mut_ptr()[1]);_out_[z += 1] = (u8)(pal.as_mut_ptr()[v].as_mut_ptr()[2]);if target == 4 {_out_[z += 1] = (u8)(255);}if i + 1 == (i32)(s.img_x) {,;}v = (i32)(if info.bpp == 8{stbi__get8(s)} else {v2});_out_[z += 1] = (u8)(pal.as_mut_ptr()[v].as_mut_ptr()[0]);_out_[z += 1] = (u8)(pal.as_mut_ptr()[v].as_mut_ptr()[1]);_out_[z += 1] = (u8)(pal.as_mut_ptr()[v].as_mut_ptr()[2]);if target == 4 {_out_[z += 1] = (u8)(255);}}
}stbi__skip(s, pad);}
}} else {
let rshift:i32 = (i32)(0);let gshift:i32 = (i32)(0);let bshift:i32 = (i32)(0);let ashift:i32 = (i32)(0);let rcount:i32 = (i32)(0);let gcount:i32 = (i32)(0);let bcount:i32 = (i32)(0);let acount:i32 = (i32)(0);let z:i32 = (i32)(0);let easy:i32 = (i32)(0);stbi__skip(s, info.offset - 14 - info.hsz);if info.bpp == 24 {width = (i32)(3 * s.img_x);} else {if info.bpp == 16 {width = (i32)(2 * s.img_x);} else {width = (i32)(0);}}pad = (i32)(-width & 3);if info.bpp == 24 {
easy = (i32)(1);} else {if info.bpp == 32 {
if mb == 0xff && mg == 0xff00 && mr == 0x00ff0000 && ma == 0xff000000 {easy = (i32)(2);}}}if !easy {
if !mr || !mg || !mb {
CRuntime.free(_out_);return stbi__err("bad masks".as_mut_ptr());}rshift = (i32)(stbi__high_bit(mr) - 7);rcount = (i32)(stbi__bitcount(mr));gshift = (i32)(stbi__high_bit(mg) - 7);gcount = (i32)(stbi__bitcount(mg));bshift = (i32)(stbi__high_bit(mb) - 7);bcount = (i32)(stbi__bitcount(mb));ashift = (i32)(stbi__high_bit(ma) - 7);acount = (i32)(stbi__bitcount(ma));}j = (i32)(0);
while (j < (i32)(s.img_y)) {
j += 1;
{
if easy {
i = (i32)(0);
while (i < (i32)(s.img_x)) {
i += 1;
{
let a:u8;_out_[z + 2] = (u8)(stbi__get8(s));_out_[z + 1] = (u8)(stbi__get8(s));_out_[z + 0] = (u8)(stbi__get8(s));z += (i32)(3);a = (u8)(if easy == 2{stbi__get8(s)} else {255});all_a |= (u32)(a);if target == 4 {_out_[z += 1] = (u8)(a);}}
}} else {
let bpp:i32 = (i32)(info.bpp);i = (i32)(0);
while (i < (i32)(s.img_x)) {
i += 1;
{
let v:u32 = (u32)(if bpp == 16{(u32)(stbi__get16le(s))} else {stbi__get32le(s)});let a:i32;_out_[z += 1] = (u8)(stbi__shiftsigned(v & mr, rshift, rcount) & 255);_out_[z += 1] = (u8)(stbi__shiftsigned(v & mg, gshift, gcount) & 255);_out_[z += 1] = (u8)(stbi__shiftsigned(v & mb, bshift, bcount) & 255);a = (i32)(if ma{stbi__shiftsigned(v & ma, ashift, acount)} else {255});all_a |= (u32)(a);if target == 4 {_out_[z += 1] = (u8)(a & 255);}}
}}stbi__skip(s, pad);}
}}
	if target == 4 && all_a == 0 {i = (i32)(4 * s.img_x * s.img_y - 1);
while (i >= 0) {
i -= (i32)(4);
_out_[i] = (u8)(255);}}
	if flip_vertically {
let t:u8;j = (i32)(0);
while (j < (i32)(s.img_y) >> 1) {
j += 1;
{
let p1:*mut u8 = _out_[j * s.img_x * target];let p2:*mut u8 = _out_[s.img_y - 1 - j * s.img_x * target];i = (i32)(0);
while (i < (i32)(s.img_x) * target) {
i += 1;
{
t = (u8)(p1[i]);p1[i] = (u8)(p2[i]);p2[i] = (u8)(t);}
}}
}}
	if req_comp && req_comp != target {
_out_ = stbi__convert_format(_out_, target, req_comp, s.img_x, s.img_y);if _out_ == (*u8)(0) {return _out_;}}
	x = (i32)(s.img_x);
	y = (i32)(s.img_y);
	if comp {comp = (i32)(s.img_n);}
	return _out_;
}

unsafe fn stbi__tga_get_comp(bits_per_pixel:i32, is_grey:i32, is_rgb16:*mut i32) -> i32 {
	if is_rgb16 {is_rgb16 = (i32)(0);}
	match bits_per_pixel{
8 => {return (i32)(STBI_grey)}15 => {16 => {if bits_per_pixel == 16 && is_grey {return (i32)(STBI_grey_alpha);}}}if is_rgb16 {is_rgb16 = (i32)(1);}return (i32)(STBI_rgb);24 => {32 => {return (i32)(bits_per_pixel / 8)}}default: return (i32)(0);}

}

unsafe fn stbi__tga_info(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	let tga_w:i32;let tga_h:i32;let tga_comp:i32;let tga_image_type:i32;let tga_bits_per_pixel:i32;let tga_colormap_bpp:i32;
	let sz:i32;let tga_colormap_type:i32;
	stbi__get8(s);
	tga_colormap_type = (i32)(stbi__get8(s));
	if tga_colormap_type > 1 {
stbi__rewind(s);return (i32)(0);}
	tga_image_type = (i32)(stbi__get8(s));
	if tga_colormap_type == 1 {
if tga_image_type != 1 && tga_image_type != 9 {
stbi__rewind(s);return (i32)(0);}stbi__skip(s, 4);sz = (i32)(stbi__get8(s));if sz != 8 && sz != 15 && sz != 16 && sz != 24 && sz != 32 {
stbi__rewind(s);return (i32)(0);}stbi__skip(s, 4);tga_colormap_bpp = (i32)(sz);} else {
if tga_image_type != 2 && tga_image_type != 3 && tga_image_type != 10 && tga_image_type != 11 {
stbi__rewind(s);return (i32)(0);}stbi__skip(s, 9);tga_colormap_bpp = (i32)(0);}
	tga_w = (i32)(stbi__get16le(s));
	if tga_w < 1 {
stbi__rewind(s);return (i32)(0);}
	tga_h = (i32)(stbi__get16le(s));
	if tga_h < 1 {
stbi__rewind(s);return (i32)(0);}
	tga_bits_per_pixel = (i32)(stbi__get8(s));
	stbi__get8(s);
	if tga_colormap_bpp != 0 {
if tga_bits_per_pixel != 8 && tga_bits_per_pixel != 16 {
stbi__rewind(s);return (i32)(0);}tga_comp = (i32)(stbi__tga_get_comp(tga_colormap_bpp, 0, (*u8)(0)));} else {
tga_comp = (i32)(stbi__tga_get_comp(tga_bits_per_pixel, tga_image_type == 3 || tga_image_type == 11, (*u8)(0)));}
	if !tga_comp {
stbi__rewind(s);return (i32)(0);}
	if x {x = (i32)(tga_w);}
	if y {y = (i32)(tga_h);}
	if comp {comp = (i32)(tga_comp);}
	return (i32)(1);
}

unsafe fn stbi__tga_test(s:*mut stbi__context) -> i32 {
	let res:i32 = (i32)(0);
	let sz:i32;let tga_color_type:i32;
	stbi__get8(s);
	tga_color_type = (i32)(stbi__get8(s));
	if tga_color_type > 1 {goto errorEnd;}
	sz = (i32)(stbi__get8(s));
	if tga_color_type == 1 {
if sz != 1 && sz != 9 {goto errorEnd;}stbi__skip(s, 4);sz = (i32)(stbi__get8(s));if sz != 8 && sz != 15 && sz != 16 && sz != 24 && sz != 32 {goto errorEnd;}stbi__skip(s, 4);} else {
if sz != 2 && sz != 3 && sz != 10 && sz != 11 {goto errorEnd;}stbi__skip(s, 9);}
	if stbi__get16le(s) < 1 {goto errorEnd;}
	if stbi__get16le(s) < 1 {goto errorEnd;}
	sz = (i32)(stbi__get8(s));
	if tga_color_type == 1 && sz != 8 && sz != 16 {goto errorEnd;}
	if sz != 8 && sz != 15 && sz != 16 && sz != 24 && sz != 32 {goto errorEnd;}
	res = (i32)(1);
	errorEnd:;
stbi__rewind(s);
	return (i32)(res);
}

unsafe fn stbi__tga_read_rgb16(s:*mut stbi__context, _out_:*mut u8){
	let px:ushort = (ushort)(stbi__get16le(s));
	let fiveBitMask:ushort = (ushort)(31);
	let r:i32 = (i32)(px >> 10 & fiveBitMask);
	let g:i32 = (i32)(px >> 5 & fiveBitMask);
	let b:i32 = (i32)(px & fiveBitMask);
	_out_[0] = (u8)(r * 255 / 31);
	_out_[1] = (u8)(g * 255 / 31);
	_out_[2] = (u8)(b * 255 / 31);
}

unsafe fn stbi__tga_load(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32, ri:*mut stbi__result_info) -> *mut u8 {
	let tga_offset:i32 = (i32)(stbi__get8(s));
	let tga_indexed:i32 = (i32)(stbi__get8(s));
	let tga_image_type:i32 = (i32)(stbi__get8(s));
	let tga_is_RLE:i32 = (i32)(0);
	let tga_palette_start:i32 = (i32)(stbi__get16le(s));
	let tga_palette_len:i32 = (i32)(stbi__get16le(s));
	let tga_palette_bits:i32 = (i32)(stbi__get8(s));
	let tga_x_origin:i32 = (i32)(stbi__get16le(s));
	let tga_y_origin:i32 = (i32)(stbi__get16le(s));
	let tga_width:i32 = (i32)(stbi__get16le(s));
	let tga_height:i32 = (i32)(stbi__get16le(s));
	let tga_bits_per_pixel:i32 = (i32)(stbi__get8(s));
	let tga_comp:i32;let tga_rgb16:i32 = (i32)(0);
	let tga_inverted:i32 = (i32)(stbi__get8(s));
	let tga_data:*mut u8;
	let tga_palette:*mut u8 = (*u8)(0);
	let i:i32;let j:i32;
	let raw_data:[u8;4] = stackalloc u8[4];
raw_data[0] = (u8)(0);

	let RLE_count:i32 = (i32)(0);
	let RLE_repeating:i32 = (i32)(0);
	let read_next_pixel:i32 = (i32)(1);
	if tga_image_type >= 8 {
tga_image_type -= (i32)(8);tga_is_RLE = (i32)(1);}
	tga_inverted = (i32)(1 - tga_inverted >> 5 & 1);
	if tga_indexed {tga_comp = (i32)(stbi__tga_get_comp(tga_palette_bits, 0, tga_rgb16));} else {tga_comp = (i32)(stbi__tga_get_comp(tga_bits_per_pixel, tga_image_type == 3, tga_rgb16));}
	if !tga_comp {return stbi__err("bad format".as_mut_ptr());}
	x = (i32)(tga_width);
	y = (i32)(tga_height);
	if comp {comp = (i32)(tga_comp);}
	if !stbi__mad3sizes_valid(tga_width, tga_height, tga_comp, 0) {return stbi__err("too large".as_mut_ptr());}
	tga_data = stbi__malloc_mad3(tga_width, tga_height, tga_comp, 0);
	if !tga_data {return stbi__err("outofmem".as_mut_ptr());}
	stbi__skip(s, tga_offset);
	if !tga_indexed && !tga_is_RLE && !tga_rgb16 {
i = (i32)(0);
while (i < tga_height) {
i += 1;
{
let row:i32 = (i32)(if tga_inverted{tga_height - i - 1} else {i});let tga_row:*mut u8 = tga_data[row * tga_width * tga_comp];stbi__getn(s, tga_row, tga_width * tga_comp);}
}} else {
if tga_indexed {
stbi__skip(s, tga_palette_start);tga_palette = stbi__malloc_mad2(tga_palette_len, tga_comp, 0);if !tga_palette {
CRuntime.free(tga_data);return stbi__err("outofmem".as_mut_ptr());}if tga_rgb16 {
let pal_entry:*mut u8 = tga_palette;i = (i32)(0);
while (i < tga_palette_len) {
i += 1;
{
stbi__tga_read_rgb16(s, pal_entry);pal_entry += tga_comp;}
}} else {if !stbi__getn(s, tga_palette, tga_palette_len * tga_comp) {
CRuntime.free(tga_data);CRuntime.free(tga_palette);return stbi__err("bad palette".as_mut_ptr());}}}i = (i32)(0);
while (i < tga_width * tga_height) {
i += 1;
{
if tga_is_RLE {
if RLE_count == 0 {
let RLE_cmd:i32 = (i32)(stbi__get8(s));RLE_count = (i32)(1 + RLE_cmd & 127);RLE_repeating = (i32)(RLE_cmd >> 7);read_next_pixel = (i32)(1);} else {if !RLE_repeating {
read_next_pixel = (i32)(1);}}} else {
read_next_pixel = (i32)(1);}if read_next_pixel {
if tga_indexed {
let pal_idx:i32 = (i32)(if tga_bits_per_pixel == 8{stbi__get8(s)} else {stbi__get16le(s)});if pal_idx >= tga_palette_len {
pal_idx = (i32)(0);}pal_idx *= (i32)(tga_comp);j = (i32)(0);
while (j < tga_comp) {
j += 1;
{
raw_data.as_mut_ptr()[j] = (u8)(tga_palette[pal_idx + j]);}
}} else {if tga_rgb16 {
stbi__tga_read_rgb16(s, raw_data.as_mut_ptr());} else {
j = (i32)(0);
while (j < tga_comp) {
j += 1;
{
raw_data.as_mut_ptr()[j] = (u8)(stbi__get8(s));}
}}}read_next_pixel = (i32)(0);}j = (i32)(0);
while (j < tga_comp) {
j += 1;
tga_data[i * tga_comp + j] = (u8)(raw_data.as_mut_ptr()[j]);}RLE_count -= 1;}
}if tga_inverted {
j = (i32)(0);
while (j * 2 < tga_height) {
j += 1;
{
let index1:i32 = (i32)(j * tga_width * tga_comp);let index2:i32 = (i32)(tga_height - 1 - j * tga_width * tga_comp);i = (i32)(tga_width * tga_comp);
while (i > 0) {
i -= 1;
{
let temp:u8 = (u8)(tga_data[index1]);tga_data[index1] = (u8)(tga_data[index2]);tga_data[index2] = (u8)(temp);index1 += 1;index2 += 1;}
}}
}}if tga_palette != (*u8)(0) {
CRuntime.free(tga_palette);}}
	if tga_comp >= 3 && !tga_rgb16 {
let tga_pixel:*mut u8 = tga_data;i = (i32)(0);
while (i < tga_width * tga_height) {
i += 1;
{
let temp:u8 = (u8)(tga_pixel[0]);tga_pixel[0] = (u8)(tga_pixel[2]);tga_pixel[2] = (u8)(temp);tga_pixel += tga_comp;}
}}
	if req_comp && req_comp != tga_comp {tga_data = stbi__convert_format(tga_data, tga_comp, req_comp, tga_width, tga_height);}
	tga_palette_start = (i32)(tga_palette_len = (i32)(tga_palette_bits = (i32)(tga_x_origin = (i32)(tga_y_origin = (i32)(0)))));
	return tga_data;
}

unsafe fn stbi__psd_test(s:*mut stbi__context) -> i32 {
	let r:i32 = (i32)(stbi__get32be(s) == 0x38425053);
	stbi__rewind(s);
	return (i32)(r);
}

unsafe fn stbi__psd_decode_rle(s:*mut stbi__context, p:*mut u8, pixelCount:i32) -> i32 {
	let count:i32;let nleft:i32;let len:i32;
	count = (i32)(0);
	while (nleft = (i32)(pixelCount - count) > 0) {
len = (i32)(stbi__get8(s));if len == 128 {
} else {if len < 128 {
len += 1;if len > nleft {return (i32)(0);}count += (i32)(len);while (len) {
p = (u8)(stbi__get8(s));p += 4;len -= 1;}} else {if len > 128 {
let val:u8;len = (i32)(257 - len);if len > nleft {return (i32)(0);}val = (u8)(stbi__get8(s));count += (i32)(len);while (len) {
p = (u8)(val);p += 4;len -= 1;}}}}}
	return (i32)(1);
}

unsafe fn stbi__psd_load(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32, ri:*mut stbi__result_info, bpc:i32) -> *mut u8 {
	let pixelCount:i32;
	let channelCount:i32;let compression:i32;
	let channel:i32;let i:i32;
	let bitdepth:i32;
	let w:i32;let h:i32;
	let _out_:*mut u8;
	if stbi__get32be(s) != 0x38425053 {return stbi__err("not PSD".as_mut_ptr());}
	if stbi__get16be(s) != 1 {return stbi__err("wrong version".as_mut_ptr());}
	stbi__skip(s, 6);
	channelCount = (i32)(stbi__get16be(s));
	if channelCount < 0 || channelCount > 16 {return stbi__err("wrong channel count".as_mut_ptr());}
	h = (i32)(stbi__get32be(s));
	w = (i32)(stbi__get32be(s));
	bitdepth = (i32)(stbi__get16be(s));
	if bitdepth != 8 && bitdepth != 16 {return stbi__err("unsupported bit depth".as_mut_ptr());}
	if stbi__get16be(s) != 3 {return stbi__err("wrong color format".as_mut_ptr());}
	stbi__skip(s, stbi__get32be(s));
	stbi__skip(s, stbi__get32be(s));
	stbi__skip(s, stbi__get32be(s));
	compression = (i32)(stbi__get16be(s));
	if compression > 1 {return stbi__err("bad compression".as_mut_ptr());}
	if !stbi__mad3sizes_valid(4, w, h, 0) {return stbi__err("too large".as_mut_ptr());}
	if !compression && bitdepth == 16 && bpc == 16 {
_out_ = stbi__malloc_mad3(8, w, h, 0);ri.bits_per_channel = (i32)(16);} else {_out_ = stbi__malloc(4 * w * h);}
	if !_out_ {return stbi__err("outofmem".as_mut_ptr());}
	pixelCount = (i32)(w * h);
	if compression {
stbi__skip(s, h * channelCount * 2);channel = (i32)(0);
while (channel < 4) {
channel += 1;
{
let p:*mut u8;p = _out_[channel];if channel >= channelCount {
i = (i32)(0);
while (i < pixelCount) {
i += 1 , p += 4;
p = (u8)(if channel == 3{255} else {0});}} else {
if !stbi__psd_decode_rle(s, p, pixelCount) {
CRuntime.free(_out_);return stbi__err("corrupt".as_mut_ptr());}}}
}} else {
channel = (i32)(0);
while (channel < 4) {
channel += 1;
{
if channel >= channelCount {
if bitdepth == 16 && bpc == 16 {
let q:*mut ushort = (*ushort)(_out_)[channel];let val:ushort = (ushort)(if channel == 3{65535} else {0});i = (i32)(0);
while (i < pixelCount) {
i += 1 , q += 4;
q = (ushort)(val);}} else {
let p:*mut u8 = _out_[channel];let val:u8 = (u8)(if channel == 3{255} else {0});i = (i32)(0);
while (i < pixelCount) {
i += 1 , p += 4;
p = (u8)(val);}}} else {
if ri.bits_per_channel == 16 {
let q:*mut ushort = (*ushort)(_out_)[channel];i = (i32)(0);
while (i < pixelCount) {
i += 1 , q += 4;
q = (ushort)(stbi__get16be(s));}} else {
let p:*mut u8 = _out_[channel];if bitdepth == 16 {
i = (i32)(0);
while (i < pixelCount) {
i += 1 , p += 4;
p = (u8)(stbi__get16be(s) >> 8);}} else {
i = (i32)(0);
while (i < pixelCount) {
i += 1 , p += 4;
p = (u8)(stbi__get8(s));}}}}}
}}
	if channelCount >= 4 {
if ri.bits_per_channel == 16 {
i = (i32)(0);
while (i < w * h) {
i += 1;
{
let pixel:*mut ushort = (*ushort)(_out_)[4 * i];if pixel[3] != 0 && pixel[3] != 65535 {
let a:f32 = (f32)(pixel[3] / 65535.0f32);let ra:f32 = (f32)(1.0f32 / a);let inv_a:f32 = (f32)(65535.0f32 * 1 - ra);pixel[0] = (ushort)(pixel[0] * ra + inv_a);pixel[1] = (ushort)(pixel[1] * ra + inv_a);pixel[2] = (ushort)(pixel[2] * ra + inv_a);}}
}} else {
i = (i32)(0);
while (i < w * h) {
i += 1;
{
let pixel:*mut u8 = _out_[4 * i];if pixel[3] != 0 && pixel[3] != 255 {
let a:f32 = (f32)(pixel[3] / 255.0f32);let ra:f32 = (f32)(1.0f32 / a);let inv_a:f32 = (f32)(255.0f32 * 1 - ra);pixel[0] = (u8)(pixel[0] * ra + inv_a);pixel[1] = (u8)(pixel[1] * ra + inv_a);pixel[2] = (u8)(pixel[2] * ra + inv_a);}}
}}}
	if req_comp && req_comp != 4 {
if ri.bits_per_channel == 16 {_out_ = (*u8)(stbi__convert_format16((*ushort)(_out_), 4, req_comp, w, h));} else {_out_ = stbi__convert_format(_out_, 4, req_comp, w, h);}if _out_ == (*u8)(0) {return _out_;}}
	if comp {comp = (i32)(4);}
	y = (i32)(h);
	x = (i32)(w);
	return _out_;
}

unsafe fn stbi__gif_test_raw(s:*mut stbi__context) -> i32 {
	let sz:i32;
	if stbi__get8(s) != 'G' || stbi__get8(s) != 'I' || stbi__get8(s) != 'F' || stbi__get8(s) != '8' {return (i32)(0);}
	sz = (i32)(stbi__get8(s));
	if sz != '9' && sz != '7' {return (i32)(0);}
	if stbi__get8(s) != 'a' {return (i32)(0);}
	return (i32)(1);
}

unsafe fn stbi__gif_test(s:*mut stbi__context) -> i32 {
	let r:i32 = (i32)(stbi__gif_test_raw(s));
	stbi__rewind(s);
	return (i32)(r);
}

unsafe fn stbi__gif_parse_colortable(s:*mut stbi__context, pal:[[u8;4];256], num_entries:i32, transp:i32){
	let i:i32;
	i = (i32)(0);
while (i < num_entries) {
i += 1;
{
pal.as_mut_ptr()[i].as_mut_ptr()[2] = (u8)(stbi__get8(s));pal.as_mut_ptr()[i].as_mut_ptr()[1] = (u8)(stbi__get8(s));pal.as_mut_ptr()[i].as_mut_ptr()[0] = (u8)(stbi__get8(s));pal.as_mut_ptr()[i].as_mut_ptr()[3] = (u8)(if transp == i{0} else {255});}
}
}

unsafe fn stbi__gif_header(s:*mut stbi__context, g:*mut stbi__gif, comp:*mut i32, is_info:i32) -> i32 {
	let version:u8;
	if stbi__get8(s) != 'G' || stbi__get8(s) != 'I' || stbi__get8(s) != 'F' || stbi__get8(s) != '8' {return (i32)(stbi__err("not GIF".as_mut_ptr()));}
	version = (u8)(stbi__get8(s));
	if version != '7' && version != '9' {return (i32)(stbi__err("not GIF".as_mut_ptr()));}
	if stbi__get8(s) != 'a' {return (i32)(stbi__err("not GIF".as_mut_ptr()));}
	stbi__g_failure_reason = "".as_mut_ptr();
	g.w = (i32)(stbi__get16le(s));
	g.h = (i32)(stbi__get16le(s));
	g.flags = (i32)(stbi__get8(s));
	g.bgindex = (i32)(stbi__get8(s));
	g.ratio = (i32)(stbi__get8(s));
	g.transparent = (i32)(-1);
	if comp != null {comp = (i32)(4);}
	if is_info {return (i32)(1);}
	if g.flags & 0x80 {stbi__gif_parse_colortable(s, g.pal.as_mut_ptr(), 2 << g.flags & 7, -1);}
	return (i32)(1);
}

unsafe fn stbi__gif_info_raw(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	let g:*mut stbi__gif = (*stbi__gif)(stbi__malloc(sizeof(stbi__gif)));
	if !stbi__gif_header(s, g, comp, 1) {
stbi__rewind(s);return (i32)(0);}
	if x {x = (i32)(g.w);}
	if y {y = (i32)(g.h);}
	
	return (i32)(1);
}

unsafe fn stbi__out_gif_code(g:*mut stbi__gif, code:ushort){
	let p:*mut u8;let c:*mut u8;
	if g.codes.as_mut_ptr()[code].prefix >= 0 {stbi__out_gif_code(g, g.codes.as_mut_ptr()[code].prefix);}
	if g.cur_y >= g.max_y {return;}
	p = g._out_[g.cur_x + g.cur_y];
	c = g.color_table[g.codes.as_mut_ptr()[code].suffix * 4];
	if c[3] >= 128 {
p[0] = (u8)(c[2]);p[1] = (u8)(c[1]);p[2] = (u8)(c[0]);p[3] = (u8)(c[3]);}
	g.cur_x += (i32)(4);
	if g.cur_x >= g.max_x {
g.cur_x = (i32)(g.start_x);g.cur_y += (i32)(g.step);while (g.cur_y >= g.max_y && g.parse > 0) {
g.step = (i32)(1 << g.parse * g.line_size);g.cur_y = (i32)(g.start_y + g.step >> 1);g.parse -= 1;}}
}

unsafe fn stbi__process_gif_raster(s:*mut stbi__context, g:*mut stbi__gif) -> *mut u8 {
	let lzw_cs:u8;
	let len:i32;let init_code:i32;
	let first:u32;
	let codesize:i32;let codemask:i32;let avail:i32;let oldcode:i32;let bits:i32;let valid_bits:i32;let clear:i32;
	let p:*mut stbi__gif_lzw;
	lzw_cs = (u8)(stbi__get8(s));
	if lzw_cs > 12 {return (*u8)(0);}
	clear = (i32)(1 << lzw_cs);
	first = (u32)(1);
	codesize = (i32)(lzw_cs + 1);
	codemask = (i32)(1 << codesize - 1);
	bits = (i32)(0);
	valid_bits = (i32)(0);
	init_code = (i32)(0);
while (init_code < clear) {
init_code += 1;
{
g.codes.as_mut_ptr()[init_code].prefix = (short)(-1);g.codes.as_mut_ptr()[init_code].first = (u8)(init_code);g.codes.as_mut_ptr()[init_code].suffix = (u8)(init_code);}
}
	avail = (i32)(clear + 2);
	oldcode = (i32)(-1);
	len = (i32)(0);
	;
while () {
;
{
if valid_bits < codesize {
if len == 0 {
len = (i32)(stbi__get8(s));if len == 0 {return g._out_;}}len -= 1;bits |= (i32)((i32)(stbi__get8(s)) << valid_bits);valid_bits += (i32)(8);} else {
let code:i32 = (i32)(bits & codemask);bits >>= codesize;valid_bits -= (i32)(codesize);if code == clear {
codesize = (i32)(lzw_cs + 1);codemask = (i32)(1 << codesize - 1);avail = (i32)(clear + 2);oldcode = (i32)(-1);first = (u32)(0);} else {if code == clear + 1 {
stbi__skip(s, len);while (len = (i32)(stbi__get8(s)) > 0) {stbi__skip(s, len);}return g._out_;} else {if code <= avail {
if first {return stbi__err("no clear code".as_mut_ptr());}if oldcode >= 0 {
p = g.codes.as_mut_ptr()[avail += 1];if avail > 4096 {return stbi__err("too many codes".as_mut_ptr());}p.prefix = (short)(oldcode);p.first = (u8)(g.codes.as_mut_ptr()[oldcode].first);p.suffix = (u8)(if code == avail{p.first} else {g.codes.as_mut_ptr()[code].first});} else {if code == avail {return stbi__err("illegal code in raster".as_mut_ptr());}}stbi__out_gif_code(g, (ushort)(code));if avail & codemask == 0 && avail <= 0x0FFF {
codesize += 1;codemask = (i32)(1 << codesize - 1);}oldcode = (i32)(code);} else {
return stbi__err("illegal code in raster".as_mut_ptr());}}}}}
}
}

unsafe fn stbi__fill_gif_background(g:*mut stbi__gif, x0:i32, y0:i32, x1:i32, y1:i32){
	let x:i32;let y:i32;
	let c:*mut u8 = g.pal.as_mut_ptr()[g.bgindex].as_mut_ptr();
	y = (i32)(y0);
while (y < y1) {
y += (i32)(4 * g.w);
{
x = (i32)(x0);
while (x < x1) {
x += (i32)(4);
{
let p:*mut u8 = g._out_[y + x];p[0] = (u8)(c[2]);p[1] = (u8)(c[1]);p[2] = (u8)(c[0]);p[3] = (u8)(0);}
}}
}
}

unsafe fn stbi__gif_load_next(s:*mut stbi__context, g:*mut stbi__gif, comp:*mut i32, req_comp:i32) -> *mut u8 {
	let i:i32;
	let prev_out:*mut u8 = (*u8)(0);
	if g._out_ == null && !stbi__gif_header(s, g, comp, 0) {return (*u8)(0);}
	if !stbi__mad3sizes_valid(g.w, g.h, 4, 0) {return stbi__err("too large".as_mut_ptr());}
	prev_out = g._out_;
	g._out_ = stbi__malloc_mad3(4, g.w, g.h, 0);
	if g._out_ == null {return stbi__err("outofmem".as_mut_ptr());}
	match g.eflags & 0x1C >> 2{
0 => {stbi__fill_gif_background(g, 0, 0, 4 * g.w, 4 * g.w * g.h)},;1 => {if prev_out {CRuntime.memcpy(g._out_, prev_out, 4 * g.w * g.h);}}g.old_out = prev_out;,;2 => {if prev_out {CRuntime.memcpy(g._out_, prev_out, 4 * g.w * g.h);}}stbi__fill_gif_background(g, g.start_x, g.start_y, g.max_x, g.max_y);,;3 => {if g.old_out {
i = (i32)(g.start_y);
while (i < g.max_y) {
i += (i32)(4 * g.w);
CRuntime.memcpy(g._out_[i + g.start_x], g.old_out[i + g.start_x], g.max_x - g.start_x);}}},;}

	;
while () {
;
{
match stbi__get8(s){
0x2C => {
let prev_trans:i32 = (i32)(-1);let x:i32;let y:i32;let w:i32;let h:i32;let o:*mut u8;x = (i32)(stbi__get16le(s));y = (i32)(stbi__get16le(s));w = (i32)(stbi__get16le(s));h = (i32)(stbi__get16le(s));if x + w > g.w || y + h > g.h {return stbi__err("bad Image Descriptor".as_mut_ptr());}g.line_size = (i32)(g.w * 4);g.start_x = (i32)(x * 4);g.start_y = (i32)(y * g.line_size);g.max_x = (i32)(g.start_x + w * 4);g.max_y = (i32)(g.start_y + h * g.line_size);g.cur_x = (i32)(g.start_x);g.cur_y = (i32)(g.start_y);g.lflags = (i32)(stbi__get8(s));if g.lflags & 0x40 {
g.step = (i32)(8 * g.line_size);g.parse = (i32)(3);} else {
g.step = (i32)(g.line_size);g.parse = (i32)(0);}if g.lflags & 0x80 {
stbi__gif_parse_colortable(s, g.lpal.as_mut_ptr(), 2 << g.lflags & 7, if g.eflags & 0x01{g.transparent} else {-1});g.color_table = (*u8)(g.lpal.as_mut_ptr());} else {if g.flags & 0x80 {
if g.transparent >= 0 && g.eflags & 0x01 {
prev_trans = (i32)(g.pal.as_mut_ptr()[g.transparent].as_mut_ptr()[3]);g.pal.as_mut_ptr()[g.transparent].as_mut_ptr()[3] = (u8)(0);}g.color_table = (*u8)(g.pal.as_mut_ptr());} else {return stbi__err("missing color table".as_mut_ptr());}}o = stbi__process_gif_raster(s, g);if o == (*u8)(0) {return (*u8)(0);}if prev_trans != -1 {g.pal.as_mut_ptr()[g.transparent].as_mut_ptr()[3] = (u8)(prev_trans);}return o;}0x21 => {
let len:i32;if stbi__get8(s) == 0xF9 {
len = (i32)(stbi__get8(s));if len == 4 {
g.eflags = (i32)(stbi__get8(s));g.delay = (i32)(stbi__get16le(s));g.transparent = (i32)(stbi__get8(s));} else {
stbi__skip(s, len);,;}}while (len = (i32)(stbi__get8(s)) != 0) {stbi__skip(s, len);},;}0x3B => {return (*u8)(s)}default: return stbi__err("unknown code".as_mut_ptr());}
}
}
}

unsafe fn stbi__gif_load(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32, req_comp:i32, ri:*mut stbi__result_info) -> *mut u8 {
	let u:*mut u8 = (*u8)(0);
	let g:*mut stbi__gif = (*stbi__gif)(stbi__malloc(sizeof(stbi__gif)));
	CRuntime.memset(g, 0, sizeof(g));
	u = stbi__gif_load_next(s, g, comp, req_comp);
	if u == (*u8)(s) {u = null;}
	if u {
x = (i32)(g.w);y = (i32)(g.h);if req_comp && req_comp != 4 {u = stbi__convert_format(u, 4, req_comp, g.w, g.h);}} else {if g._out_ {CRuntime.free(g._out_);}}
	
	return u;
}

unsafe fn stbi__gif_info(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	return (i32)(stbi__gif_info_raw(s, x, y, comp));
}

unsafe fn stbi__bmp_info(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	let p:*mut u8;
	let info:stbi__bmp_data;
	info.all_a = (u32)(255);
	p = stbi__bmp_parse_header(s, info);
	stbi__rewind(s);
	if p == (*u8)(0) {return (i32)(0);}
	if x {x = (i32)(s.img_x);}
	if y {y = (i32)(s.img_y);}
	if comp {comp = (i32)(if info.ma{4} else {3});}
	return (i32)(1);
}

unsafe fn stbi__psd_info(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	let channelCount:i32;let dummy:i32;
	if !x {x = dummy;}
	if !y {y = dummy;}
	if !comp {comp = dummy;}
	if stbi__get32be(s) != 0x38425053 {
stbi__rewind(s);return (i32)(0);}
	if stbi__get16be(s) != 1 {
stbi__rewind(s);return (i32)(0);}
	stbi__skip(s, 6);
	channelCount = (i32)(stbi__get16be(s));
	if channelCount < 0 || channelCount > 16 {
stbi__rewind(s);return (i32)(0);}
	y = (i32)(stbi__get32be(s));
	x = (i32)(stbi__get32be(s));
	if stbi__get16be(s) != 8 {
stbi__rewind(s);return (i32)(0);}
	if stbi__get16be(s) != 3 {
stbi__rewind(s);return (i32)(0);}
	comp = (i32)(4);
	return (i32)(1);
}

unsafe fn stbi__info_main(s:*mut stbi__context, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	if stbi__jpeg_info(s, x, y, comp) {return (i32)(1);}
	if stbi__png_info(s, x, y, comp) {return (i32)(1);}
	if stbi__gif_info(s, x, y, comp) {return (i32)(1);}
	if stbi__bmp_info(s, x, y, comp) {return (i32)(1);}
	if stbi__psd_info(s, x, y, comp) {return (i32)(1);}
	if stbi__tga_info(s, x, y, comp) {return (i32)(1);}
	return (i32)(stbi__err("unknown image type".as_mut_ptr()));
}

unsafe fn stbi_info_from_memory(buffer:*mut u8, len:i32, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	let s:stbi__context;
	stbi__start_mem(s, buffer, len);
	return (i32)(stbi__info_main(s, x, y, comp));
}

unsafe fn stbi_info_from_callbacks(c:*mut stbi_io_callbacks, user:*mut u8, x:*mut i32, y:*mut i32, comp:*mut i32) -> i32 {
	let s:stbi__context;
	stbi__start_callbacks(s, c, user);
	return (i32)(stbi__info_main(s, x, y, comp));
}

