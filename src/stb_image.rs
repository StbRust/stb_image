// Generated by Ur at 12.08.2018 20:58:53

use std;
use c_runtime;

pub const STBI_default: i32 = 0;
pub const STBI_grey: i32 = 1;
pub const STBI_grey_alpha: i32 = 2;
pub const STBI_rgb: i32 = 3;
pub const STBI_rgb_alpha: i32 = 4;
pub const STBI_ORDER_RGB: i32 = 0;
pub const STBI_ORDER_BGR: i32 = 1;
pub const STBI__SCAN_load: i32 = 0;
pub const STBI__SCAN_type: i32 = 1;
pub const STBI__SCAN_header: i32 = 2;
pub const STBI__F_none: i32 = 0;
pub const STBI__F_sub: i32 = 1;
pub const STBI__F_up: i32 = 2;
pub const STBI__F_avg: i32 = 3;
pub const STBI__F_paeth: i32 = 4;
pub const STBI__F_avg_first: i32 = 5;
pub const STBI__F_paeth_first: i32 = 6;

pub static mut stbi__vertically_flip_on_load: i32 = 0;
pub static mut stbi__h2l_gamma_i: f32 = 1.0f32 / 2.2f32;
pub static mut stbi__h2l_scale_i: f32 = 1.0f32;
pub static mut stbi__zlength_base: [i32; 31] = [3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31, 35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0];
pub static mut stbi__zlength_extra: [i32; 31] = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 0, 0, 0];
pub static mut stbi__zdist_base: [i32; 32] = [1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193, 257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145, 8193, 12289, 16385, 24577, 0, 0];
pub static mut stbi__zdist_extra: [i32; 30] = [0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13];
pub static mut length_dezigzag: [u8; 19] = [((16) as u8), ((17) as u8), ((18) as u8), ((0) as u8), ((8) as u8), ((7) as u8), ((9) as u8), ((6) as u8), ((10) as u8), ((5) as u8), ((11) as u8), ((4) as u8), ((12) as u8), ((3) as u8), ((13) as u8), ((2) as u8), ((14) as u8), ((1) as u8), ((15) as u8)];
pub static mut stbi__zdefault_length: [u8; 288] = [((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8)];
pub static mut stbi__zdefault_distance: [u8; 32] = [((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8)];
pub static mut png_sig: [u8; 8] = [((137) as u8), ((80) as u8), ((78) as u8), ((71) as u8), ((13) as u8), ((10) as u8), ((26) as u8), ((10) as u8)];
pub static mut first_row_filter: [i32; 5] = [STBI__F_none, STBI__F_sub, STBI__F_none, STBI__F_avg_first, STBI__F_paeth_first];
pub static mut stbi__depth_scale_table: [u8; 9] = [((0) as u8), ((0xff) as u8), ((0x55) as u8), ((0) as u8), ((0x11) as u8), ((0) as u8), ((0) as u8), ((0) as u8), ((0x01) as u8)];
pub static mut stbi__unpremultiply_on_load: i32 = 0;
pub static mut stbi__de_iphone_flag: i32 = 0;

pub struct stbi__context {
    img_x: u32,
    img_y: u32,
    img_n: i32,
    img_out_n: i32,
    io: stbi_io_callbacks,
    io_user_data: *mut u8,
    read_from_callbacks: i32,
    buflen: i32,
    buffer_start: [u8; 128],
    img_buffer: *mut u8,
    img_buffer_end: *mut u8,
    img_buffer_original: *mut u8,
    img_buffer_original_end: *mut u8,
}

pub struct stbi__result_info {
    bits_per_channel: i32,
    num_channels: i32,
    channel_order: i32,
}

pub struct stbi__zhuffman {
    fast: [u16; 512],
    firstcode: [u16; 16],
    maxcode: [i32; 17],
    firstsymbol: [u16; 16],
    size: [u8; 288],
    value: [u16; 288],
}

pub struct stbi__zbuf {
    zbuffer: *mut u8,
    zbuffer_end: *mut u8,
    num_bits: i32,
    code_buffer: u32,
    zout: *mut i8,
    zout_start: *mut i8,
    zout_end: *mut i8,
    z_expandable: i32,
    z_length: stbi__zhuffman,
    z_distance: stbi__zhuffman,
}

pub struct stbi__pngchunk {
    length: u32,
    _type_: u32,
}

pub struct stbi__png {
    s: *mut stbi__context,
    idata: *mut u8,
    expanded: *mut u8,
    _out_: *mut u8,
    depth: i32,
}

pub unsafe fn stbi__start_mem(mut s: *mut stbi__context, mut buffer: *mut u8, mut len: i32) {
    (*s).io.read = None;
    (*s).read_from_callbacks = ((0) as i32);
    (*s).img_buffer = buffer;
    (*s).img_buffer_original = buffer;
    (*s).img_buffer_end = (buffer).offset((len) as isize);
    (*s).img_buffer_original_end = (buffer).offset((len) as isize);
}

pub unsafe fn stbi__start_callbacks(mut s: *mut stbi__context, mut c: *mut stbi_io_callbacks, mut user: *mut u8) {
    (*s).io = ((*c) as stbi_io_callbacks);
    (*s).io_user_data = user;
    (*s).buflen = (((*s).buffer_start.len() as i32) as i32);
    (*s).read_from_callbacks = ((1) as i32);
    (*s).img_buffer_original = (*s).buffer_start.as_mut_ptr();
    stbi__refill_buffer(s);
    (*s).img_buffer_original_end = (*s).img_buffer_end;
}

pub unsafe fn stbi__rewind(mut s: *mut stbi__context) {
    (*s).img_buffer = (*s).img_buffer_original;
    (*s).img_buffer_end = (*s).img_buffer_original_end;
}

pub unsafe fn stbi__malloc(mut size: u64) -> *mut u8 {
    return c_runtime::malloc(size);
}

pub unsafe fn stbi__addsizes_valid(mut a: i32, mut b: i32) -> i32 {
    if b < 0 { return 0; }
    return (a <= 2147483647 - b) as i32;
}

pub unsafe fn stbi__mul2sizes_valid(mut a: i32, mut b: i32) -> i32 {
    if a < 0 || b < 0 { return 0; }
    if b == 0 { return 1; }
    return (a <= 2147483647 / b) as i32;
}

pub unsafe fn stbi__mad2sizes_valid(mut a: i32, mut b: i32, mut add: i32) -> i32 {
    return ((stbi__mul2sizes_valid(a, b)) != 0 && (stbi__addsizes_valid(a * b, add)) != 0) as i32;
}

pub unsafe fn stbi__mad3sizes_valid(mut a: i32, mut b: i32, mut c: i32, mut add: i32) -> i32 {
    return ((stbi__mul2sizes_valid(a, b)) != 0 && (stbi__mul2sizes_valid(a * b, c)) != 0 && (stbi__addsizes_valid(a * b * c, add)) != 0) as i32;
}

pub unsafe fn stbi__mad4sizes_valid(mut a: i32, mut b: i32, mut c: i32, mut d: i32, mut add: i32) -> i32 {
    return ((stbi__mul2sizes_valid(a, b)) != 0 && (stbi__mul2sizes_valid(a * b, c)) != 0 && (stbi__mul2sizes_valid(a * b * c, d)) != 0 && (stbi__addsizes_valid(a * b * c * d, add)) != 0) as i32;
}

pub unsafe fn stbi__malloc_mad2(mut a: i32, mut b: i32, mut add: i32) -> *mut u8 {
    if stbi__mad2sizes_valid(a, b, add) == 0 { return (std::ptr::null_mut()); }
    return stbi__malloc((((a * b + add) as u64) as u64));
}

pub unsafe fn stbi__malloc_mad3(mut a: i32, mut b: i32, mut c: i32, mut add: i32) -> *mut u8 {
    if stbi__mad3sizes_valid(a, b, c, add) == 0 { return (std::ptr::null_mut()); }
    return stbi__malloc((((a * b * c + add) as u64) as u64));
}

pub unsafe fn stbi__malloc_mad4(mut a: i32, mut b: i32, mut c: i32, mut d: i32, mut add: i32) -> *mut u8 {
    if stbi__mad4sizes_valid(a, b, c, d, add) == 0 { return (std::ptr::null_mut()); }
    return stbi__malloc((((a * b * c * d + add) as u64) as u64));
}

pub unsafe fn stbi_image_free(mut retval_from_stbi_load: *mut u8) {
    c_runtime::free(retval_from_stbi_load);
}

pub unsafe fn stbi_set_flip_vertically_on_load(mut flag_true_if_should_flip: i32) {
    stbi__vertically_flip_on_load = ((flag_true_if_should_flip) as i32);
}

pub unsafe fn stbi__load_main(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32, mut ri: *mut stbi__result_info, mut bpc: i32) -> *mut u8 {
    (*ri).bits_per_channel = ((8) as i32);
    (*ri).channel_order = ((STBI_ORDER_RGB) as i32);
    (*ri).num_channels = ((0) as i32);
    if (stbi__png_test(s)) != 0 { return stbi__png_load(s, x, y, comp, req_comp, ri); }
    return (if stbi__err("unknown image type") != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
}

pub unsafe fn stbi__convert_16_to_8(mut orig: *mut u16, mut w: i32, mut h: i32, mut channels: i32) -> *mut u8 {
    let mut i: i32 = std::mem::uninitialized();
    let mut img_len: i32 = w * h * channels;
    let mut reduced: *mut u8;
    reduced = stbi__malloc((((img_len) as u64) as u64));
    if reduced == (std::ptr::null_mut()) { return (if stbi__err("outofmem") != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
    i = ((0) as i32);
    while (i < img_len) {
        *reduced.offset((i) as isize) = ((((((*orig.offset((i) as isize)) as i32) >> 8) & 0xFF) as u8) as u8);
        i += 1;
    }
    c_runtime::free(orig);
    return reduced;
}

pub unsafe fn stbi__convert_8_to_16(mut orig: *mut u8, mut w: i32, mut h: i32, mut channels: i32) -> *mut u16 {
    let mut i: i32 = std::mem::uninitialized();
    let mut img_len: i32 = w * h * channels;
    let mut enlarged: *mut u16;
    enlarged = ((stbi__malloc((((img_len * 2) as u64) as u64))) as *mut u16);
    if enlarged == (std::ptr::null_mut()) { return ((if stbi__err("outofmem") != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }) as *mut u16); }
    i = ((0) as i32);
    while (i < img_len) {
        *enlarged.offset((i) as isize) = ((((((*orig.offset((i) as isize)) as i32) << 8) + ((*orig.offset((i) as isize)) as i32)) as u16) as u16);
        i += 1;
    }
    c_runtime::free(orig);
    return enlarged;
}

pub unsafe fn stbi__vertical_flip(mut image: *mut u8, mut w: i32, mut h: i32, mut bytes_per_pixel: i32) {
    let mut row: i32 = std::mem::uninitialized();
    let mut bytes_per_row: u64 = ((w) as u64) * ((bytes_per_pixel) as u64);
    let mut temp: [u8; 2048] = std::mem::uninitialized();
    let mut bytes: *mut u8 = image;
    row = ((0) as i32);
    while (row < (h >> 1)) {
        let mut row0: i32 = ((((row) as u64) * bytes_per_row) as i32);
        let mut row1: i32 = ((((h - row - 1) as u64) * bytes_per_row) as i32);
        let mut bytes_left: u64 = bytes_per_row;
        while ((bytes_left) != 0) {
            let mut bytes_copy: u64 = if (bytes_left < ((2048) as u64)) { bytes_left } else { ((2048) as u64) };
            c_runtime::memcpy(temp.as_mut_ptr(), (bytes).offset((row0) as isize), bytes_copy);
            c_runtime::memcpy((bytes).offset((row0) as isize), (bytes).offset((row1) as isize), bytes_copy);
            c_runtime::memcpy((bytes).offset((row1) as isize), temp.as_mut_ptr(), bytes_copy);
            row0 += ((bytes_copy) as i32);
            row1 += ((bytes_copy) as i32);
            bytes_left -= ((bytes_copy) as u64);
        }
        row += 1;
    }
}

pub unsafe fn stbi__load_and_postprocess_8bit(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32) -> *mut u8 {
    let mut ri: stbi__result_info = std::mem::uninitialized();
    let mut result: *mut u8 = stbi__load_main(s, x, y, comp, req_comp, ((&mut ri) as *mut stbi__result_info), 8);
    if result == (std::ptr::null_mut()) { return (std::ptr::null_mut()); }
    if ri.bits_per_channel != 8 {
        let mut cmp: i32 = req_comp;
        if cmp == 0 { cmp = ((*comp) as i32); }
        result = stbi__convert_16_to_8((((result) as *mut u16) as *mut u16), *x, *y, cmp);
        ri.bits_per_channel = ((8) as i32);
    }
    if (stbi__vertically_flip_on_load) != 0 {
        let mut channels: i32 = if (req_comp) != 0 { req_comp } else { *comp };
        stbi__vertical_flip(result, *x, *y, channels);
    }
    return result;
}

pub unsafe fn stbi__load_and_postprocess_16bit(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32) -> *mut u16 {
    let mut ri: stbi__result_info = std::mem::uninitialized();
    let mut result: *mut u8 = stbi__load_main(s, x, y, comp, req_comp, ((&mut ri) as *mut stbi__result_info), 16);
    if result == (std::ptr::null_mut()) { return (std::ptr::null_mut()); }
    if ri.bits_per_channel != 16 {
        let mut cmp: i32 = req_comp;
        if cmp == 0 { cmp = ((*comp) as i32); }
        result = stbi__convert_8_to_16(((result) as *mut u8), *x, *y, cmp) as *mut u8;
        ri.bits_per_channel = ((16) as i32);
    }
    if (stbi__vertically_flip_on_load) != 0 {
        let mut channels: i32 = if (req_comp) != 0 { req_comp } else { *comp };
        stbi__vertical_flip(result, *x, *y, channels * 2);
    }
    return ((result) as *mut u16);
}

pub unsafe fn stbi_load_16_from_memory(mut buffer: *mut u8, mut len: i32, mut x: *mut i32, mut y: *mut i32, mut channels_in_file: *mut i32, mut desired_channels: i32) -> *mut u16 {
    let mut s: stbi__context = std::mem::uninitialized();
    stbi__start_mem(((&mut s) as *mut stbi__context), buffer, len);
    return stbi__load_and_postprocess_16bit(((&mut s) as *mut stbi__context), x, y, channels_in_file, desired_channels);
}

pub unsafe fn stbi_load_16_from_callbacks(mut clbk: *mut stbi_io_callbacks, mut user: *mut u8, mut x: *mut i32, mut y: *mut i32, mut channels_in_file: *mut i32, mut desired_channels: i32) -> *mut u16 {
    let mut s: stbi__context = std::mem::uninitialized();
    stbi__start_callbacks(((&mut s) as *mut stbi__context), ((clbk) as *mut stbi_io_callbacks), user);
    return stbi__load_and_postprocess_16bit(((&mut s) as *mut stbi__context), x, y, channels_in_file, desired_channels);
}

pub unsafe fn stbi_load_from_memory(mut buffer: *mut u8, mut len: i32, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32) -> *mut u8 {
    let mut s: stbi__context = std::mem::uninitialized();
    stbi__start_mem(((&mut s) as *mut stbi__context), buffer, len);
    return stbi__load_and_postprocess_8bit(((&mut s) as *mut stbi__context), x, y, comp, req_comp);
}

pub unsafe fn stbi_load_from_callbacks(mut clbk: *mut stbi_io_callbacks, mut user: *mut u8, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32) -> *mut u8 {
    let mut s: stbi__context = std::mem::uninitialized();
    stbi__start_callbacks(((&mut s) as *mut stbi__context), ((clbk) as *mut stbi_io_callbacks), user);
    return stbi__load_and_postprocess_8bit(((&mut s) as *mut stbi__context), x, y, comp, req_comp);
}

pub unsafe fn stbi_is_hdr_from_memory(mut buffer: *mut u8, mut len: i32) -> i32 {
    return 0;
}

pub unsafe fn stbi_is_hdr_from_callbacks(mut clbk: *mut stbi_io_callbacks, mut user: *mut u8) -> i32 {
    return 0;
}

pub unsafe fn stbi_hdr_to_ldr_gamma(mut gamma: f32) {
    stbi__h2l_gamma_i = ((((1) as f32) / gamma) as f32);
}

pub unsafe fn stbi_hdr_to_ldr_scale(mut scale: f32) {
    stbi__h2l_scale_i = ((((1) as f32) / scale) as f32);
}

pub unsafe fn stbi__refill_buffer(mut s: *mut stbi__context) {
    let mut n: i32 = ((*s).io.read.unwrap())((*s).io_user_data, ((((*s).buffer_start.as_mut_ptr()) as *mut i8) as *mut i8), (*s).buflen);
    if n == 0 {
        (*s).read_from_callbacks = ((0) as i32);
        (*s).img_buffer = (*s).buffer_start.as_mut_ptr();
        (*s).img_buffer_end = ((*s).buffer_start.as_mut_ptr()).offset((1) as isize);
        *(*s).img_buffer = (((0) as u8) as u8);
    } else {
        (*s).img_buffer = (*s).buffer_start.as_mut_ptr();
        (*s).img_buffer_end = ((*s).buffer_start.as_mut_ptr()).offset((n) as isize);
    }
}

pub unsafe fn stbi__get8(mut s: *mut stbi__context) -> u8 {
    if (*s).img_buffer < (*s).img_buffer_end {
        let mut res: u8 = *(*s).img_buffer;
        ((*s).img_buffer = (*s).img_buffer.offset(1));
        return res;
    }
    if ((*s).read_from_callbacks) != 0 {
        stbi__refill_buffer(s);
        let mut res: u8 = *(*s).img_buffer;
        ((*s).img_buffer = (*s).img_buffer.offset(1));
        return res;
    }
    return ((0) as u8);
}

pub unsafe fn stbi__at_eof(mut s: *mut stbi__context) -> i32 {
    if ((*s).io.read.is_some()) {
        if ((*s).io.eof)((*s).io_user_data) == 0 { return 0; }
        if (*s).read_from_callbacks == 0 { return 1; }
    }
    return ((*s).img_buffer >= (*s).img_buffer_end) as i32;
}

pub unsafe fn stbi__skip(mut s: *mut stbi__context, mut n: i32) {
    if n < 0 {
        (*s).img_buffer = (*s).img_buffer_end;
        return;
    }
    if ((*s).io.read.is_some()) {
        let mut blen: i32 = (((((*s).img_buffer_end) as usize) - (((*s).img_buffer) as usize)) as i32);
        if blen < n {
            (*s).img_buffer = (*s).img_buffer_end;
            ((*s).io.skip)((*s).io_user_data, n - blen);
            return;
        }
    }
    (*s).img_buffer = (*s).img_buffer.offset((((n) as *mut u8)) as isize);
}

pub unsafe fn stbi__getn(mut s: *mut stbi__context, mut buffer: *mut u8, mut n: i32) -> i32 {
    if ((*s).io.read.is_some()) {
        let mut blen: i32 = (((((*s).img_buffer_end) as usize) - (((*s).img_buffer) as usize)) as i32);
        if blen < n {
            let mut res: i32 = std::mem::uninitialized();
            let mut count: i32 = std::mem::uninitialized();
            c_runtime::memcpy(buffer, (*s).img_buffer, (((blen) as u64) as u64));
            count = ((((*s).io.read.unwrap())((*s).io_user_data, (((buffer) as *mut i8)).offset((blen) as isize), n - blen)) as i32);
            res = ((count == (n - blen)) as i32);
            (*s).img_buffer = (*s).img_buffer_end;
            return res;
        }
    }
    if ((*s).img_buffer).offset((n) as isize) <= (*s).img_buffer_end {
        c_runtime::memcpy(buffer, (*s).img_buffer, (((n) as u64) as u64));
        (*s).img_buffer = (*s).img_buffer.offset((((n) as *mut u8)) as isize);
        return 1;
    } else { return 0; }
}

pub unsafe fn stbi__get16be(mut s: *mut stbi__context) -> i32 {
    let mut z: i32 = ((stbi__get8(s)) as i32);
    return (z << 8) + ((stbi__get8(s)) as i32);
}

pub unsafe fn stbi__get32be(mut s: *mut stbi__context) -> u32 {
    let mut z: u32 = ((stbi__get16be(s)) as u32);
    return (z << 16) + ((stbi__get16be(s)) as u32);
}

pub unsafe fn stbi__compute_y(mut r: i32, mut g: i32, mut b: i32) -> u8 {
    return ((((r * 77) + (g * 150) + (29 * b)) >> 8) as u8);
}

pub unsafe fn stbi__convert_format(mut data: *mut u8, mut img_n: i32, mut req_comp: i32, mut x: u32, mut y: u32) -> *mut u8 {
    let mut i: i32 = std::mem::uninitialized();
    let mut j: i32 = std::mem::uninitialized();
    let mut good: *mut u8;
    if req_comp == img_n { return data; }
    good = stbi__malloc_mad3(req_comp, (((x) as i32) as i32), (((y) as i32) as i32), 0);
    if good == (std::ptr::null_mut()) {
        c_runtime::free(data);
        return (if stbi__err("outofmem") != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
    }
    j = ((0) as i32);
    while (j < ((y) as i32)) {
        let mut src: i32 = ((((j) as u32) * x * ((img_n) as u32)) as i32);
        let mut dest: i32 = ((((j) as u32) * x * ((req_comp) as u32)) as i32);
        {
            if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (2)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u8);
                    *good.offset((dest + 1) as isize) = (((255) as u8) as u8);
                    i -= 1;
                    src += ((1) as i32);
                    dest += ((2) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (3)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 1) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 2) as isize) = *data.offset((src) as isize);
                    i -= 1;
                    src += ((1) as i32);
                    dest += ((3) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (4)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 1) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 2) as isize) = *data.offset((src) as isize);
                    i -= 1;
                    src += ((1) as i32);
                    dest += ((4) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (1)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u8);
                    i -= 1;
                    src += ((2) as i32);
                    dest += ((1) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (3)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 1) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 2) as isize) = *data.offset((src) as isize);
                    i -= 1;
                    src += ((2) as i32);
                    dest += ((3) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (4)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 1) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 2) as isize) = *data.offset((src) as isize);
                    i -= 1;
                    src += ((2) as i32);
                    dest += ((4) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (4)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u8);
                    *good.offset((dest + 1) as isize) = ((*data.offset((src + 1) as isize)) as u8);
                    *good.offset((dest + 2) as isize) = ((*data.offset((src + 2) as isize)) as u8);
                    i -= 1;
                    src += ((3) as i32);
                    dest += ((4) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (1)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((stbi__compute_y((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u8);
                    i -= 1;
                    src += ((3) as i32);
                    dest += ((1) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (2)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((stbi__compute_y((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u8);
                    *good.offset((dest + 1) as isize) = (((255) as u8) as u8);
                    i -= 1;
                    src += ((3) as i32);
                    dest += ((2) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (1)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((stbi__compute_y((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u8);
                    i -= 1;
                    src += ((4) as i32);
                    dest += ((1) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (2)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((stbi__compute_y((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u8);
                    i -= 1;
                    src += ((4) as i32);
                    dest += ((2) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (3)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u8);
                    *good.offset((dest + 1) as isize) = ((*data.offset((src + 1) as isize)) as u8);
                    *good.offset((dest + 2) as isize) = ((*data.offset((src + 2) as isize)) as u8);
                    i -= 1;
                    src += ((4) as i32);
                    dest += ((3) as i32);
                }
            } else { return (if stbi__err("0") != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
        }
        j += 1;
    }
    c_runtime::free(data);
    return good;
}

pub unsafe fn stbi__compute_y_16(mut r: i32, mut g: i32, mut b: i32) -> u16 {
    return ((((r * 77) + (g * 150) + (29 * b)) >> 8) as u16);
}

pub unsafe fn stbi__convert_format16(mut data: *mut u16, mut img_n: i32, mut req_comp: i32, mut x: u32, mut y: u32) -> *mut u16 {
    let mut i: i32 = std::mem::uninitialized();
    let mut j: i32 = std::mem::uninitialized();
    let mut good: *mut u16;
    if req_comp == img_n { return data; }
    good = ((stbi__malloc((((((req_comp) as u32) * x * y * ((2) as u32)) as u64) as u64))) as *mut u16);
    if good == (std::ptr::null_mut()) {
        c_runtime::free(data);
        return ((if stbi__err("outofmem") != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }) as *mut u16);
    }
    j = ((0) as i32);
    while (j < ((y) as i32)) {
        let mut src: i32 = ((((j) as u32) * x * ((img_n) as u32)) as i32);
        let mut dest: i32 = ((((j) as u32) * x * ((req_comp) as u32)) as i32);
        {
            if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (2)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u16);
                    *good.offset((dest + 1) as isize) = (((0xffff) as u16) as u16);
                    i -= 1;
                    src += ((1) as i32);
                    dest += ((2) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (3)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 1) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 2) as isize) = *data.offset((src) as isize);
                    i -= 1;
                    src += ((1) as i32);
                    dest += ((3) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (4)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 1) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 2) as isize) = *data.offset((src) as isize);
                    i -= 1;
                    src += ((1) as i32);
                    dest += ((4) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (1)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u16);
                    i -= 1;
                    src += ((2) as i32);
                    dest += ((1) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (3)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 1) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 2) as isize) = *data.offset((src) as isize);
                    i -= 1;
                    src += ((2) as i32);
                    dest += ((3) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (4)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 1) as isize) = *data.offset((src) as isize);
                    *good.offset((dest + 2) as isize) = *data.offset((src) as isize);
                    i -= 1;
                    src += ((2) as i32);
                    dest += ((4) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (4)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u16);
                    *good.offset((dest + 1) as isize) = ((*data.offset((src + 1) as isize)) as u16);
                    *good.offset((dest + 2) as isize) = ((*data.offset((src + 2) as isize)) as u16);
                    i -= 1;
                    src += ((3) as i32);
                    dest += ((4) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (1)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((stbi__compute_y_16((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u16);
                    i -= 1;
                    src += ((3) as i32);
                    dest += ((1) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (2)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((stbi__compute_y_16((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u16);
                    *good.offset((dest + 1) as isize) = (((0xffff) as u16) as u16);
                    i -= 1;
                    src += ((3) as i32);
                    dest += ((2) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (1)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((stbi__compute_y_16((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u16);
                    i -= 1;
                    src += ((4) as i32);
                    dest += ((1) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (2)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((stbi__compute_y_16((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u16);
                    i -= 1;
                    src += ((4) as i32);
                    dest += ((2) as i32);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (3)) {
                i = (((x - ((1) as u32)) as i32) as i32);
                while (i >= 0) {
                    *good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u16);
                    *good.offset((dest + 1) as isize) = ((*data.offset((src + 1) as isize)) as u16);
                    *good.offset((dest + 2) as isize) = ((*data.offset((src + 2) as isize)) as u16);
                    i -= 1;
                    src += ((4) as i32);
                    dest += ((3) as i32);
                }
            } else { return ((if stbi__err("0") != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }) as *mut u16); }
        }
        j += 1;
    }
    c_runtime::free(data);
    return good;
}

pub unsafe fn stbi__bitreverse16(mut n: i32) -> i32 {
    n = ((((n & 0xAAAA) >> 1) | ((n & 0x5555) << 1)) as i32);
    n = ((((n & 0xCCCC) >> 2) | ((n & 0x3333) << 2)) as i32);
    n = ((((n & 0xF0F0) >> 4) | ((n & 0x0F0F) << 4)) as i32);
    n = ((((n & 0xFF00) >> 8) | ((n & 0x00FF) << 8)) as i32);
    return n;
}

pub unsafe fn stbi__bit_reverse(mut v: i32, mut bits: i32) -> i32 {
    return (stbi__bitreverse16(v) >> (16 - bits));
}

pub unsafe fn stbi__zbuild_huffman(mut z: *mut stbi__zhuffman, mut sizelist: *mut u8, mut num: i32) -> i32 {
    let mut i: i32 = std::mem::uninitialized();
    let mut k: i32 = 0;
    let mut code: i32 = std::mem::uninitialized();
    let mut next_code: [i32; 16] = std::mem::uninitialized();
    let mut sizes: [i32; 17] = std::mem::uninitialized();
    c_runtime::memset(((sizes.as_mut_ptr()) as *mut u8), 0, ((sizes.len() * std::mem::size_of::<i32>()) as u64));
    c_runtime::memset((((*z).fast.as_mut_ptr()) as *mut u8), 0, (((*z).fast.len() * std::mem::size_of::<u16>()) as u64));
    i = ((0) as i32);
    while (i < num) {
        sizes[(*sizelist.offset((i) as isize)) as usize] += 1;
        i += 1;
    }
    sizes[(0) as usize] = ((0) as i32);
    i = ((1) as i32);
    while (i < 16) {
        if sizes[(i) as usize] > (1 << i) { return stbi__err("bad sizes"); }
        i += 1;
    }
    code = ((0) as i32);
    i = ((1) as i32);
    while (i < 16) {
        next_code[(i) as usize] = ((code) as i32);
        (*z).firstcode[(i) as usize] = (((code) as u16) as u16);
        (*z).firstsymbol[(i) as usize] = (((k) as u16) as u16);
        code = ((code + sizes[(i) as usize]) as i32);
        if (sizes[(i) as usize]) != 0 { if code - 1 >= (1 << i) { return stbi__err("bad codelengths"); } }
        (*z).maxcode[(i) as usize] = ((code << (16 - i)) as i32);
        code <<= 1;
        k += ((sizes[(i) as usize]) as i32);
        i += 1;
    }
    (*z).maxcode[(16) as usize] = ((0x10000) as i32);
    i = ((0) as i32);
    while (i < num) {
        let mut s: i32 = ((*sizelist.offset((i) as isize)) as i32);
        if (s) != 0 {
            let mut c: i32 = next_code[(s) as usize] - (((*z).firstcode[(s) as usize]) as i32) + (((*z).firstsymbol[(s) as usize]) as i32);
            let mut fastv: u16 = (((s << 9) | i) as u16);
            (*z).size[(c) as usize] = (((s) as u8) as u8);
            (*z).value[(c) as usize] = (((i) as u16) as u16);
            if s <= 9 {
                let mut j: i32 = stbi__bit_reverse(next_code[(s) as usize], s);
                while (j < (1 << 9)) {
                    (*z).fast[(j) as usize] = ((fastv) as u16);
                    j += ((1 << s) as i32);
                }
            }
            next_code[(s) as usize] += 1;
        }
        i += 1;
    }
    return 1;
}

pub unsafe fn stbi__zget8(mut z: *mut stbi__zbuf) -> u8 {
    if (*z).zbuffer >= (*z).zbuffer_end { return ((0) as u8); }
    let mut res: u8 = *(*z).zbuffer;
    ((*z).zbuffer = (*z).zbuffer.offset(1));
    return res;
}

pub unsafe fn stbi__fill_bits(mut z: *mut stbi__zbuf) {
    while (true) {
        (*z).code_buffer |= ((((stbi__zget8(z)) as u32) << (*z).num_bits) as u32);
        (*z).num_bits += ((8) as i32);
        if !((*z).num_bits <= 24) { break; }
    }
}

pub unsafe fn stbi__zreceive(mut z: *mut stbi__zbuf, mut n: i32) -> u32 {
    let mut k: u32 = std::mem::uninitialized();
    if (*z).num_bits < n { stbi__fill_bits(z); }
    k = (((*z).code_buffer & (((1 << n) - 1) as u32)) as u32);
    (*z).code_buffer >>= n;
    (*z).num_bits -= ((n) as i32);
    return k;
}

pub unsafe fn stbi__zhuffman_decode_slowpath(mut a: *mut stbi__zbuf, mut z: *mut stbi__zhuffman) -> i32 {
    let mut b: i32 = std::mem::uninitialized();
    let mut s: i32 = std::mem::uninitialized();
    let mut k: i32 = std::mem::uninitialized();
    k = ((stbi__bit_reverse(((((*a).code_buffer) as i32) as i32), 16)) as i32);
    s = ((9 + 1) as i32);
    while (true) {
        if k < (*z).maxcode[(s) as usize] { break; }
        s += 1;
    }
    if s == 16 { return -1; }
    b = (((k >> (16 - s)) - (((*z).firstcode[(s) as usize]) as i32) + (((*z).firstsymbol[(s) as usize]) as i32)) as i32);
    (*a).code_buffer >>= s;
    (*a).num_bits -= ((s) as i32);
    return (((*z).value[(b) as usize]) as i32);
}

pub unsafe fn stbi__zhuffman_decode(mut a: *mut stbi__zbuf, mut z: *mut stbi__zhuffman) -> i32 {
    let mut b: i32 = std::mem::uninitialized();
    let mut s: i32 = std::mem::uninitialized();
    if (*a).num_bits < 16 { stbi__fill_bits(a); }
    b = ((((*z).fast[((*a).code_buffer & (((1 << 9) - 1) as u32)) as usize]) as i32) as i32);
    if (b) != 0 {
        s = ((b >> 9) as i32);
        (*a).code_buffer >>= s;
        (*a).num_bits -= ((s) as i32);
        return b & 511;
    }
    return stbi__zhuffman_decode_slowpath(a, z);
}

pub unsafe fn stbi__zexpand(mut z: *mut stbi__zbuf, mut zout: *mut i8, mut n: i32) -> i32 {
    let mut q: *mut i8;
    let mut cur: i32 = std::mem::uninitialized();
    let mut limit: i32 = std::mem::uninitialized();
    let mut old_limit: i32 = std::mem::uninitialized();
    (*z).zout = zout;
    if (*z).z_expandable == 0 { return stbi__err("output buffer limit"); }
    cur = ((((((*z).zout) as usize) - (((*z).zout_start) as usize)) as i32) as i32);
    limit = (((((*z).zout_end) as usize) - (((*z).zout_start) as usize)) as i32);
    old_limit = (((((*z).zout_end) as usize) - (((*z).zout_start) as usize)) as i32);
    while (cur + n > limit) { limit *= ((2) as i32); }
    q = ((c_runtime::realloc((((*z).zout_start) as *mut u8), (((limit) as u64) as u64))) as *mut i8);
    if q == (std::ptr::null_mut()) { return stbi__err("outofmem"); }
    (*z).zout_start = q;
    (*z).zout = (q).offset((cur) as isize);
    (*z).zout_end = (q).offset((limit) as isize);
    return 1;
}

pub unsafe fn stbi__parse_huffman_block(mut a: *mut stbi__zbuf) -> i32 {
    let mut zout: *mut i8 = (*a).zout;
    ;
    while (true) {
        let mut z: i32 = stbi__zhuffman_decode(a, ((&mut (*a).z_length) as *mut stbi__zhuffman));
        if z < 256 {
            if z < 0 { return stbi__err("bad huffman code"); }
            if zout >= (*a).zout_end {
                if stbi__zexpand(a, zout, 1) == 0 { return 0; }
                zout = (*a).zout;
            }
            *zout = (((z) as i8) as i8);
            (zout = zout.offset(1));
        } else {
            let mut p: *mut u8;
            let mut len: i32 = std::mem::uninitialized();
            let mut dist: i32 = std::mem::uninitialized();
            if z == 256 {
                (*a).zout = zout;
                return 1;
            }
            z -= ((257) as i32);
            len = ((stbi__zlength_base[(z) as usize]) as i32);
            if (stbi__zlength_extra[(z) as usize]) != 0 { len += ((stbi__zreceive(a, stbi__zlength_extra[(z) as usize])) as i32); }
            z = ((stbi__zhuffman_decode(a, ((&mut (*a).z_distance) as *mut stbi__zhuffman))) as i32);
            if z < 0 { return stbi__err("bad huffman code"); }
            dist = ((stbi__zdist_base[(z) as usize]) as i32);
            if (stbi__zdist_extra[(z) as usize]) != 0 { dist += ((stbi__zreceive(a, stbi__zdist_extra[(z) as usize])) as i32); }
            if ((zout) as usize) - (((*a).zout_start) as usize) < dist as usize { return stbi__err("bad dist"); }
            if (zout).offset((len) as isize) > (*a).zout_end {
                if stbi__zexpand(a, zout, len) == 0 { return 0; }
                zout = (*a).zout;
            }
            p = (((zout).offset(-((dist) as isize))) as *mut u8);
            if dist == 1 {
                let mut v: u8 = *p;
                if (len) != 0 {
                    while (true) {
                        *zout = (((v) as i8) as i8);
                        (zout = zout.offset(1));
                        len -= 1;
                        if !((len) != 0) { break; }
                    }
                }
            } else {
                if (len) != 0 {
                    while (true) {
                        *zout = (((*p) as i8) as i8);
                        (zout = zout.offset(1));
                        (p = p.offset(1));
                        len -= 1;
                        if !((len) != 0) { break; }
                    }
                }
            }
        }
    }
    return 0;
}

pub unsafe fn stbi__compute_huffman_codes(mut a: *mut stbi__zbuf) -> i32 {
    let mut z_codelength: stbi__zhuffman = std::mem::uninitialized();
    let mut lencodes: [u8; 455] = std::mem::uninitialized();
    let mut codelength_sizes: [u8; 19] = std::mem::uninitialized();
    let mut i: i32 = std::mem::uninitialized();
    let mut n: i32 = std::mem::uninitialized();
    let mut hlit: i32 = ((stbi__zreceive(a, 5) + ((257) as u32)) as i32);
    let mut hdist: i32 = ((stbi__zreceive(a, 5) + ((1) as u32)) as i32);
    let mut hclen: i32 = ((stbi__zreceive(a, 4) + ((4) as u32)) as i32);
    let mut ntot: i32 = hlit + hdist;
    c_runtime::memset(codelength_sizes.as_mut_ptr(), 0, ((codelength_sizes.len()) as u64));
    i = ((0) as i32);
    while (i < hclen) {
        let mut s: i32 = ((stbi__zreceive(a, 3)) as i32);
        codelength_sizes[(length_dezigzag[(i) as usize]) as usize] = (((s) as u8) as u8);
        i += 1;
    }
    if stbi__zbuild_huffman(((&mut z_codelength) as *mut stbi__zhuffman), codelength_sizes.as_mut_ptr(), 19) == 0 { return 0; }
    n = ((0) as i32);
    while (n < ntot) {
        let mut c: i32 = stbi__zhuffman_decode(a, ((&mut z_codelength) as *mut stbi__zhuffman));
        if c < 0 || c >= 19 { return stbi__err("bad codelengths"); }
        if c < 16 {
            lencodes[(n) as usize] = (((c) as u8) as u8);
            n += 1;
        } else {
            let mut fill: u8 = ((0) as u8);
            if c == 16 {
                c = (((stbi__zreceive(a, 2) + ((3) as u32)) as i32) as i32);
                if n == 0 { return stbi__err("bad codelengths"); }
                fill = ((lencodes[(n - 1) as usize]) as u8);
            } else {
                if c == 17 { c = (((stbi__zreceive(a, 3) + ((3) as u32)) as i32) as i32); } else {
                    c = (((stbi__zreceive(a, 7) + ((11) as u32)) as i32) as i32);
                }
            }
            if ntot - n < c { return stbi__err("bad codelengths"); }
            c_runtime::memset((lencodes.as_mut_ptr()).offset((n) as isize), (((fill) as i32) as i32), (((c) as u64) as u64));
            n += ((c) as i32);
        }
    }
    if n != ntot { return stbi__err("bad codelengths"); }
    if stbi__zbuild_huffman(((&mut (*a).z_length) as *mut stbi__zhuffman), lencodes.as_mut_ptr(), hlit) == 0 { return 0; }
    if stbi__zbuild_huffman(((&mut (*a).z_distance) as *mut stbi__zhuffman), (lencodes.as_mut_ptr()).offset((hlit) as isize), hdist) == 0 { return 0; }
    return 1;
}

pub unsafe fn stbi__parse_uncompressed_block(mut a: *mut stbi__zbuf) -> i32 {
    let mut header: [u8; 4] = std::mem::uninitialized();
    let mut len: i32 = std::mem::uninitialized();
    let mut nlen: i32 = std::mem::uninitialized();
    let mut k: i32 = std::mem::uninitialized();
    if ((*a).num_bits & 7) != 0 { stbi__zreceive(a, (*a).num_bits & 7); }
    k = ((0) as i32);
    while ((*a).num_bits > 0) {
        header[(k) as usize] = ((((*a).code_buffer & ((255) as u32)) as u8) as u8);
        k += 1;
        (*a).code_buffer >>= 8;
        (*a).num_bits -= ((8) as i32);
    }
    while (k < 4) {
        header[(k) as usize] = ((stbi__zget8(a)) as u8);
        k += 1;
    }
    len = ((((header[(1) as usize]) as i32) * 256 + ((header[(0) as usize]) as i32)) as i32);
    nlen = ((((header[(3) as usize]) as i32) * 256 + ((header[(2) as usize]) as i32)) as i32);
    if nlen != (len ^ 0xffff) { return stbi__err("zlib corrupt"); }
    if ((*a).zbuffer).offset((len) as isize) > (*a).zbuffer_end { return stbi__err("read past buffer"); }
    if ((*a).zout).offset((len) as isize) > (*a).zout_end { if stbi__zexpand(a, (*a).zout, len) == 0 { return 0; } }
    c_runtime::memcpy((((*a).zout) as *mut u8), (*a).zbuffer, (((len) as u64) as u64));
    (*a).zbuffer = (*a).zbuffer.offset((((len) as *mut u8)) as isize);
    (*a).zout = (*a).zout.offset((((len) as *mut i8)) as isize);
    return 1;
}

pub unsafe fn stbi__parse_zlib_header(mut a: *mut stbi__zbuf) -> i32 {
    let mut cmf: i32 = ((stbi__zget8(a)) as i32);
    let mut cm: i32 = cmf & 15;
    let mut flg: i32 = ((stbi__zget8(a)) as i32);
    if (cmf * 256 + flg) % 31 != 0 { return stbi__err("bad zlib header"); }
    if (flg & 32) != 0 { return stbi__err("no preset dict"); }
    if cm != 8 { return stbi__err("bad compression"); }
    return 1;
}

pub unsafe fn stbi__parse_zlib(mut a: *mut stbi__zbuf, mut parse_header: i32) -> i32 {
    let mut _final_: i32 = std::mem::uninitialized();
    let mut _type_: i32 = std::mem::uninitialized();
    if (parse_header) != 0 { if stbi__parse_zlib_header(a) == 0 { return 0; } }
    (*a).num_bits = ((0) as i32);
    (*a).code_buffer = (((0) as u32) as u32);
    while (true) {
        _final_ = (((stbi__zreceive(a, 1)) as i32) as i32);
        _type_ = (((stbi__zreceive(a, 2)) as i32) as i32);
        if _type_ == 0 {
            if stbi__parse_uncompressed_block(a) == 0 { return 0; }
        } else {
            if _type_ == 3 {
                return 0;
            } else {
                if _type_ == 1 {
                    if stbi__zbuild_huffman(((&mut (*a).z_length) as *mut stbi__zhuffman), ((stbi__zdefault_length.as_mut_ptr()) as *mut u8), 288) == 0 { return 0; }
                    if stbi__zbuild_huffman(((&mut (*a).z_distance) as *mut stbi__zhuffman), ((stbi__zdefault_distance.as_mut_ptr()) as *mut u8), 32) == 0 { return 0; }
                } else {
                    if stbi__compute_huffman_codes(a) == 0 { return 0; }
                }
                if stbi__parse_huffman_block(a) == 0 { return 0; }
            }
        }
        if !(_final_ == 0) { break; }
    }

    return 1;
}

pub unsafe fn stbi__do_zlib(mut a: *mut stbi__zbuf, mut obuf: *mut i8, mut olen: i32, mut exp: i32, mut parse_header: i32) -> i32 {
    (*a).zout_start = obuf;
    (*a).zout = obuf;
    (*a).zout_end = (obuf).offset((olen) as isize);
    (*a).z_expandable = ((exp) as i32);
    return stbi__parse_zlib(a, parse_header);
}

pub unsafe fn stbi_zlib_decode_malloc_guesssize(mut buffer: *mut i8, mut len: i32, mut initial_size: i32, mut outlen: *mut i32) -> *mut i8 {
    let mut a: stbi__zbuf = std::mem::uninitialized();
    let mut p: *mut i8 = ((stbi__malloc((((initial_size) as u64) as u64))) as *mut i8);
    if p == (std::ptr::null_mut()) { return (std::ptr::null_mut()); }
    a.zbuffer = ((buffer) as *mut u8);
    a.zbuffer_end = (((buffer) as *mut u8)).offset((len) as isize);
    if (stbi__do_zlib(((&mut a) as *mut stbi__zbuf), p, initial_size, 1, 1)) != 0 {
        if (outlen) != std::ptr::null_mut() { *outlen = (((((a.zout) as usize) - ((a.zout_start) as usize)) as i32) as i32); }
        return a.zout_start;
    } else {
        c_runtime::free(a.zout_start);
        return (std::ptr::null_mut());
    }
}

pub unsafe fn stbi_zlib_decode_malloc(mut buffer: *mut i8, mut len: i32, mut outlen: *mut i32) -> *mut i8 {
    return stbi_zlib_decode_malloc_guesssize(buffer, len, 16384, outlen);
}

pub unsafe fn stbi_zlib_decode_malloc_guesssize_headerflag(mut buffer: *mut i8, mut len: i32, mut initial_size: i32, mut outlen: *mut i32, mut parse_header: i32) -> *mut i8 {
    let mut a: stbi__zbuf = std::mem::uninitialized();
    let mut p: *mut i8 = ((stbi__malloc((((initial_size) as u64) as u64))) as *mut i8);
    if p == (std::ptr::null_mut()) { return (std::ptr::null_mut()); }
    a.zbuffer = ((buffer) as *mut u8);
    a.zbuffer_end = (((buffer) as *mut u8)).offset((len) as isize);
    if (stbi__do_zlib(((&mut a) as *mut stbi__zbuf), p, initial_size, 1, parse_header)) != 0 {
        if (outlen) != std::ptr::null_mut() { *outlen = (((((a.zout) as usize) - ((a.zout_start) as usize)) as i32) as i32); }
        return a.zout_start;
    } else {
        c_runtime::free(a.zout_start);
        return (std::ptr::null_mut());
    }
}

pub unsafe fn stbi_zlib_decode_buffer(mut obuffer: *mut i8, mut olen: i32, mut ibuffer: *mut i8, mut ilen: i32) -> i32 {
    let mut a: stbi__zbuf = std::mem::uninitialized();
    a.zbuffer = ((ibuffer) as *mut u8);
    a.zbuffer_end = (((ibuffer) as *mut u8)).offset((ilen) as isize);
    if (stbi__do_zlib(((&mut a) as *mut stbi__zbuf), obuffer, olen, 0, 1)) != 0 { return ((((a.zout) as usize) - ((a.zout_start) as usize)) as i32); } else { return -1; }
}

pub unsafe fn stbi_zlib_decode_noheader_malloc(mut buffer: *mut i8, mut len: i32, mut outlen: *mut i32) -> *mut i8 {
    let mut a: stbi__zbuf = std::mem::uninitialized();
    let mut p: *mut i8 = ((stbi__malloc((((16384) as u64) as u64))) as *mut i8);
    if p == (std::ptr::null_mut()) { return (std::ptr::null_mut()); }
    a.zbuffer = ((buffer) as *mut u8);
    a.zbuffer_end = (((buffer) as *mut u8)).offset((len) as isize);
    if (stbi__do_zlib(((&mut a) as *mut stbi__zbuf), p, 16384, 1, 0)) != 0 {
        if (outlen) != std::ptr::null_mut() { *outlen = (((((a.zout) as usize) - ((a.zout_start) as usize)) as i32) as i32); }
        return a.zout_start;
    } else {
        c_runtime::free(a.zout_start);
        return (std::ptr::null_mut());
    }
}

pub unsafe fn stbi_zlib_decode_noheader_buffer(mut obuffer: *mut i8, mut olen: i32, mut ibuffer: *mut i8, mut ilen: i32) -> i32 {
    let mut a: stbi__zbuf = std::mem::uninitialized();
    a.zbuffer = ((ibuffer) as *mut u8);
    a.zbuffer_end = (((ibuffer) as *mut u8)).offset((ilen) as isize);
    if (stbi__do_zlib(((&mut a) as *mut stbi__zbuf), obuffer, olen, 0, 0)) != 0 { return ((((a.zout) as usize) - ((a.zout_start) as usize)) as i32); } else { return -1; }
}

pub unsafe fn stbi__get_chunk_header(mut s: *mut stbi__context) -> stbi__pngchunk {
    let mut c: stbi__pngchunk = std::mem::uninitialized();
    c.length = ((stbi__get32be(s)) as u32);
    c._type_ = ((stbi__get32be(s)) as u32);
    return c;
}

pub unsafe fn stbi__check_png_header(mut s: *mut stbi__context) -> i32 {
    let mut i: i32 = std::mem::uninitialized();
    i = ((0) as i32);
    while (i < 8) {
        if ((stbi__get8(s)) as i32) != ((png_sig[(i) as usize]) as i32) { return stbi__err("bad png sig"); }
        i += 1;
    }
    return 1;
}

pub unsafe fn stbi__paeth(mut a: i32, mut b: i32, mut c: i32) -> i32 {
    let mut p: i32 = a + b - c;
    let mut pa: i32 = c_runtime::abs(p - a);
    let mut pb: i32 = c_runtime::abs(p - b);
    let mut pc: i32 = c_runtime::abs(p - c);
    if pa <= pb && pa <= pc { return a; }
    if pb <= pc { return b; }
    return c;
}

pub unsafe fn stbi__create_png_image_raw(mut a: *mut stbi__png, mut raw: *mut u8, mut raw_len: u32, mut out_n: i32, mut x: u32, mut y: u32, mut depth: i32, mut color: i32) -> i32 {
    let mut bytes: i32 = (if depth == 16 { 2 } else { 1 });
    let mut s: *mut stbi__context = (*a).s;
    let mut i: u32 = std::mem::uninitialized();
    let mut j: u32 = std::mem::uninitialized();
    let mut stride: u32 = x * ((out_n) as u32) * ((bytes) as u32);
    let mut img_len: u32 = std::mem::uninitialized();
    let mut img_width_bytes: u32 = std::mem::uninitialized();
    let mut k: i32 = std::mem::uninitialized();
    let mut img_n: i32 = (*s).img_n;
    let mut output_bytes: i32 = out_n * bytes;
    let mut filter_bytes: i32 = img_n * bytes;
    let mut width: i32 = ((x) as i32);
    (*a)._out_ = stbi__malloc_mad3((((x) as i32) as i32), (((y) as i32) as i32), output_bytes, 0);
    if (*a)._out_ == std::ptr::null_mut() { return stbi__err("outofmem"); }
    img_width_bytes = ((((((img_n) as u32) * x * ((depth) as u32)) + ((7) as u32)) >> 3) as u32);
    img_len = (((img_width_bytes + ((1) as u32)) * y) as u32);
    if raw_len < img_len { return stbi__err("not enough pixels"); }
    j = (((0) as u32) as u32);
    while (j < y) {
        let mut cur: *mut u8 = ((*a)._out_).offset((stride * j) as isize);
        let mut prior: *mut u8;
        let mut filter: i32 = ((*raw) as i32);
        (raw = raw.offset(1));
        if filter > 4 { return stbi__err("invalid filter"); }
        if depth < 8 {
            cur = cur.offset((((x * ((out_n) as u32) - img_width_bytes) as *mut u8)) as isize);
            filter_bytes = ((1) as i32);
            width = (((img_width_bytes) as i32) as i32);
        }
        prior = (cur).offset(-((stride) as isize));
        if j == ((0) as u32) { filter = ((first_row_filter[(filter) as usize]) as i32); }
        k = ((0) as i32);
        while (k < filter_bytes) {
            {
                if filter == STBI__F_none { *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8); } else if filter == STBI__F_sub { *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8); } else if filter == STBI__F_up { *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((*prior.offset((k) as isize)) as i32)) & 255) as u8) as u8); } else if filter == STBI__F_avg { *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + (((*prior.offset((k) as isize)) as i32) >> 1)) & 255) as u8) as u8); } else if filter == STBI__F_paeth { *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + stbi__paeth(0, (((*prior.offset((k) as isize)) as i32) as i32), 0)) & 255) as u8) as u8); } else if filter == STBI__F_avg_first { *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8); } else if filter == STBI__F_paeth_first { *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8); }
            }
            k += 1;
        }
        if depth == 8 {
            if img_n != out_n { *cur.offset((img_n) as isize) = (((255) as u8) as u8); }
            raw = raw.offset((((img_n) as *mut u8)) as isize);
            cur = cur.offset((((out_n) as *mut u8)) as isize);
            prior = prior.offset((((out_n) as *mut u8)) as isize);
        } else {
            if depth == 16 {
                if img_n != out_n {
                    *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                    *cur.offset((filter_bytes + 1) as isize) = (((255) as u8) as u8);
                }
                raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
                cur = cur.offset((((output_bytes) as *mut u8)) as isize);
                prior = prior.offset((((output_bytes) as *mut u8)) as isize);
            } else {
                raw = raw.offset((((1) as *mut u8)) as isize);
                cur = cur.offset((((1) as *mut u8)) as isize);
                prior = prior.offset((((1) as *mut u8)) as isize);
            }
        }
        if depth < 8 || img_n == out_n {
            let mut nk: i32 = (width - 1) * filter_bytes;
            {
                if filter == STBI__F_none { c_runtime::memcpy(cur, raw, (((nk) as u64) as u64)); } else if filter == STBI__F_sub {
                    k = ((0) as i32);
                    while (k < nk) {
                        *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((*cur.offset((k - filter_bytes) as isize)) as i32)) & 255) as u8) as u8);
                        k += 1;
                    }
                } else if filter == STBI__F_up {
                    k = ((0) as i32);
                    while (k < nk) {
                        *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((*prior.offset((k) as isize)) as i32)) & 255) as u8) as u8);
                        k += 1;
                    }
                } else if filter == STBI__F_avg {
                    k = ((0) as i32);
                    while (k < nk) {
                        *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((((*prior.offset((k) as isize)) as i32) + ((*cur.offset((k - filter_bytes) as isize)) as i32)) >> 1)) & 255) as u8) as u8);
                        k += 1;
                    }
                } else if filter == STBI__F_paeth {
                    k = ((0) as i32);
                    while (k < nk) {
                        *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + stbi__paeth((((*cur.offset((k - filter_bytes) as isize)) as i32) as i32), (((*prior.offset((k) as isize)) as i32) as i32), (((*prior.offset((k - filter_bytes) as isize)) as i32) as i32))) & 255) as u8) as u8);
                        k += 1;
                    }
                } else if filter == STBI__F_avg_first {
                    k = ((0) as i32);
                    while (k < nk) {
                        *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + (((*cur.offset((k - filter_bytes) as isize)) as i32) >> 1)) & 255) as u8) as u8);
                        k += 1;
                    }
                } else if filter == STBI__F_paeth_first {
                    k = ((0) as i32);
                    while (k < nk) {
                        *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + stbi__paeth((((*cur.offset((k - filter_bytes) as isize)) as i32) as i32), 0, 0)) & 255) as u8) as u8);
                        k += 1;
                    }
                }
            }
            raw = raw.offset((((nk) as *mut u8)) as isize);
        } else {
            {
                if filter == STBI__F_none {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8);
                            k += 1;
                        }
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
                        cur = cur.offset((((output_bytes) as *mut u8)) as isize);
                        prior = prior.offset((((output_bytes) as *mut u8)) as isize);
                    }
                } else if filter == STBI__F_sub {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((*cur.offset((k - output_bytes) as isize)) as i32)) & 255) as u8) as u8);
                            k += 1;
                        }
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
                        cur = cur.offset((((output_bytes) as *mut u8)) as isize);
                        prior = prior.offset((((output_bytes) as *mut u8)) as isize);
                    }
                } else if filter == STBI__F_up {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((*prior.offset((k) as isize)) as i32)) & 255) as u8) as u8);
                            k += 1;
                        }
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
                        cur = cur.offset((((output_bytes) as *mut u8)) as isize);
                        prior = prior.offset((((output_bytes) as *mut u8)) as isize);
                    }
                } else if filter == STBI__F_avg {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((((*prior.offset((k) as isize)) as i32) + ((*cur.offset((k - output_bytes) as isize)) as i32)) >> 1)) & 255) as u8) as u8);
                            k += 1;
                        }
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
                        cur = cur.offset((((output_bytes) as *mut u8)) as isize);
                        prior = prior.offset((((output_bytes) as *mut u8)) as isize);
                    }
                } else if filter == STBI__F_paeth {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + stbi__paeth((((*cur.offset((k - output_bytes) as isize)) as i32) as i32), (((*prior.offset((k) as isize)) as i32) as i32), (((*prior.offset((k - output_bytes) as isize)) as i32) as i32))) & 255) as u8) as u8);
                            k += 1;
                        }
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
                        cur = cur.offset((((output_bytes) as *mut u8)) as isize);
                        prior = prior.offset((((output_bytes) as *mut u8)) as isize);
                    }
                } else if filter == STBI__F_avg_first {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + (((*cur.offset((k - output_bytes) as isize)) as i32) >> 1)) & 255) as u8) as u8);
                            k += 1;
                        }
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
                        cur = cur.offset((((output_bytes) as *mut u8)) as isize);
                        prior = prior.offset((((output_bytes) as *mut u8)) as isize);
                    }
                } else if filter == STBI__F_paeth_first {
                    i = ((x - ((1) as u32)) as u32);
                    while (i >= ((1) as u32)) {
                        k = ((0) as i32);
                        while (k < filter_bytes) {
                            *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + stbi__paeth((((*cur.offset((k - output_bytes) as isize)) as i32) as i32), 0, 0)) & 255) as u8) as u8);
                            k += 1;
                        }
                        i -= 1;
                        *cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
                        raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
                        cur = cur.offset((((output_bytes) as *mut u8)) as isize);
                        prior = prior.offset((((output_bytes) as *mut u8)) as isize);
                    }
                }
            }
            if depth == 16 {
                cur = ((*a)._out_).offset((stride * j) as isize);
                i = (((0) as u32) as u32);
                while (i < x) {
                    *cur.offset((filter_bytes + 1) as isize) = (((255) as u8) as u8);
                    i += 1;
                    cur = cur.offset((((output_bytes) as *mut u8)) as isize);
                }
            }
        }
        j += 1;
    }
    if depth < 8 {
        j = (((0) as u32) as u32);
        while (j < y) {
            let mut cur: *mut u8 = ((*a)._out_).offset((stride * j) as isize);
            let mut _in_: *mut u8 = ((((*a)._out_).offset((stride * j) as isize)).offset((x * ((out_n) as u32)) as isize)).offset(-((img_width_bytes) as isize));
            let mut scale: u8 = ((if (color == 0) { ((stbi__depth_scale_table[(depth) as usize]) as i32) } else { 1 }) as u8);
            if depth == 4 {
                k = (((x * ((img_n) as u32)) as i32) as i32);
                while (k >= 2) {
                    *cur = ((((scale) as i32) * (((*_in_) as i32) >> 4)) as u8);
                    (cur = cur.offset(1));
                    *cur = ((((scale) as i32) * (((*_in_) as i32) & 0x0f)) as u8);
                    (cur = cur.offset(1));
                    k -= ((2) as i32);
                    (_in_ = _in_.offset(1));
                }
                if k > 0 {
                    *cur = ((((scale) as i32) * (((*_in_) as i32) >> 4)) as u8);
                    (cur = cur.offset(1));
                }
            } else {
                if depth == 2 {
                    k = (((x * ((img_n) as u32)) as i32) as i32);
                    while (k >= 4) {
                        *cur = ((((scale) as i32) * (((*_in_) as i32) >> 6)) as u8);
                        (cur = cur.offset(1));
                        *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 4) & 0x03)) as u8);
                        (cur = cur.offset(1));
                        *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 2) & 0x03)) as u8);
                        (cur = cur.offset(1));
                        *cur = ((((scale) as i32) * (((*_in_) as i32) & 0x03)) as u8);
                        (cur = cur.offset(1));
                        k -= ((4) as i32);
                        (_in_ = _in_.offset(1));
                    }
                    if k > 0 {
                        *cur = ((((scale) as i32) * (((*_in_) as i32) >> 6)) as u8);
                        (cur = cur.offset(1));
                    }
                    if k > 1 {
                        *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 4) & 0x03)) as u8);
                        (cur = cur.offset(1));
                    }
                    if k > 2 {
                        *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 2) & 0x03)) as u8);
                        (cur = cur.offset(1));
                    }
                } else {
                    if depth == 1 {
                        k = (((x * ((img_n) as u32)) as i32) as i32);
                        while (k >= 8) {
                            *cur = ((((scale) as i32) * (((*_in_) as i32) >> 7)) as u8);
                            (cur = cur.offset(1));
                            *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 6) & 0x01)) as u8);
                            (cur = cur.offset(1));
                            *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 5) & 0x01)) as u8);
                            (cur = cur.offset(1));
                            *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 4) & 0x01)) as u8);
                            (cur = cur.offset(1));
                            *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 3) & 0x01)) as u8);
                            (cur = cur.offset(1));
                            *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 2) & 0x01)) as u8);
                            (cur = cur.offset(1));
                            *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 1) & 0x01)) as u8);
                            (cur = cur.offset(1));
                            *cur = ((((scale) as i32) * (((*_in_) as i32) & 0x01)) as u8);
                            (cur = cur.offset(1));
                            k -= ((8) as i32);
                            (_in_ = _in_.offset(1));
                        }
                        if k > 0 {
                            *cur = ((((scale) as i32) * (((*_in_) as i32) >> 7)) as u8);
                            (cur = cur.offset(1));
                        }
                        if k > 1 {
                            *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 6) & 0x01)) as u8);
                            (cur = cur.offset(1));
                        }
                        if k > 2 {
                            *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 5) & 0x01)) as u8);
                            (cur = cur.offset(1));
                        }
                        if k > 3 {
                            *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 4) & 0x01)) as u8);
                            (cur = cur.offset(1));
                        }
                        if k > 4 {
                            *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 3) & 0x01)) as u8);
                            (cur = cur.offset(1));
                        }
                        if k > 5 {
                            *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 2) & 0x01)) as u8);
                            (cur = cur.offset(1));
                        }
                        if k > 6 {
                            *cur = ((((scale) as i32) * ((((*_in_) as i32) >> 1) & 0x01)) as u8);
                            (cur = cur.offset(1));
                        }
                    }
                }
            }
            if img_n != out_n {
                let mut q: i32 = std::mem::uninitialized();
                cur = ((*a)._out_).offset((stride * j) as isize);
                if img_n == 1 {
                    q = (((x - ((1) as u32)) as i32) as i32);
                    while (q >= 0) {
                        *cur.offset((q * 2 + 1) as isize) = (((255) as u8) as u8);
                        *cur.offset((q * 2 + 0) as isize) = ((*cur.offset((q) as isize)) as u8);
                        q -= 1;
                    }
                } else {
                    q = (((x - ((1) as u32)) as i32) as i32);
                    while (q >= 0) {
                        *cur.offset((q * 4 + 3) as isize) = (((255) as u8) as u8);
                        *cur.offset((q * 4 + 2) as isize) = ((*cur.offset((q * 3 + 2) as isize)) as u8);
                        *cur.offset((q * 4 + 1) as isize) = ((*cur.offset((q * 3 + 1) as isize)) as u8);
                        *cur.offset((q * 4 + 0) as isize) = ((*cur.offset((q * 3 + 0) as isize)) as u8);
                        q -= 1;
                    }
                }
            }
            j += 1;
        }
    } else {
        if depth == 16 {
            let mut cur: *mut u8 = (*a)._out_;
            let mut cur16: *mut u16 = ((cur) as *mut u16);
            i = (((0) as u32) as u32);
            while (i < x * y * ((out_n) as u32)) {
                *cur16 = ((((((*cur.offset((0) as isize)) as i32) << 8) | ((*cur.offset((1) as isize)) as i32)) as u16) as u16);
                i += 1;
                (cur16 = cur16.offset(1));
                cur = cur.offset((((2) as *mut u8)) as isize);
            }
        }
    }
    return 1;
}

pub unsafe fn stbi__create_png_image(mut a: *mut stbi__png, mut image_data: *mut u8, mut image_data_len: u32, mut out_n: i32, mut depth: i32, mut color: i32, mut interlaced: i32) -> i32 {
    let mut bytes: i32 = (if depth == 16 { 2 } else { 1 });
    let mut out_bytes: i32 = out_n * bytes;
    let mut _final_: *mut u8;
    let mut p: i32 = std::mem::uninitialized();
    if interlaced == 0 { return stbi__create_png_image_raw(a, image_data, image_data_len, out_n, (*(*a).s).img_x, (*(*a).s).img_y, depth, color); }
    _final_ = stbi__malloc_mad3(((((*(*a).s).img_x) as i32) as i32), ((((*(*a).s).img_y) as i32) as i32), out_bytes, 0);
    p = ((0) as i32);
    while (p < 7) {
        let mut xorig: [i32; 7] = [0, 4, 0, 2, 0, 1, 0];
        let mut yorig: [i32; 7] = [0, 0, 4, 0, 2, 0, 1];
        let mut xspc: [i32; 7] = [8, 8, 4, 4, 2, 2, 1];
        let mut yspc: [i32; 7] = [8, 8, 8, 4, 4, 2, 2];
        let mut i: i32 = std::mem::uninitialized();
        let mut j: i32 = std::mem::uninitialized();
        let mut x: i32 = std::mem::uninitialized();
        let mut y: i32 = std::mem::uninitialized();
        x = (((((*(*a).s).img_x - ((xorig[(p) as usize]) as u32) + ((xspc[(p) as usize]) as u32) - ((1) as u32)) / ((xspc[(p) as usize]) as u32)) as i32) as i32);
        y = (((((*(*a).s).img_y - ((yorig[(p) as usize]) as u32) + ((yspc[(p) as usize]) as u32) - ((1) as u32)) / ((yspc[(p) as usize]) as u32)) as i32) as i32);
        if (x) != 0 && (y) != 0 {
            let mut img_len: u32 = (((((((*(*a).s).img_n * x * depth) + 7) >> 3) + 1) * y) as u32);
            if stbi__create_png_image_raw(a, image_data, image_data_len, out_n, (((x) as u32) as u32), (((y) as u32) as u32), depth, color) == 0 {
                c_runtime::free(_final_);
                return 0;
            }
            j = ((0) as i32);
            while (j < y) {
                i = ((0) as i32);
                while (i < x) {
                    let mut out_y: i32 = j * yspc[(p) as usize] + yorig[(p) as usize];
                    let mut out_x: i32 = i * xspc[(p) as usize] + xorig[(p) as usize];
                    c_runtime::memcpy(((_final_).offset((((out_y) as u32) * (*(*a).s).img_x * ((out_bytes) as u32)) as isize)).offset((out_x * out_bytes) as isize), ((*a)._out_).offset(((j * x + i) * out_bytes) as isize), (((out_bytes) as u64) as u64));
                    i += 1;
                }
                j += 1;
            }
            c_runtime::free((*a)._out_);
            image_data = image_data.offset((((img_len) as *mut u8)) as isize);
            image_data_len -= ((img_len) as u32);
        }
        p += 1;
    }
    (*a)._out_ = _final_;
    return 1;
}

pub unsafe fn stbi__compute_transparency(mut z: *mut stbi__png, mut tc: *mut u8, mut out_n: i32) -> i32 {
    let mut s: *mut stbi__context = (*z).s;
    let mut i: u32 = std::mem::uninitialized();
    let mut pixel_count: u32 = (*s).img_x * (*s).img_y;
    let mut p: *mut u8 = (*z)._out_;
    if out_n == 2 {
        i = (((0) as u32) as u32);
        while (i < pixel_count) {
            *p.offset((1) as isize) = (((if ((*p.offset((0) as isize)) as i32) == ((*tc.offset((0) as isize)) as i32) { 0 } else { 255 }) as u8) as u8);
            p = p.offset((((2) as *mut u8)) as isize);
            i += 1;
        }
    } else {
        i = (((0) as u32) as u32);
        while (i < pixel_count) {
            if ((*p.offset((0) as isize)) as i32) == ((*tc.offset((0) as isize)) as i32) && ((*p.offset((1) as isize)) as i32) == ((*tc.offset((1) as isize)) as i32) && ((*p.offset((2) as isize)) as i32) == ((*tc.offset((2) as isize)) as i32) { *p.offset((3) as isize) = (((0) as u8) as u8); }
            p = p.offset((((4) as *mut u8)) as isize);
            i += 1;
        }
    }
    return 1;
}

pub unsafe fn stbi__compute_transparency16(mut z: *mut stbi__png, mut tc: *mut u16, mut out_n: i32) -> i32 {
    let mut s: *mut stbi__context = (*z).s;
    let mut i: u32 = std::mem::uninitialized();
    let mut pixel_count: u32 = (*s).img_x * (*s).img_y;
    let mut p: *mut u16 = (((*z)._out_) as *mut u16);
    if out_n == 2 {
        i = (((0) as u32) as u32);
        while (i < pixel_count) {
            *p.offset((1) as isize) = (((if ((*p.offset((0) as isize)) as i32) == ((*tc.offset((0) as isize)) as i32) { 0 } else { 65535 }) as u16) as u16);
            p = p.offset((((2) as *mut u16)) as isize);
            i += 1;
        }
    } else {
        i = (((0) as u32) as u32);
        while (i < pixel_count) {
            if ((*p.offset((0) as isize)) as i32) == ((*tc.offset((0) as isize)) as i32) && ((*p.offset((1) as isize)) as i32) == ((*tc.offset((1) as isize)) as i32) && ((*p.offset((2) as isize)) as i32) == ((*tc.offset((2) as isize)) as i32) { *p.offset((3) as isize) = (((0) as u16) as u16); }
            p = p.offset((((4) as *mut u16)) as isize);
            i += 1;
        }
    }
    return 1;
}

pub unsafe fn stbi__expand_png_palette(mut a: *mut stbi__png, mut palette: *mut u8, mut len: i32, mut pal_img_n: i32) -> i32 {
    let mut i: u32 = std::mem::uninitialized();
    let mut pixel_count: u32 = (*(*a).s).img_x * (*(*a).s).img_y;
    let mut p: *mut u8;
    let mut temp_out: *mut u8;
    let mut orig: *mut u8 = (*a)._out_;
    p = stbi__malloc_mad2((((pixel_count) as i32) as i32), pal_img_n, 0);
    if p == (std::ptr::null_mut()) { return stbi__err("outofmem"); }
    temp_out = p;
    if pal_img_n == 3 {
        i = (((0) as u32) as u32);
        while (i < pixel_count) {
            let mut n: i32 = ((*orig.offset((i) as isize)) as i32) * 4;
            *p.offset((0) as isize) = ((*palette.offset((n) as isize)) as u8);
            *p.offset((1) as isize) = ((*palette.offset((n + 1) as isize)) as u8);
            *p.offset((2) as isize) = ((*palette.offset((n + 2) as isize)) as u8);
            p = p.offset((((3) as *mut u8)) as isize);
            i += 1;
        }
    } else {
        i = (((0) as u32) as u32);
        while (i < pixel_count) {
            let mut n: i32 = ((*orig.offset((i) as isize)) as i32) * 4;
            *p.offset((0) as isize) = ((*palette.offset((n) as isize)) as u8);
            *p.offset((1) as isize) = ((*palette.offset((n + 1) as isize)) as u8);
            *p.offset((2) as isize) = ((*palette.offset((n + 2) as isize)) as u8);
            *p.offset((3) as isize) = ((*palette.offset((n + 3) as isize)) as u8);
            p = p.offset((((4) as *mut u8)) as isize);
            i += 1;
        }
    }
    c_runtime::free((*a)._out_);
    (*a)._out_ = temp_out;
    return 1;
}

pub unsafe fn stbi_set_unpremultiply_on_load(mut flag_true_if_should_unpremultiply: i32) {
    stbi__unpremultiply_on_load = ((flag_true_if_should_unpremultiply) as i32);
}

pub unsafe fn stbi_convert_iphone_png_to_rgb(mut flag_true_if_should_convert: i32) {
    stbi__de_iphone_flag = ((flag_true_if_should_convert) as i32);
}

pub unsafe fn stbi__de_iphone(mut z: *mut stbi__png) {
    let mut s: *mut stbi__context = (*z).s;
    let mut i: u32 = std::mem::uninitialized();
    let mut pixel_count: u32 = (*s).img_x * (*s).img_y;
    let mut p: *mut u8 = (*z)._out_;
    if (*s).img_out_n == 3 {
        i = (((0) as u32) as u32);
        while (i < pixel_count) {
            let mut t: u8 = *p.offset((0) as isize);
            *p.offset((0) as isize) = ((*p.offset((2) as isize)) as u8);
            *p.offset((2) as isize) = ((t) as u8);
            p = p.offset((((3) as *mut u8)) as isize);
            i += 1;
        }
    } else {
        if (stbi__unpremultiply_on_load) != 0 {
            i = (((0) as u32) as u32);
            while (i < pixel_count) {
                let mut a: u8 = *p.offset((3) as isize);
                let mut t: u8 = *p.offset((0) as isize);
                if (a) != 0 {
                    let mut half: u8 = ((((a) as i32) / 2) as u8);
                    *p.offset((0) as isize) = ((((((*p.offset((2) as isize)) as i32) * 255 + ((half) as i32)) / ((a) as i32)) as u8) as u8);
                    *p.offset((1) as isize) = ((((((*p.offset((1) as isize)) as i32) * 255 + ((half) as i32)) / ((a) as i32)) as u8) as u8);
                    *p.offset((2) as isize) = ((((((t) as i32) * 255 + ((half) as i32)) / ((a) as i32)) as u8) as u8);
                } else {
                    *p.offset((0) as isize) = ((*p.offset((2) as isize)) as u8);
                    *p.offset((2) as isize) = ((t) as u8);
                }
                p = p.offset((((4) as *mut u8)) as isize);
                i += 1;
            }
        } else {
            i = (((0) as u32) as u32);
            while (i < pixel_count) {
                let mut t: u8 = *p.offset((0) as isize);
                *p.offset((0) as isize) = ((*p.offset((2) as isize)) as u8);
                *p.offset((2) as isize) = ((t) as u8);
                p = p.offset((((4) as *mut u8)) as isize);
                i += 1;
            }
        }
    }
}

pub unsafe fn stbi__parse_png_file(mut z: *mut stbi__png, mut scan: i32, mut req_comp: i32) -> i32 {
    let mut palette: [u8; 1024] = std::mem::uninitialized();
    let mut pal_img_n: u8 = ((0) as u8);
    let mut has_trans: u8 = ((0) as u8);
    let mut tc: [u8; 3] = std::mem::uninitialized();
    let mut tc16: [u16; 3] = std::mem::uninitialized();
    let mut ioff: u32 = ((0) as u32);
    let mut idata_limit: u32 = ((0) as u32);
    let mut i: u32 = std::mem::uninitialized();
    let mut pal_len: u32 = ((0) as u32);
    let mut first: i32 = 1;
    let mut k: i32 = std::mem::uninitialized();
    let mut interlace: i32 = 0;
    let mut color: i32 = 0;
    let mut is_iphone: i32 = 0;
    let mut s: *mut stbi__context = (*z).s;
    (*z).expanded = (std::ptr::null_mut());
    (*z).idata = (std::ptr::null_mut());
    (*z)._out_ = (std::ptr::null_mut());
    if stbi__check_png_header(s) == 0 { return 0; }
    if scan == STBI__SCAN_type { return 1; }
    ;
    while (true) {
        let mut c: stbi__pngchunk = stbi__get_chunk_header(s);
        {
            if c._type_ == ((((('C') as i32) << 24) + ((('g') as i32) << 16) + ((('B') as i32) << 8) + (('I') as i32)) as u32) {
                is_iphone = ((1) as i32);
                stbi__skip(s, (((c.length) as i32) as i32));
            } else if c._type_ == ((((('I') as i32) << 24) + ((('H') as i32) << 16) + ((('D') as i32) << 8) + (('R') as i32)) as u32) {
                {
                    let mut comp: i32 = std::mem::uninitialized();
                    let mut filter: i32 = std::mem::uninitialized();
                    if first == 0 { return stbi__err("multiple IHDR"); }
                    first = ((0) as i32);
                    if c.length != ((13) as u32) { return stbi__err("bad IHDR len"); }
                    (*s).img_x = ((stbi__get32be(s)) as u32);
                    if (*s).img_x > ((1 << 24) as u32) { return stbi__err("too large"); }
                    (*s).img_y = ((stbi__get32be(s)) as u32);
                    if (*s).img_y > ((1 << 24) as u32) { return stbi__err("too large"); }
                    (*z).depth = (((stbi__get8(s)) as i32) as i32);
                    if (*z).depth != 1 && (*z).depth != 2 && (*z).depth != 4 && (*z).depth != 8 && (*z).depth != 16 { return stbi__err("1/2/4/8/16-bit only"); }
                    color = (((stbi__get8(s)) as i32) as i32);
                    if color > 6 { return stbi__err("bad ctype"); }
                    if color == 3 && (*z).depth == 16 { return stbi__err("bad ctype"); }
                    if color == 3 { pal_img_n = (((3) as u8) as u8); } else { if (color & 1) != 0 { return stbi__err("bad ctype"); } }
                    comp = (((stbi__get8(s)) as i32) as i32);
                    if (comp) != 0 { return stbi__err("bad comp method"); }
                    filter = (((stbi__get8(s)) as i32) as i32);
                    if (filter) != 0 { return stbi__err("bad filter method"); }
                    interlace = (((stbi__get8(s)) as i32) as i32);
                    if interlace > 1 { return stbi__err("bad interlace method"); }
                    if (*s).img_x == 0 || (*s).img_y == 0 { return stbi__err("0-pixel image"); }
                    if pal_img_n == 0 {
                        (*s).img_n = (((if (color & 2) != 0 { 3 } else { 1 }) + (if (color & 4) != 0 { 1 } else { 0 })) as i32);
                        if ((1 << 30) as u32) / (*s).img_x / (((*s).img_n) as u32) < (*s).img_y { return stbi__err("too large"); }
                        if scan == STBI__SCAN_header { return 1; }
                    } else {
                        (*s).img_n = ((1) as i32);
                        if ((1 << 30) as u32) / (*s).img_x / ((4) as u32) < (*s).img_y { return stbi__err("too large"); }
                    }
                }
            } else if c._type_ == ((((('P') as i32) << 24) + ((('L') as i32) << 16) + ((('T') as i32) << 8) + (('E') as i32)) as u32) {
                {
                    if (first) != 0 { return stbi__err("first not IHDR"); }
                    if c.length > ((256 * 3) as u32) { return stbi__err("invalid PLTE"); }
                    pal_len = ((c.length / ((3) as u32)) as u32);
                    if pal_len * ((3) as u32) != c.length { return stbi__err("invalid PLTE"); }
                    i = (((0) as u32) as u32);
                    while (i < pal_len) {
                        palette[(i * ((4) as u32) + ((0) as u32)) as usize] = ((stbi__get8(s)) as u8);
                        palette[(i * ((4) as u32) + ((1) as u32)) as usize] = ((stbi__get8(s)) as u8);
                        palette[(i * ((4) as u32) + ((2) as u32)) as usize] = ((stbi__get8(s)) as u8);
                        palette[(i * ((4) as u32) + ((3) as u32)) as usize] = (((255) as u8) as u8);
                        i += 1;
                    }
                }
            } else if c._type_ == ((((('t') as i32) << 24) + ((('R') as i32) << 16) + ((('N') as i32) << 8) + (('S') as i32)) as u32) {
                {
                    if (first) != 0 { return stbi__err("first not IHDR"); }
                    if ((*z).idata) != std::ptr::null_mut() { return stbi__err("tRNS after IDAT"); }
                    if (pal_img_n) != 0 {
                        if scan == STBI__SCAN_header {
                            (*s).img_n = ((4) as i32);
                            return 1;
                        }
                        if pal_len == ((0) as u32) { return stbi__err("tRNS before PLTE"); }
                        if c.length > pal_len { return stbi__err("bad tRNS len"); }
                        pal_img_n = (((4) as u8) as u8);
                        i = (((0) as u32) as u32);
                        while (i < c.length) {
                            palette[(i * ((4) as u32) + ((3) as u32)) as usize] = ((stbi__get8(s)) as u8);
                            i += 1;
                        }
                    } else {
                        if ((*s).img_n & 1) == 0 { return stbi__err("tRNS with alpha"); }
                        if c.length != (((*s).img_n) as u32) * ((2) as u32) { return stbi__err("bad tRNS len"); }
                        has_trans = (((1) as u8) as u8);
                        if (*z).depth == 16 {
                            k = ((0) as i32);
                            while (k < (*s).img_n) {
                                tc16[(k) as usize] = (((stbi__get16be(s)) as u16) as u16);
                                k += 1;
                            }
                        } else {
                            k = ((0) as i32);
                            while (k < (*s).img_n) {
                                tc[(k) as usize] = ((((((stbi__get16be(s) & 255) as u8) as i32) * ((stbi__depth_scale_table[((*z).depth) as usize]) as i32)) as u8) as u8);
                                k += 1;
                            }
                        }
                    }
                }
            } else if c._type_ == ((((('I') as i32) << 24) + ((('D') as i32) << 16) + ((('A') as i32) << 8) + (('T') as i32)) as u32) {
                {
                    if (first) != 0 { return stbi__err("first not IHDR"); }
                    if ((pal_img_n) as i32) != 0 && pal_len == 0 { return stbi__err("no PLTE"); }
                    if scan == STBI__SCAN_header {
                        (*s).img_n = (((pal_img_n) as i32) as i32);
                        return 1;
                    }
                    if ((ioff + c.length) as i32) < ((ioff) as i32) { return 0; }
                    if ioff + c.length > idata_limit {
                        let mut idata_limit_old: u32 = idata_limit;
                        let mut p: *mut u8;
                        if idata_limit == ((0) as u32) { idata_limit = ((if c.length > ((4096) as u32) { c.length } else { ((4096) as u32) }) as u32); }
                        while (ioff + c.length > idata_limit) { idata_limit *= (((2) as u32) as u32); }
                        p = c_runtime::realloc((*z).idata, (((idata_limit) as u64) as u64));
                        if p == (std::ptr::null_mut()) { return stbi__err("outofmem"); }
                        (*z).idata = p;
                    }
                    if stbi__getn(s, ((*z).idata).offset((ioff) as isize), (((c.length) as i32) as i32)) == 0 { return stbi__err("outofdata"); }
                    ioff += ((c.length) as u32);
                }
            } else if c._type_ == ((((('I') as i32) << 24) + ((('E') as i32) << 16) + ((('N') as i32) << 8) + (('D') as i32)) as u32) {
                {
                    let mut raw_len: u32 = std::mem::uninitialized();
                    let mut bpl: u32 = std::mem::uninitialized();
                    if (first) != 0 { return stbi__err("first not IHDR"); }
                    if scan != STBI__SCAN_load { return 1; }
                    if (*z).idata == (std::ptr::null_mut()) { return stbi__err("no IDAT"); }
                    bpl = ((((*s).img_x * (((*z).depth) as u32) + ((7) as u32)) / ((8) as u32)) as u32);
                    raw_len = ((bpl * (*s).img_y * (((*s).img_n) as u32) + (*s).img_y) as u32);
                    (*z).expanded = ((stbi_zlib_decode_malloc_guesssize_headerflag((((*z).idata) as *mut i8), (((ioff) as i32) as i32), (((raw_len) as i32) as i32), (((&mut raw_len) as *mut u32) as *mut i32), !is_iphone)) as *mut u8);
                    if (*z).expanded == (std::ptr::null_mut()) { return 0; }
                    c_runtime::free((*z).idata);
                    (*z).idata = (std::ptr::null_mut());
                    if (req_comp == (*s).img_n + 1 && req_comp != 3 && pal_img_n == 0) || ((has_trans) as i32) != 0 { (*s).img_out_n = (((*s).img_n + 1) as i32); } else { (*s).img_out_n = (((*s).img_n) as i32); }
                    if stbi__create_png_image(z, (*z).expanded, raw_len, (*s).img_out_n, (*z).depth, color, interlace) == 0 { return 0; }
                    if (has_trans) != 0 {
                        if (*z).depth == 16 {
                            if stbi__compute_transparency16(z, ((tc16.as_mut_ptr()) as *mut u16), (*s).img_out_n) == 0 { return 0; }
                        } else {
                            if stbi__compute_transparency(z, ((tc.as_mut_ptr()) as *mut u8), (*s).img_out_n) == 0 { return 0; }
                        }
                    }
                    if (is_iphone) != 0 && (stbi__de_iphone_flag) != 0 && (*s).img_out_n > 2 { stbi__de_iphone(z); }
                    if (pal_img_n) != 0 {
                        (*s).img_n = (((pal_img_n) as i32) as i32);
                        (*s).img_out_n = (((pal_img_n) as i32) as i32);
                        if req_comp >= 3 { (*s).img_out_n = ((req_comp) as i32); }
                        if stbi__expand_png_palette(z, ((palette.as_mut_ptr()) as *mut u8), (((pal_len) as i32) as i32), (*s).img_out_n) == 0 { return 0; }
                    } else {
                        if (has_trans) != 0 {
                            (*s).img_n += 1;
                        }
                    }
                    c_runtime::free((*z).expanded);
                    (*z).expanded = (std::ptr::null_mut());
                    return 1;
                }
            } else {
                if (first) != 0 { return stbi__err("first not IHDR"); }
                if (c._type_ & ((1 << 29) as u32)) == ((0) as u32) {
                    return stbi__err("XXXX PNG chunk not known");
                }
                stbi__skip(s, (((c.length) as i32) as i32));
            }
        }
        stbi__get32be(s);
    }
    return 0;
}

pub unsafe fn stbi__do_png(mut p: *mut stbi__png, mut x: *mut i32, mut y: *mut i32, mut n: *mut i32, mut req_comp: i32, mut ri: *mut stbi__result_info) -> *mut u8 {
    let mut result: *mut u8 = (std::ptr::null_mut());
    if req_comp < 0 || req_comp > 4 { return (if stbi__err("bad req_comp") != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
    if (stbi__parse_png_file(p, STBI__SCAN_load, req_comp)) != 0 {
        if (*p).depth < 8 { (*ri).bits_per_channel = ((8) as i32); } else { (*ri).bits_per_channel = (((*p).depth) as i32); }
        result = (*p)._out_;
        (*p)._out_ = (std::ptr::null_mut());
        if (req_comp) != 0 && req_comp != (*(*p).s).img_out_n {
            if (*ri).bits_per_channel == 8 { result = stbi__convert_format(result, (*(*p).s).img_out_n, req_comp, (*(*p).s).img_x, (*(*p).s).img_y); } else { result = stbi__convert_format16((((result) as *mut u16) as *mut u16), (*(*p).s).img_out_n, req_comp, (*(*p).s).img_x, (*(*p).s).img_y) as *mut u8; }
            (*(*p).s).img_out_n = ((req_comp) as i32);
            if result == (std::ptr::null_mut()) { return result; }
        }
        *x = ((((*(*p).s).img_x) as i32) as i32);
        *y = ((((*(*p).s).img_y) as i32) as i32);
        if (n) != std::ptr::null_mut() { *n = (((*(*p).s).img_n) as i32); }
    }
    c_runtime::free((*p)._out_);
    (*p)._out_ = (std::ptr::null_mut());
    c_runtime::free((*p).expanded);
    (*p).expanded = (std::ptr::null_mut());
    c_runtime::free((*p).idata);
    (*p).idata = (std::ptr::null_mut());
    return result;
}

pub unsafe fn stbi__png_load(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32, mut ri: *mut stbi__result_info) -> *mut u8 {
    let mut p: stbi__png = std::mem::uninitialized();
    p.s = s;
    return stbi__do_png(((&mut p) as *mut stbi__png), x, y, comp, req_comp, ri);
}

pub unsafe fn stbi__png_test(mut s: *mut stbi__context) -> i32 {
    let mut r: i32 = std::mem::uninitialized();
    r = ((stbi__check_png_header(s)) as i32);
    stbi__rewind(s);
    return r;
}

pub unsafe fn stbi__png_info_raw(mut p: *mut stbi__png, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
    if stbi__parse_png_file(p, STBI__SCAN_header, 0) == 0 {
        stbi__rewind((*p).s);
        return 0;
    }
    if (x) != std::ptr::null_mut() { *x = ((((*(*p).s).img_x) as i32) as i32); }
    if (y) != std::ptr::null_mut() { *y = ((((*(*p).s).img_y) as i32) as i32); }
    if (comp) != std::ptr::null_mut() { *comp = (((*(*p).s).img_n) as i32); }
    return 1;
}

pub unsafe fn stbi__png_info(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
    let mut p: stbi__png = std::mem::uninitialized();
    p.s = s;
    return stbi__png_info_raw(((&mut p) as *mut stbi__png), x, y, comp);
}

pub unsafe fn stbi__info_main(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
    if (stbi__png_info(s, x, y, comp)) != 0 { return 1; }
    return stbi__err("unknown image type");
}

pub unsafe fn stbi_info_from_memory(mut buffer: *mut u8, mut len: i32, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
    let mut s: stbi__context = std::mem::uninitialized();
    stbi__start_mem(((&mut s) as *mut stbi__context), buffer, len);
    return stbi__info_main(((&mut s) as *mut stbi__context), x, y, comp);
}

pub unsafe fn stbi_info_from_callbacks(mut c: *mut stbi_io_callbacks, mut user: *mut u8, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
    let mut s: stbi__context = std::mem::uninitialized();
    stbi__start_callbacks(((&mut s) as *mut stbi__context), ((c) as *mut stbi_io_callbacks), user);
    return stbi__info_main(((&mut s) as *mut stbi__context), x, y, comp);
}

static stbi__g_failure_reason: &'static str = "";

#[derive(Clone, Copy)]
pub struct stbi_io_callbacks {
    read: Option<fn(*mut u8, *mut i8, i32) -> i32>,
    skip: fn(*mut u8, i32),
    eof: fn(*mut u8) -> i32,
}

struct stbi__resample {
    resample: unsafe fn(*mut u8, *mut u8, *mut u8, i32, i32) -> *mut u8,
    line0: *mut u8,
    line1: *mut u8,
    hs: i32,
    vs: i32,
    w_lores: i32,
    ystep: i32,
    ypos: i32,
}

struct stbi__jpeg {
    /*    s: *mut stbi__context,
    huff_dc: [stbi__huffman; 4],
    huff_ac: [stbi__huffman; 4],
    dequant: [[u16; 64]; 4],
    fast_ac: [[i16; 512]; 4],
    img_h_max: i32,
    img_v_max: i32,
    img_mcu_x: i32,
    img_mcu_y: i32,
    img_mcu_w: i32,
    img_mcu_h: i32,
    img_comp: [img_comp; 4],
    code_buffer: u32,
    code_bits: i32,
    marker: u8,
    nomore: i32,
    progressive: i32,
    spec_start: i32,
    spec_end: i32,
    succ_high: i32,
    succ_low: i32,
    eob_run: i32,
    jfif: i32,
    app14_color_transform: i32,
    rgb: i32,
    scan_n: i32,
    order: [i32; 4],
    restart_interval: i32,
    todo: i32,
    idct_block_kernel: unsafe fn(*mut u8, i32, *mut i16),
    YCbCr_to_RGB_kernel: unsafe fn(*mut u8, *mut u8, *mut u8, *mut u8, i32, i32),
    resample_row_hv_2_kernel: unsafe fn(*mut u8, *mut u8, *mut u8, i32, i32)*/
}

unsafe fn stbi__tga_test(s: *mut stbi__context) -> i32 {
    /*    let res: i32 = (i32)(0);
    let sz: i32;
    let tga_color_type: i32;
    stbi__get8(s);
    tga_color_type = (i32)(stbi__get8(s));
    if tga_color_type > 1 { goto errorEnd; }
    sz = (i32)(stbi__get8(s));
    if tga_color_type == 1 {
        if sz != 1 && sz != 9 { goto errorEnd; }
        stbi__skip(s, 4);
        sz = (i32)(stbi__get8(s));
        if sz != 8 && sz != 15 && sz != 16 && sz != 24 && sz != 32 { goto errorEnd; }
        stbi__skip(s, 4);
    } else {
        if sz != 2 && sz != 3 && sz != 10 && sz != 11 { goto errorEnd; }
        stbi__skip(s, 9);
    }
    if stbi__get16le(s) < 1 { goto errorEnd; }
    if stbi__get16le(s) < 1 { goto errorEnd; }
    sz = (i32)(stbi__get8(s));
    if tga_color_type == 1 && sz != 8 && sz != 16 { goto errorEnd; }
    if sz != 8 && sz != 15 && sz != 16 && sz != 24 && sz != 32 { goto errorEnd; }
    res = (i32)(1);
    errorEnd: ;
    stbi__rewind(s);
    return (i32)(res);*/
    return 0;
}

pub fn stbi__err(s: &str) -> i32 {
//    stbi__g_failure_reason = s;
    return 0;
}