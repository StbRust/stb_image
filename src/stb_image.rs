// Generated by Ur at 12.08.2018 18:45:14

use std;
use c_runtime;

pub const STBI_default: i32 = 0;
pub const STBI_grey: i32 = 1;
pub const STBI_grey_alpha: i32 = 2;
pub const STBI_rgb: i32 = 3;
pub const STBI_rgb_alpha: i32 = 4;
pub const STBI_ORDER_RGB: i32 = 0;
pub const STBI_ORDER_BGR: i32 = 1;
pub const STBI__SCAN_load: i32 = 0;
pub const STBI__SCAN_type: i32 = 1;
pub const STBI__SCAN_header: i32 = 2;
pub const STBI__F_none: i32 = 0;
pub const STBI__F_sub: i32 = 1;
pub const STBI__F_up: i32 = 2;
pub const STBI__F_avg: i32 = 3;
pub const STBI__F_paeth: i32 = 4;
pub const STBI__F_avg_first: i32 = 5;
pub const STBI__F_paeth_first: i32 = 6;

pub static mut stbi__vertically_flip_on_load: i32 = 0;
pub static mut stbi__h2l_gamma_i: f32 = 1.0f32 / 2.2f32;
pub static mut stbi__h2l_scale_i: f32 = 1.0f32;
pub static mut stbi__bmask: [u32; 17] = [((0) as u32), ((1) as u32), ((3) as u32), ((7) as u32), ((15) as u32), ((31) as u32), ((63) as u32), ((127) as u32), ((255) as u32), ((511) as u32), ((1023) as u32), ((2047) as u32), ((4095) as u32), ((8191) as u32), ((16383) as u32), ((32767) as u32), ((65535) as u32)];
pub static mut stbi__jbias: [i32; 16] = [0, -1, -3, -7, -15, -31, -63, -127, -255, -511, -1023, -2047, -4095, -8191, -16383, -32767];
pub static mut stbi__jpeg_dezigzag: [u8; 79] = [((0) as u8), ((1) as u8), ((8) as u8), ((16) as u8), ((9) as u8), ((2) as u8), ((3) as u8), ((10) as u8), ((17) as u8), ((24) as u8), ((32) as u8), ((25) as u8), ((18) as u8), ((11) as u8), ((4) as u8), ((5) as u8), ((12) as u8), ((19) as u8), ((26) as u8), ((33) as u8), ((40) as u8), ((48) as u8), ((41) as u8), ((34) as u8), ((27) as u8), ((20) as u8), ((13) as u8), ((6) as u8), ((7) as u8), ((14) as u8), ((21) as u8), ((28) as u8), ((35) as u8), ((42) as u8), ((49) as u8), ((56) as u8), ((57) as u8), ((50) as u8), ((43) as u8), ((36) as u8), ((29) as u8), ((22) as u8), ((15) as u8), ((23) as u8), ((30) as u8), ((37) as u8), ((44) as u8), ((51) as u8), ((58) as u8), ((59) as u8), ((52) as u8), ((45) as u8), ((38) as u8), ((31) as u8), ((39) as u8), ((46) as u8), ((53) as u8), ((60) as u8), ((61) as u8), ((54) as u8), ((47) as u8), ((55) as u8), ((62) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8), ((63) as u8)];
pub static mut stbi__zlength_base: [i32; 31] = [3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31, 35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0];
pub static mut stbi__zlength_extra: [i32; 31] = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 0, 0, 0];
pub static mut stbi__zdist_base: [i32; 32] = [1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193, 257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145, 8193, 12289, 16385, 24577, 0, 0];
pub static mut stbi__zdist_extra: [i32; 30] = [0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13];
pub static mut length_dezigzag: [u8; 19] = [((16) as u8), ((17) as u8), ((18) as u8), ((0) as u8), ((8) as u8), ((7) as u8), ((9) as u8), ((6) as u8), ((10) as u8), ((5) as u8), ((11) as u8), ((4) as u8), ((12) as u8), ((3) as u8), ((13) as u8), ((2) as u8), ((14) as u8), ((1) as u8), ((15) as u8)];
pub static mut stbi__zdefault_length: [u8; 288] = [((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((9) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((7) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8), ((8) as u8)];
pub static mut stbi__zdefault_distance: [u8; 32] = [((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8), ((5) as u8)];
pub static mut png_sig: [u8; 8] = [((137) as u8), ((80) as u8), ((78) as u8), ((71) as u8), ((13) as u8), ((10) as u8), ((26) as u8), ((10) as u8)];
pub static mut first_row_filter: [i32; 5] = [STBI__F_none, STBI__F_sub, STBI__F_none, STBI__F_avg_first, STBI__F_paeth_first];
pub static mut stbi__depth_scale_table: [u8; 9] = [((0) as u8), ((0xff) as u8), ((0x55) as u8), ((0) as u8), ((0x11) as u8), ((0) as u8), ((0) as u8), ((0) as u8), ((0x01) as u8)];
pub static mut stbi__unpremultiply_on_load: i32 = 0;
pub static mut stbi__de_iphone_flag: i32 = 0;

pub struct stbi__context {
	img_x: u32,
	img_y: u32,
	img_n: i32,
	img_out_n: i32,
	io: stbi_io_callbacks,
	io_user_data: *mut u8,
	read_from_callbacks: i32,
	buflen: i32,
	buffer_start: [u8; 128],
	img_buffer: *mut u8,
	img_buffer_end: *mut u8,
	img_buffer_original: *mut u8,
	img_buffer_original_end: *mut u8,
}

pub struct stbi__result_info {
	bits_per_channel: i32,
	num_channels: i32,
	channel_order: i32,
}

pub struct stbi__huffman {
	fast: [u8; 512],
	code: [u16; 256],
	values: [u8; 256],
	size: [u8; 257],
	maxcode: [u32; 18],
	delta: [i32; 17],
}

pub struct img_comp {
	id: i32,
	h: i32,
	v: i32,
	tq: i32,
	hd: i32,
	ha: i32,
	dc_pred: i32,
	x: i32,
	y: i32,
	w2: i32,
	h2: i32,
	data: *mut u8,
	raw_data: *mut u8,
	raw_coeff: *mut u8,
	linebuf: *mut u8,
	coeff: *mut i16,
	coeff_w: i32,
	coeff_h: i32,
}

pub struct stbi__zhuffman {
	fast: [u16; 512],
	firstcode: [u16; 16],
	maxcode: [i32; 17],
	firstsymbol: [u16; 16],
	size: [u8; 288],
	value: [u16; 288],
}

pub struct stbi__zbuf {
	zbuffer: *mut u8,
	zbuffer_end: *mut u8,
	num_bits: i32,
	code_buffer: u32,
	zout: *mut i8,
	zout_start: *mut i8,
	zout_end: *mut i8,
	z_expandable: i32,
	z_length: stbi__zhuffman,
	z_distance: stbi__zhuffman,
}

pub struct stbi__pngchunk {
	length: u32,
	_type_: u32,
}

pub struct stbi__png {
	s: *mut stbi__context,
	idata: *mut u8,
	expanded: *mut u8,
	_out_: *mut u8,
	depth: i32,
}

pub struct stbi__bmp_data {
	bpp: i32,
	offset: i32,
	hsz: i32,
	mr: u32,
	mg: u32,
	mb: u32,
	ma: u32,
	all_a: u32,
}

pub struct stbi__gif_lzw {
	prefix: i16,
	first: u8,
	suffix: u8,
}

pub struct stbi__gif {
	w: i32,
	h: i32,
	_out_: *mut u8,
	old_out: *mut u8,
	flags: i32,
	bgindex: i32,
	ratio: i32,
	transparent: i32,
	eflags: i32,
	delay: i32,
	pal: [[u8; 4]; 256],
	lpal: [[u8; 4]; 256],
	codes: [stbi__gif_lzw; 4096],
	color_table: *mut u8,
	parse: i32,
	step: i32,
	lflags: i32,
	start_x: i32,
	start_y: i32,
	max_x: i32,
	max_y: i32,
	cur_x: i32,
	cur_y: i32,
	line_size: i32,
}

pub unsafe fn stbi__start_mem(mut s: *mut stbi__context, mut buffer: *mut u8, mut len: i32) {
	(*s).io.read = None;
	(*s).read_from_callbacks = ((0) as i32);
	(*s).img_buffer = buffer;
	(*s).img_buffer_original = buffer;
	(*s).img_buffer_end = (buffer).offset((len) as isize);
	(*s).img_buffer_original_end = (buffer).offset((len) as isize);
}

pub unsafe fn stbi__start_callbacks(mut s: *mut stbi__context, mut c: *mut stbi_io_callbacks, mut user: *mut u8) {
	(*s).io = ((*c) as stbi_io_callbacks);
	(*s).io_user_data = user;
	(*s).buflen = (((*s).buffer_start.len() as i32) as i32);
	(*s).read_from_callbacks = ((1) as i32);
	(*s).img_buffer_original = (*s).buffer_start.as_mut_ptr();
	stbi__refill_buffer(((s) as *mut stbi__context));
	(*s).img_buffer_original_end = (*s).img_buffer_end;
}

pub unsafe fn stbi__rewind(mut s: *mut stbi__context) {
	(*s).img_buffer = (*s).img_buffer_original;
	(*s).img_buffer_end = (*s).img_buffer_original_end;
}

pub unsafe fn stbi__malloc(mut size: u64) -> *mut u8 {
	return c_runtime::malloc(((size) as u64));
}

pub unsafe fn stbi__addsizes_valid(mut a: i32, mut b: i32) -> i32 {
	if b < 0 { return 0; }
	return (a <= 2147483647 - b) as i32;
}

pub unsafe fn stbi__mul2sizes_valid(mut a: i32, mut b: i32) -> i32 {
	if a < 0 || b < 0 { return 0; }
	if b == 0 { return 1; }
	return (a <= 2147483647 / b) as i32;
}

pub unsafe fn stbi__mad2sizes_valid(mut a: i32, mut b: i32, mut add: i32) -> i32 {
	return ((stbi__mul2sizes_valid(((a) as i32), ((b) as i32))) != 0 && (stbi__addsizes_valid(((a * b) as i32), ((add) as i32))) != 0) as i32;
}

pub unsafe fn stbi__mad3sizes_valid(mut a: i32, mut b: i32, mut c: i32, mut add: i32) -> i32 {
	return ((stbi__mul2sizes_valid(((a) as i32), ((b) as i32))) != 0 && (stbi__mul2sizes_valid(((a * b) as i32), ((c) as i32))) != 0 && (stbi__addsizes_valid(((a * b * c) as i32), ((add) as i32))) != 0) as i32;
}

pub unsafe fn stbi__mad4sizes_valid(mut a: i32, mut b: i32, mut c: i32, mut d: i32, mut add: i32) -> i32 {
	return ((stbi__mul2sizes_valid(((a) as i32), ((b) as i32))) != 0 && (stbi__mul2sizes_valid(((a * b) as i32), ((c) as i32))) != 0 && (stbi__mul2sizes_valid(((a * b * c) as i32), ((d) as i32))) != 0 && (stbi__addsizes_valid(((a * b * c * d) as i32), ((add) as i32))) != 0) as i32;
}

pub unsafe fn stbi__malloc_mad2(mut a: i32, mut b: i32, mut add: i32) -> *mut u8 {
	if stbi__mad2sizes_valid(((a) as i32), ((b) as i32), ((add) as i32)) == 0 { return (std::ptr::null_mut()); }
	return stbi__malloc((((a * b + add) as u64) as u64));
}

pub unsafe fn stbi__malloc_mad3(mut a: i32, mut b: i32, mut c: i32, mut add: i32) -> *mut u8 {
	if stbi__mad3sizes_valid(((a) as i32), ((b) as i32), ((c) as i32), ((add) as i32)) == 0 { return (std::ptr::null_mut()); }
	return stbi__malloc((((a * b * c + add) as u64) as u64));
}

pub unsafe fn stbi__malloc_mad4(mut a: i32, mut b: i32, mut c: i32, mut d: i32, mut add: i32) -> *mut u8 {
	if stbi__mad4sizes_valid(((a) as i32), ((b) as i32), ((c) as i32), ((d) as i32), ((add) as i32)) == 0 { return (std::ptr::null_mut()); }
	return stbi__malloc((((a * b * c * d + add) as u64) as u64));
}

pub unsafe fn stbi_image_free(mut retval_from_stbi_load: *mut u8) {
	c_runtime::free(((retval_from_stbi_load) as *mut u8));
}

pub unsafe fn stbi_set_flip_vertically_on_load(mut flag_true_if_should_flip: i32) {
	stbi__vertically_flip_on_load = ((flag_true_if_should_flip) as i32);
}

pub unsafe fn stbi__load_main(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32, mut ri: *mut stbi__result_info, mut bpc: i32) -> *mut u8 {
	(*ri).bits_per_channel = ((8) as i32);
	(*ri).channel_order = ((STBI_ORDER_RGB) as i32);
	(*ri).num_channels = ((0) as i32);
	if (stbi__jpeg_test(((s) as *mut stbi__context))) != 0 { return stbi__jpeg_load(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32), ((req_comp) as i32), ((ri) as *mut stbi__result_info)); }
	if (stbi__png_test(((s) as *mut stbi__context))) != 0 { return stbi__png_load(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32), ((req_comp) as i32), ((ri) as *mut stbi__result_info)); }
	if (stbi__bmp_test(((s) as *mut stbi__context))) != 0 { return stbi__bmp_load(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32), ((req_comp) as i32), ((ri) as *mut stbi__result_info)); }
	if (stbi__gif_test(((s) as *mut stbi__context))) != 0 { return stbi__gif_load(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32), ((req_comp) as i32), ((ri) as *mut stbi__result_info)); }
	if (stbi__psd_test(((s) as *mut stbi__context))) != 0 { return stbi__psd_load(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32), ((req_comp) as i32), ((ri) as *mut stbi__result_info), ((bpc) as i32)); }
	if (stbi__tga_test(((s) as *mut stbi__context))) != 0 { return stbi__tga_load(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32), ((req_comp) as i32), ((ri) as *mut stbi__result_info)); }
	return (if stbi__err((("unknown image type"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
}

pub unsafe fn stbi__convert_16_to_8(mut orig: *mut u16, mut w: i32, mut h: i32, mut channels: i32) -> *mut u8 {
	let mut i: i32 = std::mem::uninitialized();
	let mut img_len: i32 = w * h * channels;
	let mut reduced: *mut u8;
	reduced = stbi__malloc((((img_len) as u64) as u64));
	if reduced == (std::ptr::null_mut()) { return (if stbi__err((("outofmem"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	i = ((0) as i32);
	while (i < img_len) {
		*reduced.offset((i) as isize) = ((((((*orig.offset((i) as isize)) as i32) >> 8) & 0xFF) as u8) as u8);
		i += 1;
	}
	c_runtime::free(((orig) as *mut u16));
	return reduced;
}

pub unsafe fn stbi__convert_8_to_16(mut orig: *mut u8, mut w: i32, mut h: i32, mut channels: i32) -> *mut u16 {
	let mut i: i32 = std::mem::uninitialized();
	let mut img_len: i32 = w * h * channels;
	let mut enlarged: *mut u16;
	enlarged = ((stbi__malloc((((img_len * 2) as u64) as u64))) as *mut u16);
	if enlarged == (std::ptr::null_mut()) { return ((if stbi__err((("outofmem"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }) as *mut u16); }
	i = ((0) as i32);
	while (i < img_len) {
		*enlarged.offset((i) as isize) = ((((((*orig.offset((i) as isize)) as i32) << 8) + ((*orig.offset((i) as isize)) as i32)) as u16) as u16);
		i += 1;
	}
	c_runtime::free(((orig) as *mut u8));
	return enlarged;
}

pub unsafe fn stbi__vertical_flip(mut image: *mut u8, mut w: i32, mut h: i32, mut bytes_per_pixel: i32) {
	let mut row: i32 = std::mem::uninitialized();
	let mut bytes_per_row: u64 = ((w) as u64) * ((bytes_per_pixel) as u64);
	let mut temp: [u8; 2048] = std::mem::uninitialized();
	let mut bytes: *mut u8 = image;
	row = ((0) as i32);
	while (row < (h >> 1)) {
		let mut row0: i32 = ((((row) as u64) * bytes_per_row) as i32);
		let mut row1: i32 = ((((h - row - 1) as u64) * bytes_per_row) as i32);
		let mut bytes_left: u64 = bytes_per_row;
		while ((bytes_left) != 0) {
			let mut bytes_copy: u64 = if (bytes_left < ((2048) as u64)) { bytes_left } else { ((2048) as u64) };
			c_runtime::memcpy(((temp.as_mut_ptr()) as *mut u8), (((bytes).offset((row0) as isize)) as *mut u8), ((bytes_copy) as u64));
			c_runtime::memcpy((((bytes).offset((row0) as isize)) as *mut u8), (((bytes).offset((row1) as isize)) as *mut u8), ((bytes_copy) as u64));
			c_runtime::memcpy((((bytes).offset((row1) as isize)) as *mut u8), ((temp.as_mut_ptr()) as *mut u8), ((bytes_copy) as u64));
			row0 += ((bytes_copy) as i32);
			row1 += ((bytes_copy) as i32);
			bytes_left -= ((bytes_copy) as u64);
		}
		row += 1;
	}
}

pub unsafe fn stbi__load_and_postprocess_8bit(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32) -> *mut u8 {
	let mut ri: stbi__result_info = std::mem::uninitialized();
	let mut result: *mut u8 = stbi__load_main(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32), ((req_comp) as i32), ((&mut ri) as *mut stbi__result_info), ((8) as i32));
	if result == (std::ptr::null_mut()) { return (std::ptr::null_mut()); }
	if ri.bits_per_channel != 8 {
		let mut cmp: i32 = req_comp;
		if cmp == 0 { cmp = ((*comp) as i32); }
		result = stbi__convert_16_to_8((((result) as *mut u16) as *mut u16), ((*x) as i32), ((*y) as i32), ((cmp) as i32));
		ri.bits_per_channel = ((8) as i32);
	}
	if (stbi__vertically_flip_on_load) != 0 {
		let mut channels: i32 = if (req_comp) != 0 { req_comp } else { *comp };
		stbi__vertical_flip(((result) as *mut u8), ((*x) as i32), ((*y) as i32), ((channels) as i32));
	}
	return result;
}

pub unsafe fn stbi__load_and_postprocess_16bit(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32) -> *mut u16 {
	let mut ri: stbi__result_info = std::mem::uninitialized();
	let mut result: *mut u8 = stbi__load_main(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32), ((req_comp) as i32), ((&mut ri) as *mut stbi__result_info), ((16) as i32));
	if result == (std::ptr::null_mut()) { return (std::ptr::null_mut()); }
	if ri.bits_per_channel != 16 {
		let mut cmp: i32 = req_comp;
		if cmp == 0 { cmp = ((*comp) as i32); }
		result = stbi__convert_8_to_16(((result) as *mut u8), ((*x) as i32), ((*y) as i32), ((cmp) as i32)) as *mut u8;
		ri.bits_per_channel = ((16) as i32);
	}
	if (stbi__vertically_flip_on_load) != 0 {
		let mut channels: i32 = if (req_comp) != 0 { req_comp } else { *comp };
		stbi__vertical_flip(((result) as *mut u8), ((*x) as i32), ((*y) as i32), ((channels * 2) as i32));
	}
	return ((result) as *mut u16);
}

pub unsafe fn stbi_load_16_from_memory(mut buffer: *mut u8, mut len: i32, mut x: *mut i32, mut y: *mut i32, mut channels_in_file: *mut i32, mut desired_channels: i32) -> *mut u16 {
	let mut s: stbi__context = std::mem::uninitialized();
	stbi__start_mem(((&mut s) as *mut stbi__context), ((buffer) as *mut u8), ((len) as i32));
	return stbi__load_and_postprocess_16bit(((&mut s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((channels_in_file) as *mut i32), ((desired_channels) as i32));
}

pub unsafe fn stbi_load_16_from_callbacks(mut clbk: *mut stbi_io_callbacks, mut user: *mut u8, mut x: *mut i32, mut y: *mut i32, mut channels_in_file: *mut i32, mut desired_channels: i32) -> *mut u16 {
	let mut s: stbi__context = std::mem::uninitialized();
	stbi__start_callbacks(((&mut s) as *mut stbi__context), ((clbk) as *mut stbi_io_callbacks), ((user) as *mut u8));
	return stbi__load_and_postprocess_16bit(((&mut s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((channels_in_file) as *mut i32), ((desired_channels) as i32));
}

pub unsafe fn stbi_load_from_memory(mut buffer: *mut u8, mut len: i32, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32) -> *mut u8 {
	let mut s: stbi__context = std::mem::uninitialized();
	stbi__start_mem(((&mut s) as *mut stbi__context), ((buffer) as *mut u8), ((len) as i32));
	return stbi__load_and_postprocess_8bit(((&mut s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32), ((req_comp) as i32));
}

pub unsafe fn stbi_load_from_callbacks(mut clbk: *mut stbi_io_callbacks, mut user: *mut u8, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32) -> *mut u8 {
	let mut s: stbi__context = std::mem::uninitialized();
	stbi__start_callbacks(((&mut s) as *mut stbi__context), ((clbk) as *mut stbi_io_callbacks), ((user) as *mut u8));
	return stbi__load_and_postprocess_8bit(((&mut s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32), ((req_comp) as i32));
}

pub unsafe fn stbi_is_hdr_from_memory(mut buffer: *mut u8, mut len: i32) -> i32 {
	return 0;
}

pub unsafe fn stbi_is_hdr_from_callbacks(mut clbk: *mut stbi_io_callbacks, mut user: *mut u8) -> i32 {
	return 0;
}

pub unsafe fn stbi_hdr_to_ldr_gamma(mut gamma: f32) {
	stbi__h2l_gamma_i = ((((1) as f32) / gamma) as f32);
}

pub unsafe fn stbi_hdr_to_ldr_scale(mut scale: f32) {
	stbi__h2l_scale_i = ((((1) as f32) / scale) as f32);
}

pub unsafe fn stbi__refill_buffer(mut s: *mut stbi__context) {
	let mut n: i32 = ((*s).io.read.unwrap())((((*s).io_user_data) as *mut u8), ((((*s).buffer_start.as_mut_ptr()) as *mut i8) as *mut i8), (((*s).buflen) as i32));
	if n == 0 {
		(*s).read_from_callbacks = ((0) as i32);
		(*s).img_buffer = (*s).buffer_start.as_mut_ptr();
		(*s).img_buffer_end = ((*s).buffer_start.as_mut_ptr()).offset((1) as isize);
		*(*s).img_buffer = (((0) as u8) as u8);
	} else {
		(*s).img_buffer = (*s).buffer_start.as_mut_ptr();
		(*s).img_buffer_end = ((*s).buffer_start.as_mut_ptr()).offset((n) as isize);
	}
}

pub unsafe fn stbi__get8(mut s: *mut stbi__context) -> u8 {
	if (*s).img_buffer < (*s).img_buffer_end {
		let mut res: u8 = *(*s).img_buffer;
		((*s).img_buffer = (*s).img_buffer.offset(1));
		return res;
	}
	if ((*s).read_from_callbacks) != 0 {
		stbi__refill_buffer(((s) as *mut stbi__context));
		let mut res: u8 = *(*s).img_buffer;
		((*s).img_buffer = (*s).img_buffer.offset(1));
		return res;
	}
	return ((0) as u8);
}

pub unsafe fn stbi__at_eof(mut s: *mut stbi__context) -> i32 {
	if ((*s).io.read.is_some()) {
		if ((*s).io.eof)((((*s).io_user_data) as *mut u8)) == 0 { return 0; }
		if (*s).read_from_callbacks == 0 { return 1; }
	}
	return ((*s).img_buffer >= (*s).img_buffer_end) as i32;
}

pub unsafe fn stbi__skip(mut s: *mut stbi__context, mut n: i32) {
	if n < 0 {
		(*s).img_buffer = (*s).img_buffer_end;
		return;
	}
	if ((*s).io.read.is_some()) {
		let mut blen: i32 = (((((*s).img_buffer_end) as usize) - (((*s).img_buffer) as usize)) as i32);
		if blen < n {
			(*s).img_buffer = (*s).img_buffer_end;
			((*s).io.skip)((((*s).io_user_data) as *mut u8), ((n - blen) as i32));
			return;
		}
	}
	(*s).img_buffer = (*s).img_buffer.offset((((n) as *mut u8)) as isize);
}

pub unsafe fn stbi__getn(mut s: *mut stbi__context, mut buffer: *mut u8, mut n: i32) -> i32 {
	if ((*s).io.read.is_some()) {
		let mut blen: i32 = (((((*s).img_buffer_end) as usize) - (((*s).img_buffer) as usize)) as i32);
		if blen < n {
			let mut res: i32 = std::mem::uninitialized();
			let mut count: i32 = std::mem::uninitialized();
			c_runtime::memcpy(((buffer) as *mut u8), (((*s).img_buffer) as *mut u8), (((blen) as u64) as u64));
			count = ((((*s).io.read.unwrap())((((*s).io_user_data) as *mut u8), (((((buffer) as *mut i8)).offset((blen) as isize)) as *mut i8), ((n - blen) as i32))) as i32);
			res = ((count == (n - blen)) as i32);
			(*s).img_buffer = (*s).img_buffer_end;
			return res;
		}
	}
	if ((*s).img_buffer).offset((n) as isize) <= (*s).img_buffer_end {
		c_runtime::memcpy(((buffer) as *mut u8), (((*s).img_buffer) as *mut u8), (((n) as u64) as u64));
		(*s).img_buffer = (*s).img_buffer.offset((((n) as *mut u8)) as isize);
		return 1;
	} else { return 0; }
}

pub unsafe fn stbi__get16be(mut s: *mut stbi__context) -> i32 {
	let mut z: i32 = ((stbi__get8(((s) as *mut stbi__context))) as i32);
	return (z << 8) + ((stbi__get8(((s) as *mut stbi__context))) as i32);
}

pub unsafe fn stbi__get32be(mut s: *mut stbi__context) -> u32 {
	let mut z: u32 = ((stbi__get16be(((s) as *mut stbi__context))) as u32);
	return (z << 16) + ((stbi__get16be(((s) as *mut stbi__context))) as u32);
}

pub unsafe fn stbi__get16le(mut s: *mut stbi__context) -> i32 {
	let mut z: i32 = ((stbi__get8(((s) as *mut stbi__context))) as i32);
	return z + (((stbi__get8(((s) as *mut stbi__context))) as i32) << 8);
}

pub unsafe fn stbi__get32le(mut s: *mut stbi__context) -> u32 {
	let mut z: u32 = ((stbi__get16le(((s) as *mut stbi__context))) as u32);
	return z + ((stbi__get16le(((s) as *mut stbi__context)) << 16) as u32);
}

pub unsafe fn stbi__compute_y(mut r: i32, mut g: i32, mut b: i32) -> u8 {
	return ((((r * 77) + (g * 150) + (29 * b)) >> 8) as u8);
}

pub unsafe fn stbi__convert_format(mut data: *mut u8, mut img_n: i32, mut req_comp: i32, mut x: u32, mut y: u32) -> *mut u8 {
	let mut i: i32 = std::mem::uninitialized();
	let mut j: i32 = std::mem::uninitialized();
	let mut good: *mut u8;
	if req_comp == img_n { return data; }
	good = stbi__malloc_mad3(((req_comp) as i32), (((x) as i32) as i32), (((y) as i32) as i32), ((0) as i32));
	if good == (std::ptr::null_mut()) {
		c_runtime::free(((data) as *mut u8));
		return (if stbi__err((("outofmem"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
	}
	j = ((0) as i32);
	while (j < ((y) as i32)) {
		let mut src: i32 = ((((j) as u32) * x * ((img_n) as u32)) as i32);
		let mut dest: i32 = ((((j) as u32) * x * ((req_comp) as u32)) as i32);
		{
			if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (2)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u8);
					*good.offset((dest + 1) as isize) = (((255) as u8) as u8);
					i -= 1;
					src += ((1) as i32);
					dest += ((2) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (3)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 1) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 2) as isize) = *data.offset((src) as isize);
					i -= 1;
					src += ((1) as i32);
					dest += ((3) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (4)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 1) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 2) as isize) = *data.offset((src) as isize);
					i -= 1;
					src += ((1) as i32);
					dest += ((4) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (1)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u8);
					i -= 1;
					src += ((2) as i32);
					dest += ((1) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (3)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 1) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 2) as isize) = *data.offset((src) as isize);
					i -= 1;
					src += ((2) as i32);
					dest += ((3) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (4)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 1) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 2) as isize) = *data.offset((src) as isize);
					i -= 1;
					src += ((2) as i32);
					dest += ((4) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (4)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u8);
					*good.offset((dest + 1) as isize) = ((*data.offset((src + 1) as isize)) as u8);
					*good.offset((dest + 2) as isize) = ((*data.offset((src + 2) as isize)) as u8);
					i -= 1;
					src += ((3) as i32);
					dest += ((4) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (1)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((stbi__compute_y((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u8);
					i -= 1;
					src += ((3) as i32);
					dest += ((1) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (2)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((stbi__compute_y((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u8);
					*good.offset((dest + 1) as isize) = (((255) as u8) as u8);
					i -= 1;
					src += ((3) as i32);
					dest += ((2) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (1)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((stbi__compute_y((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u8);
					i -= 1;
					src += ((4) as i32);
					dest += ((1) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (2)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((stbi__compute_y((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u8);
					i -= 1;
					src += ((4) as i32);
					dest += ((2) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (3)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u8);
					*good.offset((dest + 1) as isize) = ((*data.offset((src + 1) as isize)) as u8);
					*good.offset((dest + 2) as isize) = ((*data.offset((src + 2) as isize)) as u8);
					i -= 1;
					src += ((4) as i32);
					dest += ((3) as i32);
				}
			} else { return (if stbi__err((("0"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
		}
		j += 1;
	}
	c_runtime::free(((data) as *mut u8));
	return good;
}

pub unsafe fn stbi__compute_y_16(mut r: i32, mut g: i32, mut b: i32) -> u16 {
	return ((((r * 77) + (g * 150) + (29 * b)) >> 8) as u16);
}

pub unsafe fn stbi__convert_format16(mut data: *mut u16, mut img_n: i32, mut req_comp: i32, mut x: u32, mut y: u32) -> *mut u16 {
	let mut i: i32 = std::mem::uninitialized();
	let mut j: i32 = std::mem::uninitialized();
	let mut good: *mut u16;
	if req_comp == img_n { return data; }
	good = ((stbi__malloc((((((req_comp) as u32) * x * y * ((2) as u32)) as u64) as u64))) as *mut u16);
	if good == (std::ptr::null_mut()) {
		c_runtime::free(((data) as *mut u16));
		return ((if stbi__err((("outofmem"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }) as *mut u16);
	}
	j = ((0) as i32);
	while (j < ((y) as i32)) {
		let mut src: i32 = ((((j) as u32) * x * ((img_n) as u32)) as i32);
		let mut dest: i32 = ((((j) as u32) * x * ((req_comp) as u32)) as i32);
		{
			if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (2)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u16);
					*good.offset((dest + 1) as isize) = (((0xffff) as u16) as u16);
					i -= 1;
					src += ((1) as i32);
					dest += ((2) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (3)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 1) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 2) as isize) = *data.offset((src) as isize);
					i -= 1;
					src += ((1) as i32);
					dest += ((3) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (4)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 1) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 2) as isize) = *data.offset((src) as isize);
					i -= 1;
					src += ((1) as i32);
					dest += ((4) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (1)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u16);
					i -= 1;
					src += ((2) as i32);
					dest += ((1) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (3)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 1) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 2) as isize) = *data.offset((src) as isize);
					i -= 1;
					src += ((2) as i32);
					dest += ((3) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (4)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 1) as isize) = *data.offset((src) as isize);
					*good.offset((dest + 2) as isize) = *data.offset((src) as isize);
					i -= 1;
					src += ((2) as i32);
					dest += ((4) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (4)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u16);
					*good.offset((dest + 1) as isize) = ((*data.offset((src + 1) as isize)) as u16);
					*good.offset((dest + 2) as isize) = ((*data.offset((src + 2) as isize)) as u16);
					i -= 1;
					src += ((3) as i32);
					dest += ((4) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (1)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((stbi__compute_y_16((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u16);
					i -= 1;
					src += ((3) as i32);
					dest += ((1) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (2)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((stbi__compute_y_16((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u16);
					*good.offset((dest + 1) as isize) = (((0xffff) as u16) as u16);
					i -= 1;
					src += ((3) as i32);
					dest += ((2) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (1)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((stbi__compute_y_16((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u16);
					i -= 1;
					src += ((4) as i32);
					dest += ((1) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (2)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((stbi__compute_y_16((((*data.offset((src) as isize)) as i32) as i32), (((*data.offset((src + 1) as isize)) as i32) as i32), (((*data.offset((src + 2) as isize)) as i32) as i32))) as u16);
					i -= 1;
					src += ((4) as i32);
					dest += ((2) as i32);
				}
			} else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (3)) {
				i = (((x - ((1) as u32)) as i32) as i32);
				while (i >= 0) {
					*good.offset((dest) as isize) = ((*data.offset((src) as isize)) as u16);
					*good.offset((dest + 1) as isize) = ((*data.offset((src + 1) as isize)) as u16);
					*good.offset((dest + 2) as isize) = ((*data.offset((src + 2) as isize)) as u16);
					i -= 1;
					src += ((4) as i32);
					dest += ((3) as i32);
				}
			} else { return ((if stbi__err((("0"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }) as *mut u16); }
		}
		j += 1;
	}
	c_runtime::free(((data) as *mut u16));
	return good;
}

pub unsafe fn stbi__build_huffman(mut h: *mut stbi__huffman, mut count: *mut i32) -> i32 {
	let mut i: i32 = std::mem::uninitialized();
	let mut j: i32 = std::mem::uninitialized();
	let mut k: i32 = 0;
	let mut code: i32 = std::mem::uninitialized();
	i = ((0) as i32);
	while (i < 16) {
		j = ((0) as i32);
		while (j < *count.offset((i) as isize)) {
			*(*h).size.as_mut_ptr().offset((k) as isize) = (((i + 1) as u8) as u8);
			k += 1;
			j += 1;
		}
		i += 1;
	}
	*(*h).size.as_mut_ptr().offset((k) as isize) = (((0) as u8) as u8);
	code = ((0) as i32);
	k = ((0) as i32);
	j = ((1) as i32);
	while (j <= 16) {
		*(*h).delta.as_mut_ptr().offset((j) as isize) = ((k - code) as i32);
		if ((*(*h).size.as_mut_ptr().offset((k) as isize)) as i32) == j {
			while (((*(*h).size.as_mut_ptr().offset((k) as isize)) as i32) == j) {
				*(*h).code.as_mut_ptr().offset((k) as isize) = (((code) as u16) as u16);
				k += 1;
				code += 1;
			}
			if code - 1 >= (1 << j) { return stbi__err((("bad code lengths"))); }
		}
		*(*h).maxcode.as_mut_ptr().offset((j) as isize) = (((code << (16 - j)) as u32) as u32);
		code <<= 1;
		j += 1;
	}
	*(*h).maxcode.as_mut_ptr().offset((j) as isize) = ((0xffffffff) as u32);
	c_runtime::memset((((*h).fast.as_mut_ptr()) as *mut u8), ((255) as i32), (((1 << 9) as u64) as u64));
	i = ((0) as i32);
	while (i < k) {
		let mut s: i32 = ((*(*h).size.as_mut_ptr().offset((i) as isize)) as i32);
		if s <= 9 {
			let mut c: i32 = (((*(*h).code.as_mut_ptr().offset((i) as isize)) as i32) << (9 - s));
			let mut m: i32 = (1 << (9 - s));
			j = ((0) as i32);
			while (j < m) {
				*(*h).fast.as_mut_ptr().offset((c + j) as isize) = (((i) as u8) as u8);
				j += 1;
			}
		}
		i += 1;
	}
	return 1;
}

pub unsafe fn stbi__build_fast_ac(mut fast_ac: *mut i16, mut h: *mut stbi__huffman) {
	let mut i: i32 = std::mem::uninitialized();
	i = ((0) as i32);
	while (i < (1 << 9)) {
		let mut fast: u8 = *(*h).fast.as_mut_ptr().offset((i) as isize);
		*fast_ac.offset((i) as isize) = (((0) as i16) as i16);
		if ((fast) as i32) < 255 {
			let mut rs: i32 = ((*(*h).values.as_mut_ptr().offset((fast) as isize)) as i32);
			let mut run: i32 = (rs >> 4) & 15;
			let mut magbits: i32 = rs & 15;
			let mut len: i32 = ((*(*h).size.as_mut_ptr().offset((fast) as isize)) as i32);
			if (magbits) != 0 && len + magbits <= 9 {
				let mut k: i32 = (((i << len) & ((1 << 9) - 1)) >> (9 - magbits));
				let mut m: i32 = (1 << (magbits - 1));
				if k < m { k += (((!0 << magbits) + ((1) as u32)) as i32); }
				if k >= -128 && k <= 127 { *fast_ac.offset((i) as isize) = ((((k << 8) + (run << 4) + (len + magbits)) as i16) as i16); }
			}
		}
		i += 1;
	}
}

pub unsafe fn stbi__grow_buffer_unsafe(mut j: *mut stbi__jpeg) {
	while (true) {
		let mut b: i32 = if ((*j).nomore) != 0 { 0 } else { ((stbi__get8((((*j).s) as *mut stbi__context))) as i32) };
		if b == 0xff {
			let mut c: i32 = ((stbi__get8((((*j).s) as *mut stbi__context))) as i32);
			while (c == 0xff) { c = (((stbi__get8((((*j).s) as *mut stbi__context))) as i32) as i32); }
			if c != 0 {
				(*j).marker = (((c) as u8) as u8);
				(*j).nomore = ((1) as i32);
				return;
			}
		}
		(*j).code_buffer |= (((b << (24 - (*j).code_bits)) as u32) as u32);
		(*j).code_bits += ((8) as i32);
		if !((*j).code_bits <= 24) { break; }
	}
}

pub unsafe fn stbi__jpeg_huff_decode(mut j: *mut stbi__jpeg, mut h: *mut stbi__huffman) -> i32 {
	let mut temp: u32 = std::mem::uninitialized();
	let mut c: i32 = std::mem::uninitialized();
	let mut k: i32 = std::mem::uninitialized();
	if (*j).code_bits < 16 { stbi__grow_buffer_unsafe(((j) as *mut stbi__jpeg)); }
	c = (((((*j).code_buffer >> (32 - 9)) & (((1 << 9) - 1) as u32)) as i32) as i32);
	k = (((*(*h).fast.as_mut_ptr().offset((c) as isize)) as i32) as i32);
	if k < 255 {
		let mut s: i32 = ((*(*h).size.as_mut_ptr().offset((k) as isize)) as i32);
		if s > (*j).code_bits { return -1; }
		(*j).code_buffer <<= s;
		(*j).code_bits -= ((s) as i32);
		return ((*(*h).values.as_mut_ptr().offset((k) as isize)) as i32);
	}
	temp = (((*j).code_buffer >> 16) as u32);
	k = ((9 + 1) as i32);
	while (true) {
		if temp < *(*h).maxcode.as_mut_ptr().offset((k) as isize) { break; }
		k += 1;
	}
	if k == 17 {
		(*j).code_bits -= ((16) as i32);
		return -1;
	}
	if k > (*j).code_bits { return -1; }
	c = ((((((*j).code_buffer >> (32 - k)) & *stbi__bmask.as_mut_ptr().offset((k) as isize)) + ((*(*h).delta.as_mut_ptr().offset((k) as isize)) as u32)) as i32) as i32);
	(*j).code_bits -= ((k) as i32);
	(*j).code_buffer <<= k;
	return ((*(*h).values.as_mut_ptr().offset((c) as isize)) as i32);
}

pub unsafe fn stbi__extend_receive(mut j: *mut stbi__jpeg, mut n: i32) -> i32 {
	let mut k: u32 = std::mem::uninitialized();
	let mut sgn: i32 = std::mem::uninitialized();
	if (*j).code_bits < n { stbi__grow_buffer_unsafe(((j) as *mut stbi__jpeg)); }
	sgn = (((((*j).code_buffer) as i32) >> 31) as i32);
	k = (((c_runtime::_lrotl((((*j).code_buffer) as u32), ((n) as i32))) as u32) as u32);
	(*j).code_buffer = ((k & !*stbi__bmask.as_mut_ptr().offset((n) as isize)) as u32);
	k &= ((*stbi__bmask.as_mut_ptr().offset((n) as isize)) as u32);
	(*j).code_bits -= ((n) as i32);
	return ((k + ((*stbi__jbias.as_mut_ptr().offset((n) as isize) & !sgn) as u32)) as i32);
}

pub unsafe fn stbi__jpeg_get_bits(mut j: *mut stbi__jpeg, mut n: i32) -> i32 {
	let mut k: u32 = std::mem::uninitialized();
	if (*j).code_bits < n { stbi__grow_buffer_unsafe(((j) as *mut stbi__jpeg)); }
	k = (((c_runtime::_lrotl((((*j).code_buffer) as u32), ((n) as i32))) as u32) as u32);
	(*j).code_buffer = ((k & !*stbi__bmask.as_mut_ptr().offset((n) as isize)) as u32);
	k &= ((*stbi__bmask.as_mut_ptr().offset((n) as isize)) as u32);
	(*j).code_bits -= ((n) as i32);
	return ((k) as i32);
}

pub unsafe fn stbi__jpeg_get_bit(mut j: *mut stbi__jpeg) -> i32 {
	let mut k: u32 = std::mem::uninitialized();
	if (*j).code_bits < 1 { stbi__grow_buffer_unsafe(((j) as *mut stbi__jpeg)); }
	k = (((*j).code_buffer) as u32);
	(*j).code_buffer <<= 1;
	(*j).code_bits -= 1;
	return ((k & 0x80000000) as i32);
}

pub unsafe fn stbi__jpeg_decode_block(mut j: *mut stbi__jpeg, mut data: *mut i16, mut hdc: *mut stbi__huffman, mut hac: *mut stbi__huffman, mut fac: *mut i16, mut b: i32, mut dequant: *mut u16) -> i32 {
	let mut diff: i32 = std::mem::uninitialized();
	let mut dc: i32 = std::mem::uninitialized();
	let mut k: i32 = std::mem::uninitialized();
	let mut t: i32 = std::mem::uninitialized();
	if (*j).code_bits < 16 { stbi__grow_buffer_unsafe(((j) as *mut stbi__jpeg)); }
	t = ((stbi__jpeg_huff_decode(((j) as *mut stbi__jpeg), ((hdc) as *mut stbi__huffman))) as i32);
	if t < 0 { return stbi__err((("bad huffman code"))); }
	c_runtime::memset(((data) as *mut u8), ((0) as i32), ((((64) as u64) * std::mem::size_of::<i16> as u64) as u64));
	diff = ((if (t) != 0 { stbi__extend_receive(((j) as *mut stbi__jpeg), ((t) as i32)) } else { 0 }) as i32);
	dc = ((*(*j).img_comp.as_mut_ptr().offset((b) as isize).dc_pred + diff) as i32);
	(*j).img_comp.as_mut_ptr().offset((b) as isize).dc_pred = ((dc) as i32);
	*data.offset((0) as isize) = (((dc * ((*dequant.offset((0) as isize)) as i32)) as i16) as i16);
	k = ((1) as i32);
	while (true) {
		let mut zig: u32 = std::mem::uninitialized();
		let mut c: i32 = std::mem::uninitialized();
		let mut r: i32 = std::mem::uninitialized();
		let mut s: i32 = std::mem::uninitialized();
		if (*j).code_bits < 16 { stbi__grow_buffer_unsafe(((j) as *mut stbi__jpeg)); }
		c = (((((*j).code_buffer >> (32 - 9)) & (((1 << 9) - 1) as u32)) as i32) as i32);
		r = (((*fac.offset((c) as isize)) as i32) as i32);
		if (r) != 0 {
			k += (((r >> 4) & 15) as i32);
			s = ((r & 15) as i32);
			(*j).code_buffer <<= s;
			(*j).code_bits -= ((s) as i32);
			zig = (((*stbi__jpeg_dezigzag.as_mut_ptr().offset((k) as isize)) as u32) as u32);
			k += 1;
			*data.offset((zig) as isize) = ((((r >> 8) * ((*dequant.offset((zig) as isize)) as i32)) as i16) as i16);
		} else {
			let mut rs: i32 = stbi__jpeg_huff_decode(((j) as *mut stbi__jpeg), ((hac) as *mut stbi__huffman));
			if rs < 0 { return stbi__err((("bad huffman code"))); }
			s = ((rs & 15) as i32);
			r = ((rs >> 4) as i32);
			if s == 0 {
				if rs != 0xf0 { break; }
				k += ((16) as i32);
			} else {
				k += ((r) as i32);
				zig = (((*stbi__jpeg_dezigzag.as_mut_ptr().offset((k) as isize)) as u32) as u32);
				k += 1;
				*data.offset((zig) as isize) = (((stbi__extend_receive(((j) as *mut stbi__jpeg), ((s) as i32)) * ((*dequant.offset((zig) as isize)) as i32)) as i16) as i16);
			}
		}
		if !(k < 64) { break; }
	}

	return 1;
}

pub unsafe fn stbi__jpeg_decode_block_prog_dc(mut j: *mut stbi__jpeg, mut data: *mut i16, mut hdc: *mut stbi__huffman, mut b: i32) -> i32 {
	let mut diff: i32 = std::mem::uninitialized();
	let mut dc: i32 = std::mem::uninitialized();
	let mut t: i32 = std::mem::uninitialized();
	if (*j).spec_end != 0 { return stbi__err((("can't merge dc and ac"))); }
	if (*j).code_bits < 16 { stbi__grow_buffer_unsafe(((j) as *mut stbi__jpeg)); }
	if (*j).succ_high == 0 {
		c_runtime::memset(((data) as *mut u8), ((0) as i32), ((((64) as u64) * std::mem::size_of::<i16> as u64) as u64));
		t = ((stbi__jpeg_huff_decode(((j) as *mut stbi__jpeg), ((hdc) as *mut stbi__huffman))) as i32);
		diff = ((if (t) != 0 { stbi__extend_receive(((j) as *mut stbi__jpeg), ((t) as i32)) } else { 0 }) as i32);
		dc = ((*(*j).img_comp.as_mut_ptr().offset((b) as isize).dc_pred + diff) as i32);
		*(*j).img_comp.as_mut_ptr().offset((b) as isize).dc_pred = ((dc) as i32);
		*data.offset((0) as isize) = (((dc << (*j).succ_low) as i16) as i16);
	} else {
		if (stbi__jpeg_get_bit(((j) as *mut stbi__jpeg))) != 0 { *data.offset((0) as isize) += ((((1 << (*j).succ_low) as i16) as i32) as i16); }
	}
	return 1;
}

pub unsafe fn stbi__jpeg_decode_block_prog_ac(mut j: *mut stbi__jpeg, mut data: *mut i16, mut hac: *mut stbi__huffman, mut fac: *mut i16) -> i32 {
	let mut k: i32 = std::mem::uninitialized();
	if (*j).spec_start == 0 { return stbi__err((("can't merge dc and ac"))); }
	if (*j).succ_high == 0 {
		let mut shift: i32 = (*j).succ_low;
		if ((*j).eob_run) != 0 {
			(*j).eob_run -= 1;
			return 1;
		}
		k = (((*j).spec_start) as i32);
		while (true) {
			let mut zig: u32 = std::mem::uninitialized();
			let mut c: i32 = std::mem::uninitialized();
			let mut r: i32 = std::mem::uninitialized();
			let mut s: i32 = std::mem::uninitialized();
			if (*j).code_bits < 16 { stbi__grow_buffer_unsafe(((j) as *mut stbi__jpeg)); }
			c = (((((*j).code_buffer >> (32 - 9)) & (((1 << 9) - 1) as u32)) as i32) as i32);
			r = (((*fac.offset((c) as isize)) as i32) as i32);
			if (r) != 0 {
				k += (((r >> 4) & 15) as i32);
				s = ((r & 15) as i32);
				(*j).code_buffer <<= s;
				(*j).code_bits -= ((s) as i32);
				zig = (((*stbi__jpeg_dezigzag.as_mut_ptr().offset((k) as isize)) as u32) as u32);
				k += 1;
				*data.offset((zig) as isize) = ((((r >> 8) << shift) as i16) as i16);
			} else {
				let mut rs: i32 = stbi__jpeg_huff_decode(((j) as *mut stbi__jpeg), ((hac) as *mut stbi__huffman));
				if rs < 0 { return stbi__err((("bad huffman code"))); }
				s = ((rs & 15) as i32);
				r = ((rs >> 4) as i32);
				if s == 0 {
					if r < 15 {
						(*j).eob_run = ((1 << r) as i32);
						if (r) != 0 { (*j).eob_run += ((stbi__jpeg_get_bits(((j) as *mut stbi__jpeg), ((r) as i32))) as i32); }
						(*j).eob_run -= 1;
						break;
					}
					k += ((16) as i32);
				} else {
					k += ((r) as i32);
					zig = (((*stbi__jpeg_dezigzag.as_mut_ptr().offset((k) as isize)) as u32) as u32);
					k += 1;
					*data.offset((zig) as isize) = (((stbi__extend_receive(((j) as *mut stbi__jpeg), ((s) as i32)) << shift) as i16) as i16);
				}
			}
			if !(k <= (*j).spec_end) { break; }
		}
	} else {
		let mut bit: i16 = ((1 << (*j).succ_low) as i16);
		if ((*j).eob_run) != 0 {
			(*j).eob_run -= 1;
			k = (((*j).spec_start) as i32);
			while (k <= (*j).spec_end) {
				let mut p: *mut i16 = &mut *data.offset((*stbi__jpeg_dezigzag.as_mut_ptr().offset((k) as isize)) as isize);
				if ((*p) as i32) != 0 {
					if (stbi__jpeg_get_bit(((j) as *mut stbi__jpeg))) != 0 {
						if (((*p) as i32) & ((bit) as i32)) == 0 {
							if ((*p) as i32) > 0 { *p += (((bit) as i32) as i16); } else { *p -= (((bit) as i32) as i16); }
						}
					}
				}
				k += 1;
			}
		} else {
			k = (((*j).spec_start) as i32);
			while (true) {
				let mut r: i32 = std::mem::uninitialized();
				let mut s: i32 = std::mem::uninitialized();
				let mut rs: i32 = stbi__jpeg_huff_decode(((j) as *mut stbi__jpeg), ((hac) as *mut stbi__huffman));
				if rs < 0 { return stbi__err((("bad huffman code"))); }
				s = ((rs & 15) as i32);
				r = ((rs >> 4) as i32);
				if s == 0 {
					if r < 15 {
						(*j).eob_run = (((1 << r) - 1) as i32);
						if (r) != 0 { (*j).eob_run += ((stbi__jpeg_get_bits(((j) as *mut stbi__jpeg), ((r) as i32))) as i32); }
						r = ((64) as i32);
					} else {}
				} else {
					if s != 1 { return stbi__err((("bad huffman code"))); }
					if (stbi__jpeg_get_bit(((j) as *mut stbi__jpeg))) != 0 { s = (((bit) as i32) as i32); } else { s = ((-((bit) as i32)) as i32); }
				}
				while (k <= (*j).spec_end) {
					let mut p: *mut i16 = &mut *data.offset((*stbi__jpeg_dezigzag.as_mut_ptr().offset((k) as isize)) as isize);
					k += 1;
					if ((*p) as i32) != 0 {
						if (stbi__jpeg_get_bit(((j) as *mut stbi__jpeg))) != 0 {
							if (((*p) as i32) & ((bit) as i32)) == 0 {
								if ((*p) as i32) > 0 { *p += (((bit) as i32) as i16); } else { *p -= (((bit) as i32) as i16); }
							}
						}
					} else {
						if r == 0 {
							*p = (((s) as i16) as i16);
							break;
						}
						r -= 1;
					}
				}
				if !(k <= (*j).spec_end) { break; }
			}
		}
	}
	return 1;
}

pub unsafe fn stbi__clamp(mut x: i32) -> u8 {
	if ((x) as u32) > ((255) as u32) {
		if x < 0 { return ((0) as u8); }
		if x > 255 { return ((255) as u8); }
	}
	return ((x) as u8);
}

pub unsafe fn stbi__idct_block(mut _out_: *mut u8, mut out_stride: i32, mut data: *mut i16) {
	let mut i: i32 = std::mem::uninitialized();
	let mut val: [i32; 64] = std::mem::uninitialized();
	let mut v: *mut i32 = val.as_mut_ptr();
	let mut o: *mut u8;
	let mut d: *mut i16 = data;
	i = ((0) as i32);
	while (i < 8) {
		if ((*d.offset((8) as isize)) as i32) == 0 && ((*d.offset((16) as isize)) as i32) == 0 && ((*d.offset((24) as isize)) as i32) == 0 && ((*d.offset((32) as isize)) as i32) == 0 && ((*d.offset((40) as isize)) as i32) == 0 && ((*d.offset((48) as isize)) as i32) == 0 && ((*d.offset((56) as isize)) as i32) == 0 {
			let mut dcterm: i32 = (((*d.offset((0) as isize)) as i32) << 2);
			*v.offset((0) as isize) = dcterm;
			*v.offset((8) as isize) = dcterm;
			*v.offset((16) as isize) = dcterm;
			*v.offset((24) as isize) = dcterm;
			*v.offset((32) as isize) = dcterm;
			*v.offset((40) as isize) = dcterm;
			*v.offset((48) as isize) = dcterm;
			*v.offset((56) as isize) = dcterm;
		} else {
			let mut t0: i32 = std::mem::uninitialized();
			let mut t1: i32 = std::mem::uninitialized();
			let mut t2: i32 = std::mem::uninitialized();
			let mut t3: i32 = std::mem::uninitialized();
			let mut p1: i32 = std::mem::uninitialized();
			let mut p2: i32 = std::mem::uninitialized();
			let mut p3: i32 = std::mem::uninitialized();
			let mut p4: i32 = std::mem::uninitialized();
			let mut p5: i32 = std::mem::uninitialized();
			let mut x0: i32 = std::mem::uninitialized();
			let mut x1: i32 = std::mem::uninitialized();
			let mut x2: i32 = std::mem::uninitialized();
			let mut x3: i32 = std::mem::uninitialized();
			p2 = (((*d.offset((16) as isize)) as i32) as i32);
			p3 = (((*d.offset((48) as isize)) as i32) as i32);
			p1 = (((p2 + p3) * (((((0.5411961f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
			t2 = ((p1 + p3 * (((((-1.847759065f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
			t3 = ((p1 + p2 * (((((0.765366865f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
			p2 = (((*d.offset((0) as isize)) as i32) as i32);
			p3 = (((*d.offset((32) as isize)) as i32) as i32);
			t0 = (((p2 + p3) << 12) as i32);
			t1 = (((p2 - p3) << 12) as i32);
			x0 = ((t0 + t3) as i32);
			x3 = ((t0 - t3) as i32);
			x1 = ((t1 + t2) as i32);
			x2 = ((t1 - t2) as i32);
			t0 = (((*d.offset((56) as isize)) as i32) as i32);
			t1 = (((*d.offset((40) as isize)) as i32) as i32);
			t2 = (((*d.offset((24) as isize)) as i32) as i32);
			t3 = (((*d.offset((8) as isize)) as i32) as i32);
			p3 = ((t0 + t2) as i32);
			p4 = ((t1 + t3) as i32);
			p1 = ((t0 + t3) as i32);
			p2 = ((t1 + t2) as i32);
			p5 = (((p3 + p4) * (((((1.175875602f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
			t0 = ((t0 * (((((0.298631336f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
			t1 = ((t1 * (((((2.053119869f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
			t2 = ((t2 * (((((3.072711026f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
			t3 = ((t3 * (((((1.501321110f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
			p1 = ((p5 + p1 * (((((-0.899976223f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
			p2 = ((p5 + p2 * (((((-2.562915447f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
			p3 = ((p3 * (((((-1.961570560f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
			p4 = ((p4 * (((((-0.390180644f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
			t3 += ((p1 + p4) as i32);
			t2 += ((p2 + p3) as i32);
			t1 += ((p2 + p4) as i32);
			t0 += ((p1 + p3) as i32);
			x0 += ((512) as i32);
			x1 += ((512) as i32);
			x2 += ((512) as i32);
			x3 += ((512) as i32);
			*v.offset((0) as isize) = (((x0 + t3) >> 10) as i32);
			*v.offset((56) as isize) = (((x0 - t3) >> 10) as i32);
			*v.offset((8) as isize) = (((x1 + t2) >> 10) as i32);
			*v.offset((48) as isize) = (((x1 - t2) >> 10) as i32);
			*v.offset((16) as isize) = (((x2 + t1) >> 10) as i32);
			*v.offset((40) as isize) = (((x2 - t1) >> 10) as i32);
			*v.offset((24) as isize) = (((x3 + t0) >> 10) as i32);
			*v.offset((32) as isize) = (((x3 - t0) >> 10) as i32);
		}
		i += 1;
		(d = d.offset(1));
		(v = v.offset(1));
	}
	i = ((0) as i32);
	v = val.as_mut_ptr();
	o = _out_;
	while (i < 8) {
		let mut t0: i32 = std::mem::uninitialized();
		let mut t1: i32 = std::mem::uninitialized();
		let mut t2: i32 = std::mem::uninitialized();
		let mut t3: i32 = std::mem::uninitialized();
		let mut p1: i32 = std::mem::uninitialized();
		let mut p2: i32 = std::mem::uninitialized();
		let mut p3: i32 = std::mem::uninitialized();
		let mut p4: i32 = std::mem::uninitialized();
		let mut p5: i32 = std::mem::uninitialized();
		let mut x0: i32 = std::mem::uninitialized();
		let mut x1: i32 = std::mem::uninitialized();
		let mut x2: i32 = std::mem::uninitialized();
		let mut x3: i32 = std::mem::uninitialized();
		p2 = ((*v.offset((2) as isize)) as i32);
		p3 = ((*v.offset((6) as isize)) as i32);
		p1 = (((p2 + p3) * (((((0.5411961f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
		t2 = ((p1 + p3 * (((((-1.847759065f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
		t3 = ((p1 + p2 * (((((0.765366865f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
		p2 = ((*v.offset((0) as isize)) as i32);
		p3 = ((*v.offset((4) as isize)) as i32);
		t0 = (((p2 + p3) << 12) as i32);
		t1 = (((p2 - p3) << 12) as i32);
		x0 = ((t0 + t3) as i32);
		x3 = ((t0 - t3) as i32);
		x1 = ((t1 + t2) as i32);
		x2 = ((t1 - t2) as i32);
		t0 = ((*v.offset((7) as isize)) as i32);
		t1 = ((*v.offset((5) as isize)) as i32);
		t2 = ((*v.offset((3) as isize)) as i32);
		t3 = ((*v.offset((1) as isize)) as i32);
		p3 = ((t0 + t2) as i32);
		p4 = ((t1 + t3) as i32);
		p1 = ((t0 + t3) as i32);
		p2 = ((t1 + t2) as i32);
		p5 = (((p3 + p4) * (((((1.175875602f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
		t0 = ((t0 * (((((0.298631336f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
		t1 = ((t1 * (((((2.053119869f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
		t2 = ((t2 * (((((3.072711026f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
		t3 = ((t3 * (((((1.501321110f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
		p1 = ((p5 + p1 * (((((-0.899976223f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
		p2 = ((p5 + p2 * (((((-2.562915447f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
		p3 = ((p3 * (((((-1.961570560f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
		p4 = ((p4 * (((((-0.390180644f32) * ((4096) as f32)) as f64) + 0.5) as i32)) as i32);
		t3 += ((p1 + p4) as i32);
		t2 += ((p2 + p3) as i32);
		t1 += ((p2 + p4) as i32);
		t0 += ((p1 + p3) as i32);
		x0 += ((65536 + (128 << 17)) as i32);
		x1 += ((65536 + (128 << 17)) as i32);
		x2 += ((65536 + (128 << 17)) as i32);
		x3 += ((65536 + (128 << 17)) as i32);
		*o.offset((0) as isize) = ((stbi__clamp((((x0 + t3) >> 17) as i32))) as u8);
		*o.offset((7) as isize) = ((stbi__clamp((((x0 - t3) >> 17) as i32))) as u8);
		*o.offset((1) as isize) = ((stbi__clamp((((x1 + t2) >> 17) as i32))) as u8);
		*o.offset((6) as isize) = ((stbi__clamp((((x1 - t2) >> 17) as i32))) as u8);
		*o.offset((2) as isize) = ((stbi__clamp((((x2 + t1) >> 17) as i32))) as u8);
		*o.offset((5) as isize) = ((stbi__clamp((((x2 - t1) >> 17) as i32))) as u8);
		*o.offset((3) as isize) = ((stbi__clamp((((x3 + t0) >> 17) as i32))) as u8);
		*o.offset((4) as isize) = ((stbi__clamp((((x3 - t0) >> 17) as i32))) as u8);
		i += 1;
		v = v.offset((((8) as *mut i32)) as isize);
		o = o.offset((((out_stride) as *mut u8)) as isize);
	}
}

pub unsafe fn stbi__get_marker(mut j: *mut stbi__jpeg) -> u8 {
	let mut x: u8 = std::mem::uninitialized();
	if (((*j).marker) as i32) != 0xff {
		x = (((*j).marker) as u8);
		(*j).marker = (((0xff) as u8) as u8);
		return x;
	}
	x = ((stbi__get8((((*j).s) as *mut stbi__context))) as u8);
	if ((x) as i32) != 0xff { return ((0xff) as u8); }
	while (((x) as i32) == 0xff) { x = ((stbi__get8((((*j).s) as *mut stbi__context))) as u8); }
	return x;
}

pub unsafe fn stbi__jpeg_reset(mut j: *mut stbi__jpeg) {
	(*j).code_bits = ((0) as i32);
	(*j).code_buffer = (((0) as u32) as u32);
	(*j).nomore = ((0) as i32);
	*(*j).img_comp.as_mut_ptr().offset((0) as isize).dc_pred = 0;
	*(*j).img_comp.as_mut_ptr().offset((1) as isize).dc_pred = 0;
	*(*j).img_comp.as_mut_ptr().offset((2) as isize).dc_pred = 0;
	*(*j).img_comp.as_mut_ptr().offset((3) as isize).dc_pred = 0;
	(*j).marker = (((0xff) as u8) as u8);
	(*j).todo = ((if ((*j).restart_interval) != 0 { (*j).restart_interval } else { 0x7fffffff }) as i32);
	(*j).eob_run = ((0) as i32);
}

pub unsafe fn stbi__parse_entropy_coded_data(mut z: *mut stbi__jpeg) -> i32 {
	stbi__jpeg_reset(((z) as *mut stbi__jpeg));
	if (*z).progressive == 0 {
		if (*z).scan_n == 1 {
			let mut i: i32 = std::mem::uninitialized();
			let mut j: i32 = std::mem::uninitialized();
			let mut data: [i16; 64] = std::mem::uninitialized();
			let mut n: i32 = *(*z).order.as_mut_ptr().offset((0) as isize);
			let mut w: i32 = ((*(*z).img_comp.as_mut_ptr().offset((n) as isize).x + 7) >> 3);
			let mut h: i32 = ((*(*z).img_comp.as_mut_ptr().offset((n) as isize).y + 7) >> 3);
			j = ((0) as i32);
			while (j < h) {
				i = ((0) as i32);
				while (i < w) {
					let mut ha: i32 = *(*z).img_comp.as_mut_ptr().offset((n) as isize).ha;
					if stbi__jpeg_decode_block(((z) as *mut stbi__jpeg), ((data.as_mut_ptr()) as *mut i16), ((((*z).huff_dc.as_mut_ptr()).offset((*(*z).img_comp.as_mut_ptr().offset((n) as isize).hd) as isize)) as *mut stbi__huffman), ((((*z).huff_ac.as_mut_ptr()).offset((ha) as isize)) as *mut stbi__huffman), ((*(*z).fast_ac.as_mut_ptr().offset((ha) as isize).as_mut_ptr()) as *mut i16), ((n) as i32), ((*(*z).dequant.as_mut_ptr().offset((*(*z).img_comp.as_mut_ptr().offset((n) as isize).tq) as isize).as_mut_ptr()) as *mut u16)) == 0 { return 0; }
					((*z).idct_block_kernel)(((((*(*z).img_comp.as_mut_ptr().offset((n) as isize).data).offset((*(*z).img_comp.as_mut_ptr().offset((n) as isize).w2 * j * 8) as isize)).offset((i * 8) as isize)) as *mut u8), ((*(*z).img_comp.as_mut_ptr().offset((n) as isize).w2) as i32), ((data.as_mut_ptr()) as *mut i16));
					(*z).todo -= 1;
					if (*z).todo <= 0 {
						if (*z).code_bits < 24 { stbi__grow_buffer_unsafe(((z) as *mut stbi__jpeg)); }
						if !((((*z).marker) as i32) >= 0xd0 && (((*z).marker) as i32) <= 0xd7) { return 1; }
						stbi__jpeg_reset(((z) as *mut stbi__jpeg));
					}
					i += 1;
				}
				j += 1;
			}
			return 1;
		} else {
			let mut i: i32 = std::mem::uninitialized();
			let mut j: i32 = std::mem::uninitialized();
			let mut k: i32 = std::mem::uninitialized();
			let mut x: i32 = std::mem::uninitialized();
			let mut y: i32 = std::mem::uninitialized();
			let mut data: [i16; 64] = std::mem::uninitialized();
			j = ((0) as i32);
			while (j < (*z).img_mcu_y) {
				i = ((0) as i32);
				while (i < (*z).img_mcu_x) {
					k = ((0) as i32);
					while (k < (*z).scan_n) {
						let mut n: i32 = *(*z).order.as_mut_ptr().offset((k) as isize);
						y = ((0) as i32);
						while (y < *(*z).img_comp.as_mut_ptr().offset((n) as isize).v) {
							x = ((0) as i32);
							while (x < *(*z).img_comp.as_mut_ptr().offset((n) as isize).h) {
								let mut x2: i32 = (i * *(*z).img_comp.as_mut_ptr().offset((n) as isize).h + x) * 8;
								let mut y2: i32 = (j * *(*z).img_comp.as_mut_ptr().offset((n) as isize).v + y) * 8;
								let mut ha: i32 = *(*z).img_comp.as_mut_ptr().offset((n) as isize).ha;
								if stbi__jpeg_decode_block(((z) as *mut stbi__jpeg), ((data.as_mut_ptr()) as *mut i16), ((((*z).huff_dc.as_mut_ptr()).offset((*(*z).img_comp.as_mut_ptr().offset((n) as isize).hd) as isize)) as *mut stbi__huffman), ((((*z).huff_ac.as_mut_ptr()).offset((ha) as isize)) as *mut stbi__huffman), ((*(*z).fast_ac.as_mut_ptr().offset((ha) as isize).as_mut_ptr()) as *mut i16), ((n) as i32), ((*(*z).dequant.as_mut_ptr().offset((*(*z).img_comp.as_mut_ptr().offset((n) as isize).tq) as isize).as_mut_ptr()) as *mut u16)) == 0 { return 0; }
								((*z).idct_block_kernel)(((((*(*z).img_comp.as_mut_ptr().offset((n) as isize).data).offset((*(*z).img_comp.as_mut_ptr().offset((n) as isize).w2 * y2) as isize)).offset((x2) as isize)) as *mut u8), ((*(*z).img_comp.as_mut_ptr().offset((n) as isize).w2) as i32), ((data.as_mut_ptr()) as *mut i16));
								x += 1;
							}
							y += 1;
						}
						k += 1;
					}
					(*z).todo -= 1;
					if (*z).todo <= 0 {
						if (*z).code_bits < 24 { stbi__grow_buffer_unsafe(((z) as *mut stbi__jpeg)); }
						if !((((*z).marker) as i32) >= 0xd0 && (((*z).marker) as i32) <= 0xd7) { return 1; }
						stbi__jpeg_reset(((z) as *mut stbi__jpeg));
					}
					i += 1;
				}
				j += 1;
			}
			return 1;
		}
	} else {
		if (*z).scan_n == 1 {
			let mut i: i32 = std::mem::uninitialized();
			let mut j: i32 = std::mem::uninitialized();
			let mut n: i32 = *(*z).order.as_mut_ptr().offset((0) as isize);
			let mut w: i32 = ((*(*z).img_comp.as_mut_ptr().offset((n) as isize).x + 7) >> 3);
			let mut h: i32 = ((*(*z).img_comp.as_mut_ptr().offset((n) as isize).y + 7) >> 3);
			j = ((0) as i32);
			while (j < h) {
				i = ((0) as i32);
				while (i < w) {
					let mut data: *mut i16 = (*(*z).img_comp.as_mut_ptr().offset((n) as isize).coeff).offset((64 * (i + j * *(*z).img_comp.as_mut_ptr().offset((n) as isize).coeff_w)) as isize);
					if (*z).spec_start == 0 {
						if stbi__jpeg_decode_block_prog_dc(((z) as *mut stbi__jpeg), ((data) as *mut i16), ((&mut *(*z).huff_dc.as_mut_ptr().offset((*(*z).img_comp.as_mut_ptr().offset((n) as isize).hd) as isize)) as *mut stbi__huffman), ((n) as i32)) == 0 { return 0; }
					} else {
						let mut ha: i32 = *(*z).img_comp.as_mut_ptr().offset((n) as isize).ha;
						if stbi__jpeg_decode_block_prog_ac(((z) as *mut stbi__jpeg), ((data) as *mut i16), ((&mut *(*z).huff_ac.as_mut_ptr().offset((ha) as isize)) as *mut stbi__huffman), ((*(*z).fast_ac.as_mut_ptr().offset((ha) as isize).as_mut_ptr()) as *mut i16)) == 0 { return 0; }
					}
					(*z).todo -= 1;
					if (*z).todo <= 0 {
						if (*z).code_bits < 24 { stbi__grow_buffer_unsafe(((z) as *mut stbi__jpeg)); }
						if !((((*z).marker) as i32) >= 0xd0 && (((*z).marker) as i32) <= 0xd7) { return 1; }
						stbi__jpeg_reset(((z) as *mut stbi__jpeg));
					}
					i += 1;
				}
				j += 1;
			}
			return 1;
		} else {
			let mut i: i32 = std::mem::uninitialized();
			let mut j: i32 = std::mem::uninitialized();
			let mut k: i32 = std::mem::uninitialized();
			let mut x: i32 = std::mem::uninitialized();
			let mut y: i32 = std::mem::uninitialized();
			j = ((0) as i32);
			while (j < (*z).img_mcu_y) {
				i = ((0) as i32);
				while (i < (*z).img_mcu_x) {
					k = ((0) as i32);
					while (k < (*z).scan_n) {
						let mut n: i32 = *(*z).order.as_mut_ptr().offset((k) as isize);
						y = ((0) as i32);
						while (y < *(*z).img_comp.as_mut_ptr().offset((n) as isize).v) {
							x = ((0) as i32);
							while (x < *(*z).img_comp.as_mut_ptr().offset((n) as isize).h) {
								let mut x2: i32 = (i * *(*z).img_comp.as_mut_ptr().offset((n) as isize).h + x);
								let mut y2: i32 = (j * *(*z).img_comp.as_mut_ptr().offset((n) as isize).v + y);
								let mut data: *mut i16 = (*(*z).img_comp.as_mut_ptr().offset((n) as isize).coeff).offset((64 * (x2 + y2 * *(*z).img_comp.as_mut_ptr().offset((n) as isize).coeff_w)) as isize);
								if stbi__jpeg_decode_block_prog_dc(((z) as *mut stbi__jpeg), ((data) as *mut i16), ((&mut *(*z).huff_dc.as_mut_ptr().offset((*(*z).img_comp.as_mut_ptr().offset((n) as isize).hd) as isize)) as *mut stbi__huffman), ((n) as i32)) == 0 { return 0; }
								x += 1;
							}
							y += 1;
						}
						k += 1;
					}
					(*z).todo -= 1;
					if (*z).todo <= 0 {
						if (*z).code_bits < 24 { stbi__grow_buffer_unsafe(((z) as *mut stbi__jpeg)); }
						if !((((*z).marker) as i32) >= 0xd0 && (((*z).marker) as i32) <= 0xd7) { return 1; }
						stbi__jpeg_reset(((z) as *mut stbi__jpeg));
					}
					i += 1;
				}
				j += 1;
			}
			return 1;
		}
	}
}

pub unsafe fn stbi__jpeg_dequantize(mut data: *mut i16, mut dequant: *mut u16) {
	let mut i: i32 = std::mem::uninitialized();
	i = ((0) as i32);
	while (i < 64) {
		*data.offset((i) as isize) *= (((*dequant.offset((i) as isize)) as i32) as i16);
		i += 1;
	}
}

pub unsafe fn stbi__jpeg_finish(mut z: *mut stbi__jpeg) {
	if ((*z).progressive) != 0 {
		let mut i: i32 = std::mem::uninitialized();
		let mut j: i32 = std::mem::uninitialized();
		let mut n: i32 = std::mem::uninitialized();
		n = ((0) as i32);
		while (n < (*z).s.img_n) {
			let mut w: i32 = ((*(*z).img_comp.as_mut_ptr().offset((n) as isize).x + 7) >> 3);
			let mut h: i32 = ((*(*z).img_comp.as_mut_ptr().offset((n) as isize).y + 7) >> 3);
			j = ((0) as i32);
			while (j < h) {
				i = ((0) as i32);
				while (i < w) {
					let mut data: *mut i16 = (*(*z).img_comp.as_mut_ptr().offset((n) as isize).coeff).offset((64 * (i + j * *(*z).img_comp.as_mut_ptr().offset((n) as isize).coeff_w)) as isize);
					stbi__jpeg_dequantize(((data) as *mut i16), ((*(*z).dequant.as_mut_ptr().offset((*(*z).img_comp.as_mut_ptr().offset((n) as isize).tq) as isize).as_mut_ptr()) as *mut u16));
					((*z).idct_block_kernel)(((((*(*z).img_comp.as_mut_ptr().offset((n) as isize).data).offset((*(*z).img_comp.as_mut_ptr().offset((n) as isize).w2 * j * 8) as isize)).offset((i * 8) as isize)) as *mut u8), ((*(*z).img_comp.as_mut_ptr().offset((n) as isize).w2) as i32), ((data) as *mut i16));
					i += 1;
				}
				j += 1;
			}
			n += 1;
		}
	}
}

pub unsafe fn stbi__process_marker(mut z: *mut stbi__jpeg, mut m: i32) -> i32 {
	let mut L: i32 = std::mem::uninitialized();
	{
		if m == 0xff { return stbi__err((("expected marker"))); } else if m == 0xDD {
			if stbi__get16be((((*z).s) as *mut stbi__context)) != 4 { return stbi__err((("bad DRI len"))); }
			(*z).restart_interval = ((stbi__get16be((((*z).s) as *mut stbi__context))) as i32);
			return 1;
		} else if m == 0xDB {
			L = ((stbi__get16be((((*z).s) as *mut stbi__context)) - 2) as i32);
			while (L > 0) {
				let mut q: i32 = ((stbi__get8((((*z).s) as *mut stbi__context))) as i32);
				let mut p: i32 = (q >> 4);
				let mut sixteen: i32 = if (p != 0) { 1 } else { 0 };
				let mut t: i32 = q & 15;
				let mut i: i32 = std::mem::uninitialized();
				if p != 0 && p != 1 { return stbi__err((("bad DQT type"))); }
				if t > 3 { return stbi__err((("bad DQT table"))); }
				i = ((0) as i32);
				while (i < 64) {
					**(*z).dequant.as_mut_ptr().offset((t) as isize).as_mut_ptr().offset((*stbi__jpeg_dezigzag.as_mut_ptr().offset((i) as isize)) as isize) = (((if (sixteen) != 0 { stbi__get16be((((*z).s) as *mut stbi__context)) } else { ((stbi__get8((((*z).s) as *mut stbi__context))) as i32) }) as u16) as u16);
					i += 1;
				}
				L -= ((if (sixteen) != 0 { 129 } else { 65 }) as i32);
			}
			return (L == 0) as i32;
		} else if m == 0xC4 {
			L = ((stbi__get16be((((*z).s) as *mut stbi__context)) - 2) as i32);
			while (L > 0) {
				let mut v: *mut u8;
				let mut sizes: [i32; 16] = std::mem::uninitialized();
				let mut i: i32 = std::mem::uninitialized();
				let mut n: i32 = 0;
				let mut q: i32 = ((stbi__get8((((*z).s) as *mut stbi__context))) as i32);
				let mut tc: i32 = (q >> 4);
				let mut th: i32 = q & 15;
				if tc > 1 || th > 3 { return stbi__err((("bad DHT header"))); }
				i = ((0) as i32);
				while (i < 16) {
					*sizes.as_mut_ptr().offset((i) as isize) = (((stbi__get8((((*z).s) as *mut stbi__context))) as i32) as i32);
					n += ((*sizes.as_mut_ptr().offset((i) as isize)) as i32);
					i += 1;
				}
				L -= ((17) as i32);
				if tc == 0 {
					if stbi__build_huffman(((((*z).huff_dc.as_mut_ptr()).offset((th) as isize)) as *mut stbi__huffman), ((sizes.as_mut_ptr()) as *mut i32)) == 0 { return 0; }
					v = *(*z).huff_dc.as_mut_ptr().offset((th) as isize).values.as_mut_ptr();
				} else {
					if stbi__build_huffman(((((*z).huff_ac.as_mut_ptr()).offset((th) as isize)) as *mut stbi__huffman), ((sizes.as_mut_ptr()) as *mut i32)) == 0 { return 0; }
					v = *(*z).huff_ac.as_mut_ptr().offset((th) as isize).values.as_mut_ptr();
				}
				i = ((0) as i32);
				while (i < n) {
					*v.offset((i) as isize) = ((stbi__get8((((*z).s) as *mut stbi__context))) as u8);
					i += 1;
				}
				if tc != 0 { stbi__build_fast_ac(((*(*z).fast_ac.as_mut_ptr().offset((th) as isize).as_mut_ptr()) as *mut i16), ((((*z).huff_ac.as_mut_ptr()).offset((th) as isize)) as *mut stbi__huffman)); }
				L -= ((n) as i32);
			}
			return (L == 0) as i32;
		}
	}
	if (m >= 0xE0 && m <= 0xEF) || m == 0xFE {
		L = ((stbi__get16be((((*z).s) as *mut stbi__context))) as i32);
		if L < 2 {
			if m == 0xFE { return stbi__err((("bad COM len"))); } else { return stbi__err((("bad APP len"))); }
		}
		L -= ((2) as i32);
		if m == 0xE0 && L >= 5 {
			let mut tag: [u8; 5] = [(('J') as u8), (('F') as u8), (('I') as u8), (('F') as u8), (('\0') as u8)];
			let mut ok: i32 = 1;
			let mut i: i32 = std::mem::uninitialized();
			i = ((0) as i32);
			while (i < 5) {
				if ((stbi__get8((((*z).s) as *mut stbi__context))) as i32) != ((*tag.as_mut_ptr().offset((i) as isize)) as i32) { ok = ((0) as i32); }
				i += 1;
			}
			L -= ((5) as i32);
			if (ok) != 0 { (*z).jfif = ((1) as i32); }
		} else {
			if m == 0xEE && L >= 12 {
				let mut tag: [u8; 6] = [(('A') as u8), (('d') as u8), (('o') as u8), (('b') as u8), (('e') as u8), (('\0') as u8)];
				let mut ok: i32 = 1;
				let mut i: i32 = std::mem::uninitialized();
				i = ((0) as i32);
				while (i < 6) {
					if ((stbi__get8((((*z).s) as *mut stbi__context))) as i32) != ((*tag.as_mut_ptr().offset((i) as isize)) as i32) { ok = ((0) as i32); }
					i += 1;
				}
				L -= ((6) as i32);
				if (ok) != 0 {
					stbi__get8((((*z).s) as *mut stbi__context));
					stbi__get16be((((*z).s) as *mut stbi__context));
					stbi__get16be((((*z).s) as *mut stbi__context));
					(*z).app14_color_transform = (((stbi__get8((((*z).s) as *mut stbi__context))) as i32) as i32);
					L -= ((6) as i32);
				}
			}
		}
		stbi__skip((((*z).s) as *mut stbi__context), ((L) as i32));
		return 1;
	}
	return stbi__err((("unknown marker")));
}

pub unsafe fn stbi__process_scan_header(mut z: *mut stbi__jpeg) -> i32 {
	let mut i: i32 = std::mem::uninitialized();
	let mut Ls: i32 = stbi__get16be((((*z).s) as *mut stbi__context));
	(*z).scan_n = (((stbi__get8((((*z).s) as *mut stbi__context))) as i32) as i32);
	if (*z).scan_n < 1 || (*z).scan_n > 4 || (*z).scan_n > (*z).s.img_n { return stbi__err((("bad SOS component count"))); }
	if Ls != 6 + 2 * (*z).scan_n { return stbi__err((("bad SOS len"))); }
	i = ((0) as i32);
	while (i < (*z).scan_n) {
		let mut id: i32 = ((stbi__get8((((*z).s) as *mut stbi__context))) as i32);
		let mut which: i32 = std::mem::uninitialized();
		let mut q: i32 = ((stbi__get8((((*z).s) as *mut stbi__context))) as i32);
		which = ((0) as i32);
		while (which < (*z).s.img_n) {
			if *(*z).img_comp.as_mut_ptr().offset((which) as isize).id == id { break; }
			which += 1;
		}
		if which == (*z).s.img_n { return 0; }
		*(*z).img_comp.as_mut_ptr().offset((which) as isize).hd = ((q >> 4) as i32);
		if *(*z).img_comp.as_mut_ptr().offset((which) as isize).hd > 3 { return stbi__err((("bad DC huff"))); }
		*(*z).img_comp.as_mut_ptr().offset((which) as isize).ha = ((q & 15) as i32);
		if *(*z).img_comp.as_mut_ptr().offset((which) as isize).ha > 3 { return stbi__err((("bad AC huff"))); }
		*(*z).order.as_mut_ptr().offset((i) as isize) = ((which) as i32);
		i += 1;
	}
	{
		let mut aa: i32 = std::mem::uninitialized();
		(*z).spec_start = (((stbi__get8((((*z).s) as *mut stbi__context))) as i32) as i32);
		(*z).spec_end = (((stbi__get8((((*z).s) as *mut stbi__context))) as i32) as i32);
		aa = (((stbi__get8((((*z).s) as *mut stbi__context))) as i32) as i32);
		(*z).succ_high = ((aa >> 4) as i32);
		(*z).succ_low = ((aa & 15) as i32);
		if ((*z).progressive) != 0 {
			if (*z).spec_start > 63 || (*z).spec_end > 63 || (*z).spec_start > (*z).spec_end || (*z).succ_high > 13 || (*z).succ_low > 13 { return stbi__err((("bad SOS"))); }
		} else {
			if (*z).spec_start != 0 { return stbi__err((("bad SOS"))); }
			if (*z).succ_high != 0 || (*z).succ_low != 0 { return stbi__err((("bad SOS"))); }
			(*z).spec_end = ((63) as i32);
		}
	}

	return 1;
}

pub unsafe fn stbi__free_jpeg_components(mut z: *mut stbi__jpeg, mut ncomp: i32, mut why: i32) -> i32 {
	let mut i: i32 = std::mem::uninitialized();
	i = ((0) as i32);
	while (i < ncomp) {
		if (*(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_data) != std::ptr::null_mut() {
			c_runtime::free(((*(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_data) as *mut u8));
			*(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_data = (std::ptr::null_mut());
			*(*z).img_comp.as_mut_ptr().offset((i) as isize).data = (std::ptr::null_mut());
		}
		if (*(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_coeff) != std::ptr::null_mut() {
			c_runtime::free(((*(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_coeff) as *mut u8));
			*(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_coeff = std::ptr::null_mut();
			*(*z).img_comp.as_mut_ptr().offset((i) as isize).coeff = std::ptr::null_mut();
		}
		if (*(*z).img_comp.as_mut_ptr().offset((i) as isize).linebuf) != std::ptr::null_mut() {
			c_runtime::free(((*(*z).img_comp.as_mut_ptr().offset((i) as isize).linebuf) as *mut u8));
			*(*z).img_comp.as_mut_ptr().offset((i) as isize).linebuf = (std::ptr::null_mut());
		}
		i += 1;
	}
	return why;
}

pub unsafe fn stbi__process_frame_header(mut z: *mut stbi__jpeg, mut scan: i32) -> i32 {
	let mut s: *mut stbi__context = (*z).s;
	let mut Lf: i32 = std::mem::uninitialized();
	let mut p: i32 = std::mem::uninitialized();
	let mut i: i32 = std::mem::uninitialized();
	let mut q: i32 = std::mem::uninitialized();
	let mut h_max: i32 = 1;
	let mut v_max: i32 = 1;
	let mut c: i32 = std::mem::uninitialized();
	Lf = ((stbi__get16be(((s) as *mut stbi__context))) as i32);
	if Lf < 11 { return stbi__err((("bad SOF len"))); }
	p = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
	if p != 8 { return stbi__err((("only 8-bit"))); }
	(*s).img_y = (((stbi__get16be(((s) as *mut stbi__context))) as u32) as u32);
	if (*s).img_y == ((0) as u32) { return stbi__err((("no header height"))); }
	(*s).img_x = (((stbi__get16be(((s) as *mut stbi__context))) as u32) as u32);
	if (*s).img_x == ((0) as u32) { return stbi__err((("0 width"))); }
	c = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
	if c != 3 && c != 1 && c != 4 { return stbi__err((("bad component count"))); }
	(*s).img_n = ((c) as i32);
	i = ((0) as i32);
	while (i < c) {
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).data = (std::ptr::null_mut());
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).linebuf = (std::ptr::null_mut());
		i += 1;
	}
	if Lf != 8 + 3 * (*s).img_n { return stbi__err((("bad SOF len"))); }
	(*z).rgb = ((0) as i32);
	i = ((0) as i32);
	while (i < (*s).img_n) {
		let mut rgb: [u8; 3] = [(('R') as u8), (('G') as u8), (('B') as u8)];
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).id = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
		if (*s).img_n == 3 && *(*z).img_comp.as_mut_ptr().offset((i) as isize).id == ((*rgb.as_mut_ptr().offset((i) as isize)) as i32) { (*z).rgb += 1; }
		q = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).h = ((q >> 4) as i32);
		if *(*z).img_comp.as_mut_ptr().offset((i) as isize).h == 0 || *(*z).img_comp.as_mut_ptr().offset((i) as isize).h > 4 { return stbi__err((("bad H"))); }
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).v = ((q & 15) as i32);
		if *(*z).img_comp.as_mut_ptr().offset((i) as isize).v == 0 || *(*z).img_comp.as_mut_ptr().offset((i) as isize).v > 4 { return stbi__err((("bad V"))); }
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).tq = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
		if *(*z).img_comp.as_mut_ptr().offset((i) as isize).tq > 3 { return stbi__err((("bad TQ"))); }
		i += 1;
	}
	if scan != STBI__SCAN_load { return 1; }
	if stbi__mad3sizes_valid(((((*s).img_x) as i32) as i32), ((((*s).img_y) as i32) as i32), (((*s).img_n) as i32), ((0) as i32)) == 0 { return stbi__err((("too large"))); }
	i = ((0) as i32);
	while (i < (*s).img_n) {
		if *(*z).img_comp.as_mut_ptr().offset((i) as isize).h > h_max { h_max = ((*(*z).img_comp.as_mut_ptr().offset((i) as isize).h) as i32); }
		if *(*z).img_comp.as_mut_ptr().offset((i) as isize).v > v_max { v_max = ((*(*z).img_comp.as_mut_ptr().offset((i) as isize).v) as i32); }
		i += 1;
	}
	(*z).img_h_max = ((h_max) as i32);
	(*z).img_v_max = ((v_max) as i32);
	(*z).img_mcu_w = ((h_max * 8) as i32);
	(*z).img_mcu_h = ((v_max * 8) as i32);
	(*z).img_mcu_x = (((((*s).img_x + (((*z).img_mcu_w) as u32) - ((1) as u32)) / (((*z).img_mcu_w) as u32)) as i32) as i32);
	(*z).img_mcu_y = (((((*s).img_y + (((*z).img_mcu_h) as u32) - ((1) as u32)) / (((*z).img_mcu_h) as u32)) as i32) as i32);
	i = ((0) as i32);
	while (i < (*s).img_n) {
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).x = (((((*s).img_x * ((*(*z).img_comp.as_mut_ptr().offset((i) as isize).h) as u32) + ((h_max) as u32) - ((1) as u32)) / ((h_max) as u32)) as i32) as i32);
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).y = (((((*s).img_y * ((*(*z).img_comp.as_mut_ptr().offset((i) as isize).v) as u32) + ((v_max) as u32) - ((1) as u32)) / ((v_max) as u32)) as i32) as i32);
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).w2 = (((*z).img_mcu_x * *(*z).img_comp.as_mut_ptr().offset((i) as isize).h * 8) as i32);
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).h2 = (((*z).img_mcu_y * *(*z).img_comp.as_mut_ptr().offset((i) as isize).v * 8) as i32);
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).coeff = std::ptr::null_mut();
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_coeff = std::ptr::null_mut();
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).linebuf = (std::ptr::null_mut());
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_data = stbi__malloc_mad2(((*(*z).img_comp.as_mut_ptr().offset((i) as isize).w2) as i32), ((*(*z).img_comp.as_mut_ptr().offset((i) as isize).h2) as i32), ((15) as i32));
		if *(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_data == (std::ptr::null_mut()) { return stbi__free_jpeg_components(((z) as *mut stbi__jpeg), ((i + 1) as i32), ((stbi__err((("outofmem")))) as i32)); }
		*(*z).img_comp.as_mut_ptr().offset((i) as isize).data = (((((*(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_data) as u64) + ((15) as u64)) & ((!15) as u64)) as *mut u8);
		if ((*z).progressive) != 0 {
			*(*z).img_comp.as_mut_ptr().offset((i) as isize).coeff_w = ((*(*z).img_comp.as_mut_ptr().offset((i) as isize).w2 / 8) as i32);
			*(*z).img_comp.as_mut_ptr().offset((i) as isize).coeff_h = ((*(*z).img_comp.as_mut_ptr().offset((i) as isize).h2 / 8) as i32);
			*(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_coeff = stbi__malloc_mad3(((*(*z).img_comp.as_mut_ptr().offset((i) as isize).w2) as i32), ((*(*z).img_comp.as_mut_ptr().offset((i) as isize).h2) as i32), ((2) as i32), ((15) as i32));
			if *(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_coeff == (std::ptr::null_mut()) { return stbi__free_jpeg_components(((z) as *mut stbi__jpeg), ((i + 1) as i32), ((stbi__err((("outofmem")))) as i32)); }
			*(*z).img_comp.as_mut_ptr().offset((i) as isize).coeff = (((((*(*z).img_comp.as_mut_ptr().offset((i) as isize).raw_coeff) as u64) + ((15) as u64)) & ((!15) as u64)) as *mut i16);
		}
		i += 1;
	}
	return 1;
}

pub unsafe fn stbi__decode_jpeg_header(mut z: *mut stbi__jpeg, mut scan: i32) -> i32 {
	let mut m: i32 = std::mem::uninitialized();
	(*z).jfif = ((0) as i32);
	(*z).app14_color_transform = ((-1) as i32);
	(*z).marker = (((0xff) as u8) as u8);
	m = (((stbi__get_marker(((z) as *mut stbi__jpeg))) as i32) as i32);
	if !((m) == 0xd8) { return stbi__err((("no SOI"))); }
	if scan == STBI__SCAN_type { return 1; }
	m = (((stbi__get_marker(((z) as *mut stbi__jpeg))) as i32) as i32);
	while (!((m) == 0xc0 || (m) == 0xc1 || (m) == 0xc2)) {
		if stbi__process_marker(((z) as *mut stbi__jpeg), ((m) as i32)) == 0 { return 0; }
		m = (((stbi__get_marker(((z) as *mut stbi__jpeg))) as i32) as i32);
		while (m == 0xff) {
			if (stbi__at_eof((((*z).s) as *mut stbi__context))) != 0 { return stbi__err((("no SOF"))); }
			m = (((stbi__get_marker(((z) as *mut stbi__jpeg))) as i32) as i32);
		}
	}
	(*z).progressive = (((m) == 0xc2) as i32);
	if stbi__process_frame_header(((z) as *mut stbi__jpeg), ((scan) as i32)) == 0 { return 0; }
	return 1;
}

pub unsafe fn stbi__decode_jpeg_image(mut j: *mut stbi__jpeg) -> i32 {
	let mut m: i32 = std::mem::uninitialized();
	m = ((0) as i32);
	while (m < 4) {
		*(*j).img_comp.as_mut_ptr().offset((m) as isize).raw_data = (std::ptr::null_mut());
		*(*j).img_comp.as_mut_ptr().offset((m) as isize).raw_coeff = (std::ptr::null_mut());
		m += 1;
	}
	(*j).restart_interval = ((0) as i32);
	if stbi__decode_jpeg_header(((j) as *mut stbi__jpeg), ((STBI__SCAN_load) as i32)) == 0 { return 0; }
	m = (((stbi__get_marker(((j) as *mut stbi__jpeg))) as i32) as i32);
	while (!((m) == 0xd9)) {
		if ((m) == 0xda) {
			if stbi__process_scan_header(((j) as *mut stbi__jpeg)) == 0 { return 0; }
			if stbi__parse_entropy_coded_data(((j) as *mut stbi__jpeg)) == 0 { return 0; }
			if (((*j).marker) as i32) == 0xff {
				while (stbi__at_eof((((*j).s) as *mut stbi__context)) == 0) {
					let mut x: i32 = ((stbi__get8((((*j).s) as *mut stbi__context))) as i32);
					if x == 255 {
						(*j).marker = ((stbi__get8((((*j).s) as *mut stbi__context))) as u8);
						break;
					}
				}
			}
		} else {
			if ((m) == 0xdc) {
				let mut Ld: i32 = stbi__get16be((((*j).s) as *mut stbi__context));
				let mut NL: u32 = ((stbi__get16be((((*j).s) as *mut stbi__context))) as u32);
				if Ld != 4 { stbi__err((("bad DNL len"))); }
				if NL != (*j).s.img_y { stbi__err((("bad DNL height"))); }
			} else {
				if stbi__process_marker(((j) as *mut stbi__jpeg), ((m) as i32)) == 0 { return 0; }
			}
		}
		m = (((stbi__get_marker(((j) as *mut stbi__jpeg))) as i32) as i32);
	}
	if ((*j).progressive) != 0 { stbi__jpeg_finish(((j) as *mut stbi__jpeg)); }
	return 1;
}

pub unsafe fn resample_row_1(mut _out_: *mut u8, mut in_near: *mut u8, mut in_far: *mut u8, mut w: i32, mut hs: i32) -> *mut u8 {
	return in_near;
}

pub unsafe fn stbi__resample_row_v_2(mut _out_: *mut u8, mut in_near: *mut u8, mut in_far: *mut u8, mut w: i32, mut hs: i32) -> *mut u8 {
	let mut i: i32 = std::mem::uninitialized();
	i = ((0) as i32);
	while (i < w) {
		*_out_.offset((i) as isize) = ((((3 * ((*in_near.offset((i) as isize)) as i32) + ((*in_far.offset((i) as isize)) as i32) + 2) >> 2) as u8) as u8);
		i += 1;
	}
	return _out_;
}

pub unsafe fn stbi__resample_row_h_2(mut _out_: *mut u8, mut in_near: *mut u8, mut in_far: *mut u8, mut w: i32, mut hs: i32) -> *mut u8 {
	let mut i: i32 = std::mem::uninitialized();
	let mut input: *mut u8 = in_near;
	if w == 1 {
		*_out_.offset((0) as isize) = *input.offset((0) as isize);
		*_out_.offset((1) as isize) = *input.offset((0) as isize);
		return _out_;
	}
	*_out_.offset((0) as isize) = ((*input.offset((0) as isize)) as u8);
	*_out_.offset((1) as isize) = ((((((*input.offset((0) as isize)) as i32) * 3 + ((*input.offset((1) as isize)) as i32) + 2) >> 2) as u8) as u8);
	i = ((1) as i32);
	while (i < w - 1) {
		let mut n: i32 = 3 * ((*input.offset((i) as isize)) as i32) + 2;
		*_out_.offset((i * 2 + 0) as isize) = ((((n + ((*input.offset((i - 1) as isize)) as i32)) >> 2) as u8) as u8);
		*_out_.offset((i * 2 + 1) as isize) = ((((n + ((*input.offset((i + 1) as isize)) as i32)) >> 2) as u8) as u8);
		i += 1;
	}
	*_out_.offset((i * 2 + 0) as isize) = ((((((*input.offset((w - 2) as isize)) as i32) * 3 + ((*input.offset((w - 1) as isize)) as i32) + 2) >> 2) as u8) as u8);
	*_out_.offset((i * 2 + 1) as isize) = ((*input.offset((w - 1) as isize)) as u8);
	return _out_;
}

pub unsafe fn stbi__resample_row_hv_2(mut _out_: *mut u8, mut in_near: *mut u8, mut in_far: *mut u8, mut w: i32, mut hs: i32) -> *mut u8 {
	let mut i: i32 = std::mem::uninitialized();
	let mut t0: i32 = std::mem::uninitialized();
	let mut t1: i32 = std::mem::uninitialized();
	if w == 1 {
		*_out_.offset((0) as isize) = (((3 * ((*in_near.offset((0) as isize)) as i32) + ((*in_far.offset((0) as isize)) as i32) + 2) >> 2) as u8);
		*_out_.offset((1) as isize) = (((3 * ((*in_near.offset((0) as isize)) as i32) + ((*in_far.offset((0) as isize)) as i32) + 2) >> 2) as u8);
		return _out_;
	}
	t1 = ((3 * ((*in_near.offset((0) as isize)) as i32) + ((*in_far.offset((0) as isize)) as i32)) as i32);
	*_out_.offset((0) as isize) = ((((t1 + 2) >> 2) as u8) as u8);
	i = ((1) as i32);
	while (i < w) {
		t0 = ((t1) as i32);
		t1 = ((3 * ((*in_near.offset((i) as isize)) as i32) + ((*in_far.offset((i) as isize)) as i32)) as i32);
		*_out_.offset((i * 2 - 1) as isize) = ((((3 * t0 + t1 + 8) >> 4) as u8) as u8);
		*_out_.offset((i * 2) as isize) = ((((3 * t1 + t0 + 8) >> 4) as u8) as u8);
		i += 1;
	}
	*_out_.offset((w * 2 - 1) as isize) = ((((t1 + 2) >> 2) as u8) as u8);
	return _out_;
}

pub unsafe fn stbi__resample_row_generic(mut _out_: *mut u8, mut in_near: *mut u8, mut in_far: *mut u8, mut w: i32, mut hs: i32) -> *mut u8 {
	let mut i: i32 = std::mem::uninitialized();
	let mut j: i32 = std::mem::uninitialized();
	i = ((0) as i32);
	while (i < w) {
		j = ((0) as i32);
		while (j < hs) {
			*_out_.offset((i * hs + j) as isize) = ((*in_near.offset((i) as isize)) as u8);
			j += 1;
		}
		i += 1;
	}
	return _out_;
}

pub unsafe fn stbi__YCbCr_to_RGB_row(mut _out_: *mut u8, mut y: *mut u8, mut pcb: *mut u8, mut pcr: *mut u8, mut count: i32, mut step: i32) {
	let mut i: i32 = std::mem::uninitialized();
	i = ((0) as i32);
	while (i < count) {
		let mut y_fixed: i32 = (((*y.offset((i) as isize)) as i32) << 20) + (1 << 19);
		let mut r: i32 = std::mem::uninitialized();
		let mut g: i32 = std::mem::uninitialized();
		let mut b: i32 = std::mem::uninitialized();
		let mut cr: i32 = ((*pcr.offset((i) as isize)) as i32) - 128;
		let mut cb: i32 = ((*pcb.offset((i) as isize)) as i32) - 128;
		r = ((y_fixed + cr * ((((1.40200f32) * 4096.0f32 + 0.5f32) as i32) << 8)) as i32);
		g = (((((y_fixed + (cr * -((((0.71414f32) * 4096.0f32 + 0.5f32) as i32) << 8))) as u32) + (((cb * -((((0.34414f32) * 4096.0f32 + 0.5f32) as i32) << 8)) as u32) & 0xffff0000)) as i32) as i32);
		b = ((y_fixed + cb * ((((1.77200f32) * 4096.0f32 + 0.5f32) as i32) << 8)) as i32);
		r >>= 20;
		g >>= 20;
		b >>= 20;
		if ((r) as u32) > ((255) as u32) {
			if r < 0 { r = ((0) as i32); } else { r = ((255) as i32); }
		}
		if ((g) as u32) > ((255) as u32) {
			if g < 0 { g = ((0) as i32); } else { g = ((255) as i32); }
		}
		if ((b) as u32) > ((255) as u32) {
			if b < 0 { b = ((0) as i32); } else { b = ((255) as i32); }
		}
		*_out_.offset((0) as isize) = (((r) as u8) as u8);
		*_out_.offset((1) as isize) = (((g) as u8) as u8);
		*_out_.offset((2) as isize) = (((b) as u8) as u8);
		*_out_.offset((3) as isize) = (((255) as u8) as u8);
		_out_ = _out_.offset((((step) as *mut u8)) as isize);
		i += 1;
	}
}

pub unsafe fn stbi__setup_jpeg(mut j: *mut stbi__jpeg) {
	(*j).idct_block_kernel = ((stbi__idct_block) as *mut IntPtr);
	(*j).YCbCr_to_RGB_kernel = ((stbi__YCbCr_to_RGB_row) as *mut IntPtr);
	(*j).resample_row_hv_2_kernel = ((stbi__resample_row_hv_2) as *mut IntPtr);
}

pub unsafe fn stbi__cleanup_jpeg(mut j: *mut stbi__jpeg) {
	stbi__free_jpeg_components(((j) as *mut stbi__jpeg), (((*j).s.img_n) as i32), ((0) as i32));
}

pub unsafe fn stbi__blinn_8x8(mut x: u8, mut y: u8) -> u8 {
	let mut t: u32 = ((((x) as i32) * ((y) as i32) + 128) as u32);
	return (((t + (t >> 8)) >> 8) as u8);
}

pub unsafe fn load_jpeg_image(mut z: *mut stbi__jpeg, mut out_x: *mut i32, mut out_y: *mut i32, mut comp: *mut i32, mut req_comp: i32) -> *mut u8 {
	let mut n: i32 = std::mem::uninitialized();
	let mut decode_n: i32 = std::mem::uninitialized();
	let mut is_rgb: i32 = std::mem::uninitialized();
	(*z).s.img_n = ((0) as i32);
	if req_comp < 0 || req_comp > 4 { return (if stbi__err((("bad req_comp"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	if stbi__decode_jpeg_image(((z) as *mut stbi__jpeg)) == 0 {
		stbi__cleanup_jpeg(((z) as *mut stbi__jpeg));
		return (std::ptr::null_mut());
	}
	n = ((if (req_comp) != 0 { req_comp } else { if (*z).s.img_n >= 3 { 3 } else { 1 } }) as i32);
	is_rgb = (((*z).s.img_n == 3 && ((*z).rgb == 3 || ((*z).app14_color_transform == 0 && (*z).jfif == 0))) as i32);
	if (*z).s.img_n == 3 && n < 3 && is_rgb == 0 { decode_n = ((1) as i32); } else { decode_n = (((*z).s.img_n) as i32); }
	{
		let mut k: i32 = std::mem::uninitialized();
		let mut i: u32 = std::mem::uninitialized();
		let mut j: u32 = std::mem::uninitialized();
		let mut output: *mut u8;
		let mut coutput: [u8; 4] = std::mem::uninitialized();
		let mut res_comp: [stbi__resample; 4] = std::mem::uninitialized();
		k = ((0) as i32);
		while (k < decode_n) {
			let mut r: *mut stbi__resample = &mut *res_comp.as_mut_ptr().offset((k) as isize);
			*(*z).img_comp.as_mut_ptr().offset((k) as isize).linebuf = stbi__malloc(((((*z).s.img_x + ((3) as u32)) as u64) as u64));
			if *(*z).img_comp.as_mut_ptr().offset((k) as isize).linebuf == std::ptr::null_mut() {
				stbi__cleanup_jpeg(((z) as *mut stbi__jpeg));
				return (if stbi__err((("outofmem"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
			}
			(*r).hs = (((*z).img_h_max / *(*z).img_comp.as_mut_ptr().offset((k) as isize).h) as i32);
			(*r).vs = (((*z).img_v_max / *(*z).img_comp.as_mut_ptr().offset((k) as isize).v) as i32);
			(*r).ystep = (((*r).vs >> 1) as i32);
			(*r).w_lores = (((((*z).s.img_x + (((*r).hs) as u32) - ((1) as u32)) / (((*r).hs) as u32)) as i32) as i32);
			(*r).ypos = ((0) as i32);
			(*r).line0 = *(*z).img_comp.as_mut_ptr().offset((k) as isize).data;
			(*r).line1 = *(*z).img_comp.as_mut_ptr().offset((k) as isize).data;
			if (*r).hs == 1 && (*r).vs == 1 { (*r).resample = resample_row_1; } else { if (*r).hs == 1 && (*r).vs == 2 { (*r).resample = stbi__resample_row_v_2; } else { if (*r).hs == 2 && (*r).vs == 1 { (*r).resample = stbi__resample_row_h_2; } else { if (*r).hs == 2 && (*r).vs == 2 { (*r).resample = (((*z).resample_row_hv_2_kernel) as *mut unsigned char * (unsigned char *, unsigned char *, unsigned char *, int, int)); } else { (*r).resample = stbi__resample_row_generic; } } } }
			k += 1;
		}
		output = stbi__malloc_mad3(((n) as i32), ((((*z).s.img_x) as i32) as i32), ((((*z).s.img_y) as i32) as i32), ((1) as i32));
		if output == std::ptr::null_mut() {
			stbi__cleanup_jpeg(((z) as *mut stbi__jpeg));
			return (if stbi__err((("outofmem"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
		}
		j = (((0) as u32) as u32);
		while (j < (*z).s.img_y) {
			let mut _out_: *mut u8 = (output).offset((((n) as u32) * (*z).s.img_x * j) as isize);
			k = ((0) as i32);
			while (k < decode_n) {
				let mut r: *mut stbi__resample = &mut *res_comp.as_mut_ptr().offset((k) as isize);
				let mut y_bot: i32 = (*r).ystep >= ((*r).vs >> 1);
				*coutput.as_mut_ptr().offset((k) as isize) = ((*r).resample)(((*(*z).img_comp.as_mut_ptr().offset((k) as isize).linebuf) as *mut u8), ((if (y_bot) != 0 { (*r).line1 } else { (*r).line0 }) as *mut u8), ((if (y_bot) != 0 { (*r).line0 } else { (*r).line1 }) as *mut u8), (((*r).w_lores) as i32), (((*r).hs) as i32));
				if (*r).ystep += 1 >= (*r).vs {
					(*r).ystep = ((0) as i32);
					(*r).line0 = (*r).line1;
					if (*r).ypos += 1 < *(*z).img_comp.as_mut_ptr().offset((k) as isize).y { (*r).line1 = (*r).line1.offset((((*(*z).img_comp.as_mut_ptr().offset((k) as isize).w2) as *mut u8)) as isize); }
				}
				k += 1;
			}
			if n >= 3 {
				let mut y: *mut u8 = *coutput.as_mut_ptr().offset((0) as isize);
				if (*z).s.img_n == 3 {
					if (is_rgb) != 0 {
						i = (((0) as u32) as u32);
						while (i < (*z).s.img_x) {
							*_out_.offset((0) as isize) = ((*y.offset((i) as isize)) as u8);
							*_out_.offset((1) as isize) = ((**coutput.as_mut_ptr().offset((1) as isize).offset((i) as isize)) as u8);
							*_out_.offset((2) as isize) = ((**coutput.as_mut_ptr().offset((2) as isize).offset((i) as isize)) as u8);
							*_out_.offset((3) as isize) = (((255) as u8) as u8);
							_out_ = _out_.offset((((n) as *mut u8)) as isize);
							i += 1;
						}
					} else {
						((*z).YCbCr_to_RGB_kernel)(((_out_) as *mut u8), ((y) as *mut u8), ((*coutput.as_mut_ptr().offset((1) as isize)) as *mut u8), ((*coutput.as_mut_ptr().offset((2) as isize)) as *mut u8), ((((*z).s.img_x) as i32) as i32), ((n) as i32));
					}
				} else {
					if (*z).s.img_n == 4 {
						if (*z).app14_color_transform == 0 {
							i = (((0) as u32) as u32);
							while (i < (*z).s.img_x) {
								let mut m: u8 = **coutput.as_mut_ptr().offset((3) as isize).offset((i) as isize);
								*_out_.offset((0) as isize) = ((stbi__blinn_8x8(((**coutput.as_mut_ptr().offset((0) as isize).offset((i) as isize)) as u8), ((m) as u8))) as u8);
								*_out_.offset((1) as isize) = ((stbi__blinn_8x8(((**coutput.as_mut_ptr().offset((1) as isize).offset((i) as isize)) as u8), ((m) as u8))) as u8);
								*_out_.offset((2) as isize) = ((stbi__blinn_8x8(((**coutput.as_mut_ptr().offset((2) as isize).offset((i) as isize)) as u8), ((m) as u8))) as u8);
								*_out_.offset((3) as isize) = (((255) as u8) as u8);
								_out_ = _out_.offset((((n) as *mut u8)) as isize);
								i += 1;
							}
						} else {
							if (*z).app14_color_transform == 2 {
								((*z).YCbCr_to_RGB_kernel)(((_out_) as *mut u8), ((y) as *mut u8), ((*coutput.as_mut_ptr().offset((1) as isize)) as *mut u8), ((*coutput.as_mut_ptr().offset((2) as isize)) as *mut u8), ((((*z).s.img_x) as i32) as i32), ((n) as i32));
								i = (((0) as u32) as u32);
								while (i < (*z).s.img_x) {
									let mut m: u8 = **coutput.as_mut_ptr().offset((3) as isize).offset((i) as isize);
									*_out_.offset((0) as isize) = ((stbi__blinn_8x8((((255 - ((*_out_.offset((0) as isize)) as i32)) as u8) as u8), ((m) as u8))) as u8);
									*_out_.offset((1) as isize) = ((stbi__blinn_8x8((((255 - ((*_out_.offset((1) as isize)) as i32)) as u8) as u8), ((m) as u8))) as u8);
									*_out_.offset((2) as isize) = ((stbi__blinn_8x8((((255 - ((*_out_.offset((2) as isize)) as i32)) as u8) as u8), ((m) as u8))) as u8);
									_out_ = _out_.offset((((n) as *mut u8)) as isize);
									i += 1;
								}
							} else {
								((*z).YCbCr_to_RGB_kernel)(((_out_) as *mut u8), ((y) as *mut u8), ((*coutput.as_mut_ptr().offset((1) as isize)) as *mut u8), ((*coutput.as_mut_ptr().offset((2) as isize)) as *mut u8), ((((*z).s.img_x) as i32) as i32), ((n) as i32));
							}
						}
					} else {
						i = (((0) as u32) as u32);
						while (i < (*z).s.img_x) {
							*_out_.offset((0) as isize) = *y.offset((i) as isize);
							*_out_.offset((1) as isize) = *y.offset((i) as isize);
							*_out_.offset((2) as isize) = *y.offset((i) as isize);
							*_out_.offset((3) as isize) = (((255) as u8) as u8);
							_out_ = _out_.offset((((n) as *mut u8)) as isize);
							i += 1;
						}
					}
				}
			} else {
				if (is_rgb) != 0 {
					if n == 1 {
						i = (((0) as u32) as u32);
						while (i < (*z).s.img_x) {
							*_out_ = stbi__compute_y((((**coutput.as_mut_ptr().offset((0) as isize).offset((i) as isize)) as i32) as i32), (((**coutput.as_mut_ptr().offset((1) as isize).offset((i) as isize)) as i32) as i32), (((**coutput.as_mut_ptr().offset((2) as isize).offset((i) as isize)) as i32) as i32));
							(_out_ = _out_.offset(1));
							i += 1;
						}
					} else {
						i = (((0) as u32) as u32);
						while (i < (*z).s.img_x) {
							*_out_.offset((0) as isize) = ((stbi__compute_y((((**coutput.as_mut_ptr().offset((0) as isize).offset((i) as isize)) as i32) as i32), (((**coutput.as_mut_ptr().offset((1) as isize).offset((i) as isize)) as i32) as i32), (((**coutput.as_mut_ptr().offset((2) as isize).offset((i) as isize)) as i32) as i32))) as u8);
							*_out_.offset((1) as isize) = (((255) as u8) as u8);
							i += 1;
							_out_ = _out_.offset((((2) as *mut u8)) as isize);
						}
					}
				} else {
					if (*z).s.img_n == 4 && (*z).app14_color_transform == 0 {
						i = (((0) as u32) as u32);
						while (i < (*z).s.img_x) {
							let mut m: u8 = **coutput.as_mut_ptr().offset((3) as isize).offset((i) as isize);
							let mut r: u8 = stbi__blinn_8x8(((**coutput.as_mut_ptr().offset((0) as isize).offset((i) as isize)) as u8), ((m) as u8));
							let mut g: u8 = stbi__blinn_8x8(((**coutput.as_mut_ptr().offset((1) as isize).offset((i) as isize)) as u8), ((m) as u8));
							let mut b: u8 = stbi__blinn_8x8(((**coutput.as_mut_ptr().offset((2) as isize).offset((i) as isize)) as u8), ((m) as u8));
							*_out_.offset((0) as isize) = ((stbi__compute_y((((r) as i32) as i32), (((g) as i32) as i32), (((b) as i32) as i32))) as u8);
							*_out_.offset((1) as isize) = (((255) as u8) as u8);
							_out_ = _out_.offset((((n) as *mut u8)) as isize);
							i += 1;
						}
					} else {
						if (*z).s.img_n == 4 && (*z).app14_color_transform == 2 {
							i = (((0) as u32) as u32);
							while (i < (*z).s.img_x) {
								*_out_.offset((0) as isize) = ((stbi__blinn_8x8((((255 - ((**coutput.as_mut_ptr().offset((0) as isize).offset((i) as isize)) as i32)) as u8) as u8), ((**coutput.as_mut_ptr().offset((3) as isize).offset((i) as isize)) as u8))) as u8);
								*_out_.offset((1) as isize) = (((255) as u8) as u8);
								_out_ = _out_.offset((((n) as *mut u8)) as isize);
								i += 1;
							}
						} else {
							let mut y: *mut u8 = *coutput.as_mut_ptr().offset((0) as isize);
							if n == 1 {
								i = (((0) as u32) as u32);
								while (i < (*z).s.img_x) {
									*_out_.offset((i) as isize) = ((*y.offset((i) as isize)) as u8);
									i += 1;
								}
							} else {
								i = (((0) as u32) as u32);
								while (i < (*z).s.img_x) {
									*_out_ = *y.offset((i) as isize);
									(_out_ = _out_.offset(1));
									*_out_ = ((255) as u8);
									(_out_ = _out_.offset(1));
									i += 1;
								}
							}
						}
					}
				}
			}
			j += 1;
		}
		stbi__cleanup_jpeg(((z) as *mut stbi__jpeg));
		*out_x = ((((*z).s.img_x) as i32) as i32);
		*out_y = ((((*z).s.img_y) as i32) as i32);
		if (comp) != std::ptr::null_mut() { *comp = ((if (*z).s.img_n >= 3 { 3 } else { 1 }) as i32); }
		return output;
	}
}

pub unsafe fn stbi__jpeg_load(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32, mut ri: *mut stbi__result_info) -> *mut u8 {
	let mut result: *mut u8;
	let mut j: *mut stbi__jpeg = ((stbi__malloc(((std::mem::size_of::<stbi__jpeg>()) as u64))) as *mut stbi__jpeg);
	(*j).s = s;
	stbi__setup_jpeg(((j) as *mut stbi__jpeg));
	result = load_jpeg_image(((j) as *mut stbi__jpeg), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32), ((req_comp) as i32));
	c_runtime::free(((j) as *mut stbi__jpeg));
	return result;
}

pub unsafe fn stbi__jpeg_test(mut s: *mut stbi__context) -> i32 {
	let mut r: i32 = std::mem::uninitialized();
	let mut j: *mut stbi__jpeg = ((stbi__malloc(((std::mem::size_of::<stbi__jpeg>()) as u64))) as *mut stbi__jpeg);
	(*j).s = s;
	stbi__setup_jpeg(((j) as *mut stbi__jpeg));
	r = ((stbi__decode_jpeg_header(((j) as *mut stbi__jpeg), ((STBI__SCAN_type) as i32))) as i32);
	stbi__rewind(((s) as *mut stbi__context));
	c_runtime::free(((j) as *mut stbi__jpeg));
	return r;
}

pub unsafe fn stbi__jpeg_info_raw(mut j: *mut stbi__jpeg, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
	if stbi__decode_jpeg_header(((j) as *mut stbi__jpeg), ((STBI__SCAN_header) as i32)) == 0 {
		stbi__rewind((((*j).s) as *mut stbi__context));
		return 0;
	}
	if (x) != std::ptr::null_mut() { *x = ((((*j).s.img_x) as i32) as i32); }
	if (y) != std::ptr::null_mut() { *y = ((((*j).s.img_y) as i32) as i32); }
	if (comp) != std::ptr::null_mut() { *comp = ((if (*j).s.img_n >= 3 { 3 } else { 1 }) as i32); }
	return 1;
}

pub unsafe fn stbi__jpeg_info(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
	let mut result: i32 = std::mem::uninitialized();
	let mut j: *mut stbi__jpeg = ((stbi__malloc(((std::mem::size_of::<stbi__jpeg>()) as u64))) as *mut stbi__jpeg);
	(*j).s = s;
	result = ((stbi__jpeg_info_raw(((j) as *mut stbi__jpeg), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32))) as i32);
	c_runtime::free(((j) as *mut stbi__jpeg));
	return result;
}

pub unsafe fn stbi__bitreverse16(mut n: i32) -> i32 {
	n = ((((n & 0xAAAA) >> 1) | ((n & 0x5555) << 1)) as i32);
	n = ((((n & 0xCCCC) >> 2) | ((n & 0x3333) << 2)) as i32);
	n = ((((n & 0xF0F0) >> 4) | ((n & 0x0F0F) << 4)) as i32);
	n = ((((n & 0xFF00) >> 8) | ((n & 0x00FF) << 8)) as i32);
	return n;
}

pub unsafe fn stbi__bit_reverse(mut v: i32, mut bits: i32) -> i32 {
	return (stbi__bitreverse16(((v) as i32)) >> (16 - bits));
}

pub unsafe fn stbi__zbuild_huffman(mut z: *mut stbi__zhuffman, mut sizelist: *mut u8, mut num: i32) -> i32 {
	let mut i: i32 = std::mem::uninitialized();
	let mut k: i32 = 0;
	let mut code: i32 = std::mem::uninitialized();
	let mut next_code: [i32; 16] = std::mem::uninitialized();
	let mut sizes: [i32; 17] = std::mem::uninitialized();
	c_runtime::memset(((sizes.as_mut_ptr()) as *mut u8), ((0) as i32), ((sizes.len() * std::mem::size_of::<i32>()) as u64));
	c_runtime::memset((((*z).fast.as_mut_ptr()) as *mut u8), ((0) as i32), (((*z).fast.len() * std::mem::size_of::<u16>()) as u64));
	i = ((0) as i32);
	while (i < num) {
		*sizes.as_mut_ptr().offset((*sizelist.offset((i) as isize)) as isize) += 1;
		i += 1;
	}
	*sizes.as_mut_ptr().offset((0) as isize) = ((0) as i32);
	i = ((1) as i32);
	while (i < 16) {
		if *sizes.as_mut_ptr().offset((i) as isize) > (1 << i) { return stbi__err((("bad sizes"))); }
		i += 1;
	}
	code = ((0) as i32);
	i = ((1) as i32);
	while (i < 16) {
		*next_code.as_mut_ptr().offset((i) as isize) = ((code) as i32);
		*(*z).firstcode.as_mut_ptr().offset((i) as isize) = (((code) as u16) as u16);
		*(*z).firstsymbol.as_mut_ptr().offset((i) as isize) = (((k) as u16) as u16);
		code = ((code + *sizes.as_mut_ptr().offset((i) as isize)) as i32);
		if (*sizes.as_mut_ptr().offset((i) as isize)) != 0 { if code - 1 >= (1 << i) { return stbi__err((("bad codelengths"))); } }
		*(*z).maxcode.as_mut_ptr().offset((i) as isize) = ((code << (16 - i)) as i32);
		code <<= 1;
		k += ((*sizes.as_mut_ptr().offset((i) as isize)) as i32);
		i += 1;
	}
	*(*z).maxcode.as_mut_ptr().offset((16) as isize) = ((0x10000) as i32);
	i = ((0) as i32);
	while (i < num) {
		let mut s: i32 = ((*sizelist.offset((i) as isize)) as i32);
		if (s) != 0 {
			let mut c: i32 = *next_code.as_mut_ptr().offset((s) as isize) - ((*(*z).firstcode.as_mut_ptr().offset((s) as isize)) as i32) + ((*(*z).firstsymbol.as_mut_ptr().offset((s) as isize)) as i32);
			let mut fastv: u16 = (((s << 9) | i) as u16);
			*(*z).size.as_mut_ptr().offset((c) as isize) = (((s) as u8) as u8);
			*(*z).value.as_mut_ptr().offset((c) as isize) = (((i) as u16) as u16);
			if s <= 9 {
				let mut j: i32 = stbi__bit_reverse(((*next_code.as_mut_ptr().offset((s) as isize)) as i32), ((s) as i32));
				while (j < (1 << 9)) {
					*(*z).fast.as_mut_ptr().offset((j) as isize) = ((fastv) as u16);
					j += ((1 << s) as i32);
				}
			}
			*next_code.as_mut_ptr().offset((s) as isize) += 1;
		}
		i += 1;
	}
	return 1;
}

pub unsafe fn stbi__zget8(mut z: *mut stbi__zbuf) -> u8 {
	if (*z).zbuffer >= (*z).zbuffer_end { return ((0) as u8); }
	let mut res: u8 = *(*z).zbuffer;
	((*z).zbuffer = (*z).zbuffer.offset(1));
	return res;
}

pub unsafe fn stbi__fill_bits(mut z: *mut stbi__zbuf) {
	while (true) {
		(*z).code_buffer |= ((((stbi__zget8(((z) as *mut stbi__zbuf))) as u32) << (*z).num_bits) as u32);
		(*z).num_bits += ((8) as i32);
		if !((*z).num_bits <= 24) { break; }
	}
}

pub unsafe fn stbi__zreceive(mut z: *mut stbi__zbuf, mut n: i32) -> u32 {
	let mut k: u32 = std::mem::uninitialized();
	if (*z).num_bits < n { stbi__fill_bits(((z) as *mut stbi__zbuf)); }
	k = (((*z).code_buffer & (((1 << n) - 1) as u32)) as u32);
	(*z).code_buffer >>= n;
	(*z).num_bits -= ((n) as i32);
	return k;
}

pub unsafe fn stbi__zhuffman_decode_slowpath(mut a: *mut stbi__zbuf, mut z: *mut stbi__zhuffman) -> i32 {
	let mut b: i32 = std::mem::uninitialized();
	let mut s: i32 = std::mem::uninitialized();
	let mut k: i32 = std::mem::uninitialized();
	k = ((stbi__bit_reverse(((((*a).code_buffer) as i32) as i32), ((16) as i32))) as i32);
	s = ((9 + 1) as i32);
	while (true) {
		if k < *(*z).maxcode.as_mut_ptr().offset((s) as isize) { break; }
		s += 1;
	}
	if s == 16 { return -1; }
	b = (((k >> (16 - s)) - ((*(*z).firstcode.as_mut_ptr().offset((s) as isize)) as i32) + ((*(*z).firstsymbol.as_mut_ptr().offset((s) as isize)) as i32)) as i32);
	(*a).code_buffer >>= s;
	(*a).num_bits -= ((s) as i32);
	return ((*(*z).value.as_mut_ptr().offset((b) as isize)) as i32);
}

pub unsafe fn stbi__zhuffman_decode(mut a: *mut stbi__zbuf, mut z: *mut stbi__zhuffman) -> i32 {
	let mut b: i32 = std::mem::uninitialized();
	let mut s: i32 = std::mem::uninitialized();
	if (*a).num_bits < 16 { stbi__fill_bits(((a) as *mut stbi__zbuf)); }
	b = (((*(*z).fast.as_mut_ptr().offset(((*a).code_buffer & (((1 << 9) - 1) as u32)) as isize)) as i32) as i32);
	if (b) != 0 {
		s = ((b >> 9) as i32);
		(*a).code_buffer >>= s;
		(*a).num_bits -= ((s) as i32);
		return b & 511;
	}
	return stbi__zhuffman_decode_slowpath(((a) as *mut stbi__zbuf), ((z) as *mut stbi__zhuffman));
}

pub unsafe fn stbi__zexpand(mut z: *mut stbi__zbuf, mut zout: *mut i8, mut n: i32) -> i32 {
	let mut q: *mut i8;
	let mut cur: i32 = std::mem::uninitialized();
	let mut limit: i32 = std::mem::uninitialized();
	let mut old_limit: i32 = std::mem::uninitialized();
	(*z).zout = zout;
	if (*z).z_expandable == 0 { return stbi__err((("output buffer limit"))); }
	cur = ((((((*z).zout) as usize) - (((*z).zout_start) as usize)) as i32) as i32);
	limit = (((((*z).zout_end) as usize) - (((*z).zout_start) as usize)) as i32);
	old_limit = (((((*z).zout_end) as usize) - (((*z).zout_start) as usize)) as i32);
	while (cur + n > limit) { limit *= ((2) as i32); }
	q = ((c_runtime::realloc((((*z).zout_start) as *mut u8), (((limit) as u64) as u64))) as *mut i8);
	if q == (std::ptr::null_mut()) { return stbi__err((("outofmem"))); }
	(*z).zout_start = q;
	(*z).zout = (q).offset((cur) as isize);
	(*z).zout_end = (q).offset((limit) as isize);
	return 1;
}

pub unsafe fn stbi__parse_huffman_block(mut a: *mut stbi__zbuf) -> i32 {
	let mut zout: *mut i8 = (*a).zout;
	;
	while (true) {
		let mut z: i32 = stbi__zhuffman_decode(((a) as *mut stbi__zbuf), ((&mut (*a).z_length) as *mut stbi__zhuffman));
		if z < 256 {
			if z < 0 { return stbi__err((("bad huffman code"))); }
			if zout >= (*a).zout_end {
				if stbi__zexpand(((a) as *mut stbi__zbuf), ((zout) as *mut i8), ((1) as i32)) == 0 { return 0; }
				zout = (*a).zout;
			}
			*zout = (((z) as i8) as i8);
			(zout = zout.offset(1));
		} else {
			let mut p: *mut u8;
			let mut len: i32 = std::mem::uninitialized();
			let mut dist: i32 = std::mem::uninitialized();
			if z == 256 {
				(*a).zout = zout;
				return 1;
			}
			z -= ((257) as i32);
			len = ((*stbi__zlength_base.as_mut_ptr().offset((z) as isize)) as i32);
			if (*stbi__zlength_extra.as_mut_ptr().offset((z) as isize)) != 0 { len += ((stbi__zreceive(((a) as *mut stbi__zbuf), ((*stbi__zlength_extra.as_mut_ptr().offset((z) as isize)) as i32))) as i32); }
			z = ((stbi__zhuffman_decode(((a) as *mut stbi__zbuf), ((&mut (*a).z_distance) as *mut stbi__zhuffman))) as i32);
			if z < 0 { return stbi__err((("bad huffman code"))); }
			dist = ((*stbi__zdist_base.as_mut_ptr().offset((z) as isize)) as i32);
			if (*stbi__zdist_extra.as_mut_ptr().offset((z) as isize)) != 0 { dist += ((stbi__zreceive(((a) as *mut stbi__zbuf), ((*stbi__zdist_extra.as_mut_ptr().offset((z) as isize)) as i32))) as i32); }
			if ((zout) as usize) - (((*a).zout_start) as usize) < dist as usize { return stbi__err((("bad dist"))); }
			if (zout).offset((len) as isize) > (*a).zout_end {
				if stbi__zexpand(((a) as *mut stbi__zbuf), ((zout) as *mut i8), ((len) as i32)) == 0 { return 0; }
				zout = (*a).zout;
			}
			p = (((zout).offset(-((dist) as isize))) as *mut u8);
			if dist == 1 {
				let mut v: u8 = *p;
				if (len) != 0 {
					while (true) {
						*zout = (((v) as i8) as i8);
						(zout = zout.offset(1));
						len -= 1;
						if !((len) != 0) { break; }
					}
				}
			} else {
				if (len) != 0 {
					while (true) {
						*zout = (((*p) as i8) as i8);
						(zout = zout.offset(1));
						(p = p.offset(1));
						len -= 1;
						if !((len) != 0) { break; }
					}
				}
			}
		}
	}
	return 0;
}

pub unsafe fn stbi__compute_huffman_codes(mut a: *mut stbi__zbuf) -> i32 {
	let mut z_codelength: stbi__zhuffman = std::mem::uninitialized();
	let mut lencodes: [u8; 455] = std::mem::uninitialized();
	let mut codelength_sizes: [u8; 19] = std::mem::uninitialized();
	let mut i: i32 = std::mem::uninitialized();
	let mut n: i32 = std::mem::uninitialized();
	let mut hlit: i32 = ((stbi__zreceive(((a) as *mut stbi__zbuf), ((5) as i32)) + ((257) as u32)) as i32);
	let mut hdist: i32 = ((stbi__zreceive(((a) as *mut stbi__zbuf), ((5) as i32)) + ((1) as u32)) as i32);
	let mut hclen: i32 = ((stbi__zreceive(((a) as *mut stbi__zbuf), ((4) as i32)) + ((4) as u32)) as i32);
	let mut ntot: i32 = hlit + hdist;
	c_runtime::memset(((codelength_sizes.as_mut_ptr()) as *mut u8), ((0) as i32), ((codelength_sizes.len()) as u64));
	i = ((0) as i32);
	while (i < hclen) {
		let mut s: i32 = ((stbi__zreceive(((a) as *mut stbi__zbuf), ((3) as i32))) as i32);
		*codelength_sizes.as_mut_ptr().offset((*length_dezigzag.as_mut_ptr().offset((i) as isize)) as isize) = (((s) as u8) as u8);
		i += 1;
	}
	if stbi__zbuild_huffman(((&mut z_codelength) as *mut stbi__zhuffman), ((codelength_sizes.as_mut_ptr()) as *mut u8), ((19) as i32)) == 0 { return 0; }
	n = ((0) as i32);
	while (n < ntot) {
		let mut c: i32 = stbi__zhuffman_decode(((a) as *mut stbi__zbuf), ((&mut z_codelength) as *mut stbi__zhuffman));
		if c < 0 || c >= 19 { return stbi__err((("bad codelengths"))); }
		if c < 16 {
			*lencodes.as_mut_ptr().offset((n) as isize) = (((c) as u8) as u8);
			n += 1;
		} else {
			let mut fill: u8 = ((0) as u8);
			if c == 16 {
				c = (((stbi__zreceive(((a) as *mut stbi__zbuf), ((2) as i32)) + ((3) as u32)) as i32) as i32);
				if n == 0 { return stbi__err((("bad codelengths"))); }
				fill = ((*lencodes.as_mut_ptr().offset((n - 1) as isize)) as u8);
			} else {
				if c == 17 { c = (((stbi__zreceive(((a) as *mut stbi__zbuf), ((3) as i32)) + ((3) as u32)) as i32) as i32); } else {
					c = (((stbi__zreceive(((a) as *mut stbi__zbuf), ((7) as i32)) + ((11) as u32)) as i32) as i32);
				}
			}
			if ntot - n < c { return stbi__err((("bad codelengths"))); }
			c_runtime::memset((((lencodes.as_mut_ptr()).offset((n) as isize)) as *mut u8), (((fill) as i32) as i32), (((c) as u64) as u64));
			n += ((c) as i32);
		}
	}
	if n != ntot { return stbi__err((("bad codelengths"))); }
	if stbi__zbuild_huffman(((&mut (*a).z_length) as *mut stbi__zhuffman), ((lencodes.as_mut_ptr()) as *mut u8), ((hlit) as i32)) == 0 { return 0; }
	if stbi__zbuild_huffman(((&mut (*a).z_distance) as *mut stbi__zhuffman), (((lencodes.as_mut_ptr()).offset((hlit) as isize)) as *mut u8), ((hdist) as i32)) == 0 { return 0; }
	return 1;
}

pub unsafe fn stbi__parse_uncompressed_block(mut a: *mut stbi__zbuf) -> i32 {
	let mut header: [u8; 4] = std::mem::uninitialized();
	let mut len: i32 = std::mem::uninitialized();
	let mut nlen: i32 = std::mem::uninitialized();
	let mut k: i32 = std::mem::uninitialized();
	if ((*a).num_bits & 7) != 0 { stbi__zreceive(((a) as *mut stbi__zbuf), (((*a).num_bits & 7) as i32)); }
	k = ((0) as i32);
	while ((*a).num_bits > 0) {
		*header.as_mut_ptr().offset((k) as isize) = ((((*a).code_buffer & ((255) as u32)) as u8) as u8);
		k += 1;
		(*a).code_buffer >>= 8;
		(*a).num_bits -= ((8) as i32);
	}
	while (k < 4) {
		*header.as_mut_ptr().offset((k) as isize) = ((stbi__zget8(((a) as *mut stbi__zbuf))) as u8);
		k += 1;
	}
	len = ((((*header.as_mut_ptr().offset((1) as isize)) as i32) * 256 + ((*header.as_mut_ptr().offset((0) as isize)) as i32)) as i32);
	nlen = ((((*header.as_mut_ptr().offset((3) as isize)) as i32) * 256 + ((*header.as_mut_ptr().offset((2) as isize)) as i32)) as i32);
	if nlen != (len ^ 0xffff) { return stbi__err((("zlib corrupt"))); }
	if ((*a).zbuffer).offset((len) as isize) > (*a).zbuffer_end { return stbi__err((("read past buffer"))); }
	if ((*a).zout).offset((len) as isize) > (*a).zout_end { if stbi__zexpand(((a) as *mut stbi__zbuf), (((*a).zout) as *mut i8), ((len) as i32)) == 0 { return 0; } }
	c_runtime::memcpy((((*a).zout) as *mut u8), (((*a).zbuffer) as *mut u8), (((len) as u64) as u64));
	(*a).zbuffer = (*a).zbuffer.offset((((len) as *mut u8)) as isize);
	(*a).zout = (*a).zout.offset((((len) as *mut i8)) as isize);
	return 1;
}

pub unsafe fn stbi__parse_zlib_header(mut a: *mut stbi__zbuf) -> i32 {
	let mut cmf: i32 = ((stbi__zget8(((a) as *mut stbi__zbuf))) as i32);
	let mut cm: i32 = cmf & 15;
	let mut flg: i32 = ((stbi__zget8(((a) as *mut stbi__zbuf))) as i32);
	if (cmf * 256 + flg) % 31 != 0 { return stbi__err((("bad zlib header"))); }
	if (flg & 32) != 0 { return stbi__err((("no preset dict"))); }
	if cm != 8 { return stbi__err((("bad compression"))); }
	return 1;
}

pub unsafe fn stbi__parse_zlib(mut a: *mut stbi__zbuf, mut parse_header: i32) -> i32 {
	let mut _final_: i32 = std::mem::uninitialized();
	let mut _type_: i32 = std::mem::uninitialized();
	if (parse_header) != 0 { if stbi__parse_zlib_header(((a) as *mut stbi__zbuf)) == 0 { return 0; } }
	(*a).num_bits = ((0) as i32);
	(*a).code_buffer = (((0) as u32) as u32);
	while (true) {
		_final_ = (((stbi__zreceive(((a) as *mut stbi__zbuf), ((1) as i32))) as i32) as i32);
		_type_ = (((stbi__zreceive(((a) as *mut stbi__zbuf), ((2) as i32))) as i32) as i32);
		if _type_ == 0 {
			if stbi__parse_uncompressed_block(((a) as *mut stbi__zbuf)) == 0 { return 0; }
		} else {
			if _type_ == 3 {
				return 0;
			} else {
				if _type_ == 1 {
					if stbi__zbuild_huffman(((&mut (*a).z_length) as *mut stbi__zhuffman), ((stbi__zdefault_length.as_mut_ptr()) as *mut u8), ((288) as i32)) == 0 { return 0; }
					if stbi__zbuild_huffman(((&mut (*a).z_distance) as *mut stbi__zhuffman), ((stbi__zdefault_distance.as_mut_ptr()) as *mut u8), ((32) as i32)) == 0 { return 0; }
				} else {
					if stbi__compute_huffman_codes(((a) as *mut stbi__zbuf)) == 0 { return 0; }
				}
				if stbi__parse_huffman_block(((a) as *mut stbi__zbuf)) == 0 { return 0; }
			}
		}
		if !(_final_ == 0) { break; }
	}

	return 1;
}

pub unsafe fn stbi__do_zlib(mut a: *mut stbi__zbuf, mut obuf: *mut i8, mut olen: i32, mut exp: i32, mut parse_header: i32) -> i32 {
	(*a).zout_start = obuf;
	(*a).zout = obuf;
	(*a).zout_end = (obuf).offset((olen) as isize);
	(*a).z_expandable = ((exp) as i32);
	return stbi__parse_zlib(((a) as *mut stbi__zbuf), ((parse_header) as i32));
}

pub unsafe fn stbi_zlib_decode_malloc_guesssize(mut buffer: *mut i8, mut len: i32, mut initial_size: i32, mut outlen: *mut i32) -> *mut i8 {
	let mut a: stbi__zbuf = std::mem::uninitialized();
	let mut p: *mut i8 = ((stbi__malloc((((initial_size) as u64) as u64))) as *mut i8);
	if p == (std::ptr::null_mut()) { return (std::ptr::null_mut()); }
	a.zbuffer = ((buffer) as *mut u8);
	a.zbuffer_end = (((buffer) as *mut u8)).offset((len) as isize);
	if (stbi__do_zlib(((&mut a) as *mut stbi__zbuf), ((p) as *mut i8), ((initial_size) as i32), ((1) as i32), ((1) as i32))) != 0 {
		if (outlen) != std::ptr::null_mut() { *outlen = (((((a.zout) as usize) - ((a.zout_start) as usize)) as i32) as i32); }
		return a.zout_start;
	} else {
		c_runtime::free(((a.zout_start) as *mut i8));
		return (std::ptr::null_mut());
	}
}

pub unsafe fn stbi_zlib_decode_malloc(mut buffer: *mut i8, mut len: i32, mut outlen: *mut i32) -> *mut i8 {
	return stbi_zlib_decode_malloc_guesssize(((buffer) as *mut i8), ((len) as i32), ((16384) as i32), ((outlen) as *mut i32));
}

pub unsafe fn stbi_zlib_decode_malloc_guesssize_headerflag(mut buffer: *mut i8, mut len: i32, mut initial_size: i32, mut outlen: *mut i32, mut parse_header: i32) -> *mut i8 {
	let mut a: stbi__zbuf = std::mem::uninitialized();
	let mut p: *mut i8 = ((stbi__malloc((((initial_size) as u64) as u64))) as *mut i8);
	if p == (std::ptr::null_mut()) { return (std::ptr::null_mut()); }
	a.zbuffer = ((buffer) as *mut u8);
	a.zbuffer_end = (((buffer) as *mut u8)).offset((len) as isize);
	if (stbi__do_zlib(((&mut a) as *mut stbi__zbuf), ((p) as *mut i8), ((initial_size) as i32), ((1) as i32), ((parse_header) as i32))) != 0 {
		if (outlen) != std::ptr::null_mut() { *outlen = (((((a.zout) as usize) - ((a.zout_start) as usize)) as i32) as i32); }
		return a.zout_start;
	} else {
		c_runtime::free(((a.zout_start) as *mut i8));
		return (std::ptr::null_mut());
	}
}

pub unsafe fn stbi_zlib_decode_buffer(mut obuffer: *mut i8, mut olen: i32, mut ibuffer: *mut i8, mut ilen: i32) -> i32 {
	let mut a: stbi__zbuf = std::mem::uninitialized();
	a.zbuffer = ((ibuffer) as *mut u8);
	a.zbuffer_end = (((ibuffer) as *mut u8)).offset((ilen) as isize);
	if (stbi__do_zlib(((&mut a) as *mut stbi__zbuf), ((obuffer) as *mut i8), ((olen) as i32), ((0) as i32), ((1) as i32))) != 0 { return ((((a.zout) as usize) - ((a.zout_start) as usize)) as i32); } else { return -1; }
}

pub unsafe fn stbi_zlib_decode_noheader_malloc(mut buffer: *mut i8, mut len: i32, mut outlen: *mut i32) -> *mut i8 {
	let mut a: stbi__zbuf = std::mem::uninitialized();
	let mut p: *mut i8 = ((stbi__malloc((((16384) as u64) as u64))) as *mut i8);
	if p == (std::ptr::null_mut()) { return (std::ptr::null_mut()); }
	a.zbuffer = ((buffer) as *mut u8);
	a.zbuffer_end = (((buffer) as *mut u8)).offset((len) as isize);
	if (stbi__do_zlib(((&mut a) as *mut stbi__zbuf), ((p) as *mut i8), ((16384) as i32), ((1) as i32), ((0) as i32))) != 0 {
		if (outlen) != std::ptr::null_mut() { *outlen = (((((a.zout) as usize) - ((a.zout_start) as usize)) as i32) as i32); }
		return a.zout_start;
	} else {
		c_runtime::free(((a.zout_start) as *mut i8));
		return (std::ptr::null_mut());
	}
}

pub unsafe fn stbi_zlib_decode_noheader_buffer(mut obuffer: *mut i8, mut olen: i32, mut ibuffer: *mut i8, mut ilen: i32) -> i32 {
	let mut a: stbi__zbuf = std::mem::uninitialized();
	a.zbuffer = ((ibuffer) as *mut u8);
	a.zbuffer_end = (((ibuffer) as *mut u8)).offset((ilen) as isize);
	if (stbi__do_zlib(((&mut a) as *mut stbi__zbuf), ((obuffer) as *mut i8), ((olen) as i32), ((0) as i32), ((0) as i32))) != 0 { return ((((a.zout) as usize) - ((a.zout_start) as usize)) as i32); } else { return -1; }
}

pub unsafe fn stbi__get_chunk_header(mut s: *mut stbi__context) -> stbi__pngchunk {
	let mut c: stbi__pngchunk = std::mem::uninitialized();
	c.length = ((stbi__get32be(((s) as *mut stbi__context))) as u32);
	c._type_ = ((stbi__get32be(((s) as *mut stbi__context))) as u32);
	return c;
}

pub unsafe fn stbi__check_png_header(mut s: *mut stbi__context) -> i32 {
	let mut i: i32 = std::mem::uninitialized();
	i = ((0) as i32);
	while (i < 8) {
		if ((stbi__get8(((s) as *mut stbi__context))) as i32) != ((*png_sig.as_mut_ptr().offset((i) as isize)) as i32) { return stbi__err((("bad png sig"))); }
		i += 1;
	}
	return 1;
}

pub unsafe fn stbi__paeth(mut a: i32, mut b: i32, mut c: i32) -> i32 {
	let mut p: i32 = a + b - c;
	let mut pa: i32 = c_runtime::abs(((p - a) as i32));
	let mut pb: i32 = c_runtime::abs(((p - b) as i32));
	let mut pc: i32 = c_runtime::abs(((p - c) as i32));
	if pa <= pb && pa <= pc { return a; }
	if pb <= pc { return b; }
	return c;
}

pub unsafe fn stbi__create_png_image_raw(mut a: *mut stbi__png, mut raw: *mut u8, mut raw_len: u32, mut out_n: i32, mut x: u32, mut y: u32, mut depth: i32, mut color: i32) -> i32 {
	let mut bytes: i32 = (if depth == 16 { 2 } else { 1 });
	let mut s: *mut stbi__context = (*a).s;
	let mut i: u32 = std::mem::uninitialized();
	let mut j: u32 = std::mem::uninitialized();
	let mut stride: u32 = x * ((out_n) as u32) * ((bytes) as u32);
	let mut img_len: u32 = std::mem::uninitialized();
	let mut img_width_bytes: u32 = std::mem::uninitialized();
	let mut k: i32 = std::mem::uninitialized();
	let mut img_n: i32 = (*s).img_n;
	let mut output_bytes: i32 = out_n * bytes;
	let mut filter_bytes: i32 = img_n * bytes;
	let mut width: i32 = ((x) as i32);
	(*a)._out_ = stbi__malloc_mad3((((x) as i32) as i32), (((y) as i32) as i32), ((output_bytes) as i32), ((0) as i32));
	if (*a)._out_ == std::ptr::null_mut() { return stbi__err((("outofmem"))); }
	img_width_bytes = ((((((img_n) as u32) * x * ((depth) as u32)) + ((7) as u32)) >> 3) as u32);
	img_len = (((img_width_bytes + ((1) as u32)) * y) as u32);
	if raw_len < img_len { return stbi__err((("not enough pixels"))); }
	j = (((0) as u32) as u32);
	while (j < y) {
		let mut cur: *mut u8 = ((*a)._out_).offset((stride * j) as isize);
		let mut prior: *mut u8;
		let mut filter: i32 = ((*raw) as i32);
		(raw = raw.offset(1));
		if filter > 4 { return stbi__err((("invalid filter"))); }
		if depth < 8 {
			cur = cur.offset((((x * ((out_n) as u32) - img_width_bytes) as *mut u8)) as isize);
			filter_bytes = ((1) as i32);
			width = (((img_width_bytes) as i32) as i32);
		}
		prior = (cur).offset(-((stride) as isize));
		if j == ((0) as u32) { filter = ((*first_row_filter.as_mut_ptr().offset((filter) as isize)) as i32); }
		k = ((0) as i32);
		while (k < filter_bytes) {
			{
				if filter == STBI__F_none { *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8); } else if filter == STBI__F_sub { *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8); } else if filter == STBI__F_up { *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((*prior.offset((k) as isize)) as i32)) & 255) as u8) as u8); } else if filter == STBI__F_avg { *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + (((*prior.offset((k) as isize)) as i32) >> 1)) & 255) as u8) as u8); } else if filter == STBI__F_paeth { *cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + stbi__paeth(((0) as i32), (((*prior.offset((k) as isize)) as i32) as i32), ((0) as i32))) & 255) as u8) as u8); } else if filter == STBI__F_avg_first { *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8); } else if filter == STBI__F_paeth_first { *cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8); }
			}
			k += 1;
		}
		if depth == 8 {
			if img_n != out_n { *cur.offset((img_n) as isize) = (((255) as u8) as u8); }
			raw = raw.offset((((img_n) as *mut u8)) as isize);
			cur = cur.offset((((out_n) as *mut u8)) as isize);
			prior = prior.offset((((out_n) as *mut u8)) as isize);
		} else {
			if depth == 16 {
				if img_n != out_n {
					*cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
					*cur.offset((filter_bytes + 1) as isize) = (((255) as u8) as u8);
				}
				raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
				cur = cur.offset((((output_bytes) as *mut u8)) as isize);
				prior = prior.offset((((output_bytes) as *mut u8)) as isize);
			} else {
				raw = raw.offset((((1) as *mut u8)) as isize);
				cur = cur.offset((((1) as *mut u8)) as isize);
				prior = prior.offset((((1) as *mut u8)) as isize);
			}
		}
		if depth < 8 || img_n == out_n {
			let mut nk: i32 = (width - 1) * filter_bytes;
			{
				if filter == STBI__F_none { c_runtime::memcpy(((cur) as *mut u8), ((raw) as *mut u8), (((nk) as u64) as u64)); } else if filter == STBI__F_sub {
					k = ((0) as i32);
					while (k < nk) {
						*cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((*cur.offset((k - filter_bytes) as isize)) as i32)) & 255) as u8) as u8);
						k += 1;
					}
				} else if filter == STBI__F_up {
					k = ((0) as i32);
					while (k < nk) {
						*cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((*prior.offset((k) as isize)) as i32)) & 255) as u8) as u8);
						k += 1;
					}
				} else if filter == STBI__F_avg {
					k = ((0) as i32);
					while (k < nk) {
						*cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((((*prior.offset((k) as isize)) as i32) + ((*cur.offset((k - filter_bytes) as isize)) as i32)) >> 1)) & 255) as u8) as u8);
						k += 1;
					}
				} else if filter == STBI__F_paeth {
					k = ((0) as i32);
					while (k < nk) {
						*cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + stbi__paeth((((*cur.offset((k - filter_bytes) as isize)) as i32) as i32), (((*prior.offset((k) as isize)) as i32) as i32), (((*prior.offset((k - filter_bytes) as isize)) as i32) as i32))) & 255) as u8) as u8);
						k += 1;
					}
				} else if filter == STBI__F_avg_first {
					k = ((0) as i32);
					while (k < nk) {
						*cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + (((*cur.offset((k - filter_bytes) as isize)) as i32) >> 1)) & 255) as u8) as u8);
						k += 1;
					}
				} else if filter == STBI__F_paeth_first {
					k = ((0) as i32);
					while (k < nk) {
						*cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + stbi__paeth((((*cur.offset((k - filter_bytes) as isize)) as i32) as i32), ((0) as i32), ((0) as i32))) & 255) as u8) as u8);
						k += 1;
					}
				}
			}
			raw = raw.offset((((nk) as *mut u8)) as isize);
		} else {
			{
				if filter == STBI__F_none {
					i = ((x - ((1) as u32)) as u32);
					while (i >= ((1) as u32)) {
						k = ((0) as i32);
						while (k < filter_bytes) {
							*cur.offset((k) as isize) = ((*raw.offset((k) as isize)) as u8);
							k += 1;
						}
						i -= 1;
						*cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
						raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
						cur = cur.offset((((output_bytes) as *mut u8)) as isize);
						prior = prior.offset((((output_bytes) as *mut u8)) as isize);
					}
				} else if filter == STBI__F_sub {
					i = ((x - ((1) as u32)) as u32);
					while (i >= ((1) as u32)) {
						k = ((0) as i32);
						while (k < filter_bytes) {
							*cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((*cur.offset((k - output_bytes) as isize)) as i32)) & 255) as u8) as u8);
							k += 1;
						}
						i -= 1;
						*cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
						raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
						cur = cur.offset((((output_bytes) as *mut u8)) as isize);
						prior = prior.offset((((output_bytes) as *mut u8)) as isize);
					}
				} else if filter == STBI__F_up {
					i = ((x - ((1) as u32)) as u32);
					while (i >= ((1) as u32)) {
						k = ((0) as i32);
						while (k < filter_bytes) {
							*cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((*prior.offset((k) as isize)) as i32)) & 255) as u8) as u8);
							k += 1;
						}
						i -= 1;
						*cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
						raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
						cur = cur.offset((((output_bytes) as *mut u8)) as isize);
						prior = prior.offset((((output_bytes) as *mut u8)) as isize);
					}
				} else if filter == STBI__F_avg {
					i = ((x - ((1) as u32)) as u32);
					while (i >= ((1) as u32)) {
						k = ((0) as i32);
						while (k < filter_bytes) {
							*cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + ((((*prior.offset((k) as isize)) as i32) + ((*cur.offset((k - output_bytes) as isize)) as i32)) >> 1)) & 255) as u8) as u8);
							k += 1;
						}
						i -= 1;
						*cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
						raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
						cur = cur.offset((((output_bytes) as *mut u8)) as isize);
						prior = prior.offset((((output_bytes) as *mut u8)) as isize);
					}
				} else if filter == STBI__F_paeth {
					i = ((x - ((1) as u32)) as u32);
					while (i >= ((1) as u32)) {
						k = ((0) as i32);
						while (k < filter_bytes) {
							*cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + stbi__paeth((((*cur.offset((k - output_bytes) as isize)) as i32) as i32), (((*prior.offset((k) as isize)) as i32) as i32), (((*prior.offset((k - output_bytes) as isize)) as i32) as i32))) & 255) as u8) as u8);
							k += 1;
						}
						i -= 1;
						*cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
						raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
						cur = cur.offset((((output_bytes) as *mut u8)) as isize);
						prior = prior.offset((((output_bytes) as *mut u8)) as isize);
					}
				} else if filter == STBI__F_avg_first {
					i = ((x - ((1) as u32)) as u32);
					while (i >= ((1) as u32)) {
						k = ((0) as i32);
						while (k < filter_bytes) {
							*cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + (((*cur.offset((k - output_bytes) as isize)) as i32) >> 1)) & 255) as u8) as u8);
							k += 1;
						}
						i -= 1;
						*cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
						raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
						cur = cur.offset((((output_bytes) as *mut u8)) as isize);
						prior = prior.offset((((output_bytes) as *mut u8)) as isize);
					}
				} else if filter == STBI__F_paeth_first {
					i = ((x - ((1) as u32)) as u32);
					while (i >= ((1) as u32)) {
						k = ((0) as i32);
						while (k < filter_bytes) {
							*cur.offset((k) as isize) = ((((((*raw.offset((k) as isize)) as i32) + stbi__paeth((((*cur.offset((k - output_bytes) as isize)) as i32) as i32), ((0) as i32), ((0) as i32))) & 255) as u8) as u8);
							k += 1;
						}
						i -= 1;
						*cur.offset((filter_bytes) as isize) = (((255) as u8) as u8);
						raw = raw.offset((((filter_bytes) as *mut u8)) as isize);
						cur = cur.offset((((output_bytes) as *mut u8)) as isize);
						prior = prior.offset((((output_bytes) as *mut u8)) as isize);
					}
				}
			}
			if depth == 16 {
				cur = ((*a)._out_).offset((stride * j) as isize);
				i = (((0) as u32) as u32);
				while (i < x) {
					*cur.offset((filter_bytes + 1) as isize) = (((255) as u8) as u8);
					i += 1;
					cur = cur.offset((((output_bytes) as *mut u8)) as isize);
				}
			}
		}
		j += 1;
	}
	if depth < 8 {
		j = (((0) as u32) as u32);
		while (j < y) {
			let mut cur: *mut u8 = ((*a)._out_).offset((stride * j) as isize);
			let mut _in_: *mut u8 = ((((*a)._out_).offset((stride * j) as isize)).offset((x * ((out_n) as u32)) as isize)).offset(-((img_width_bytes) as isize));
			let mut scale: u8 = ((if (color == 0) { ((*stbi__depth_scale_table.as_mut_ptr().offset((depth) as isize)) as i32) } else { 1 }) as u8);
			if depth == 4 {
				k = (((x * ((img_n) as u32)) as i32) as i32);
				while (k >= 2) {
					*cur = ((((scale) as i32) * (((*_in_) as i32) >> 4)) as u8);
					(cur = cur.offset(1));
					*cur = ((((scale) as i32) * (((*_in_) as i32) & 0x0f)) as u8);
					(cur = cur.offset(1));
					k -= ((2) as i32);
					(_in_ = _in_.offset(1));
				}
				if k > 0 {
					*cur = ((((scale) as i32) * (((*_in_) as i32) >> 4)) as u8);
					(cur = cur.offset(1));
				}
			} else {
				if depth == 2 {
					k = (((x * ((img_n) as u32)) as i32) as i32);
					while (k >= 4) {
						*cur = ((((scale) as i32) * (((*_in_) as i32) >> 6)) as u8);
						(cur = cur.offset(1));
						*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 4) & 0x03)) as u8);
						(cur = cur.offset(1));
						*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 2) & 0x03)) as u8);
						(cur = cur.offset(1));
						*cur = ((((scale) as i32) * (((*_in_) as i32) & 0x03)) as u8);
						(cur = cur.offset(1));
						k -= ((4) as i32);
						(_in_ = _in_.offset(1));
					}
					if k > 0 {
						*cur = ((((scale) as i32) * (((*_in_) as i32) >> 6)) as u8);
						(cur = cur.offset(1));
					}
					if k > 1 {
						*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 4) & 0x03)) as u8);
						(cur = cur.offset(1));
					}
					if k > 2 {
						*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 2) & 0x03)) as u8);
						(cur = cur.offset(1));
					}
				} else {
					if depth == 1 {
						k = (((x * ((img_n) as u32)) as i32) as i32);
						while (k >= 8) {
							*cur = ((((scale) as i32) * (((*_in_) as i32) >> 7)) as u8);
							(cur = cur.offset(1));
							*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 6) & 0x01)) as u8);
							(cur = cur.offset(1));
							*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 5) & 0x01)) as u8);
							(cur = cur.offset(1));
							*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 4) & 0x01)) as u8);
							(cur = cur.offset(1));
							*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 3) & 0x01)) as u8);
							(cur = cur.offset(1));
							*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 2) & 0x01)) as u8);
							(cur = cur.offset(1));
							*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 1) & 0x01)) as u8);
							(cur = cur.offset(1));
							*cur = ((((scale) as i32) * (((*_in_) as i32) & 0x01)) as u8);
							(cur = cur.offset(1));
							k -= ((8) as i32);
							(_in_ = _in_.offset(1));
						}
						if k > 0 {
							*cur = ((((scale) as i32) * (((*_in_) as i32) >> 7)) as u8);
							(cur = cur.offset(1));
						}
						if k > 1 {
							*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 6) & 0x01)) as u8);
							(cur = cur.offset(1));
						}
						if k > 2 {
							*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 5) & 0x01)) as u8);
							(cur = cur.offset(1));
						}
						if k > 3 {
							*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 4) & 0x01)) as u8);
							(cur = cur.offset(1));
						}
						if k > 4 {
							*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 3) & 0x01)) as u8);
							(cur = cur.offset(1));
						}
						if k > 5 {
							*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 2) & 0x01)) as u8);
							(cur = cur.offset(1));
						}
						if k > 6 {
							*cur = ((((scale) as i32) * ((((*_in_) as i32) >> 1) & 0x01)) as u8);
							(cur = cur.offset(1));
						}
					}
				}
			}
			if img_n != out_n {
				let mut q: i32 = std::mem::uninitialized();
				cur = ((*a)._out_).offset((stride * j) as isize);
				if img_n == 1 {
					q = (((x - ((1) as u32)) as i32) as i32);
					while (q >= 0) {
						*cur.offset((q * 2 + 1) as isize) = (((255) as u8) as u8);
						*cur.offset((q * 2 + 0) as isize) = ((*cur.offset((q) as isize)) as u8);
						q -= 1;
					}
				} else {
					q = (((x - ((1) as u32)) as i32) as i32);
					while (q >= 0) {
						*cur.offset((q * 4 + 3) as isize) = (((255) as u8) as u8);
						*cur.offset((q * 4 + 2) as isize) = ((*cur.offset((q * 3 + 2) as isize)) as u8);
						*cur.offset((q * 4 + 1) as isize) = ((*cur.offset((q * 3 + 1) as isize)) as u8);
						*cur.offset((q * 4 + 0) as isize) = ((*cur.offset((q * 3 + 0) as isize)) as u8);
						q -= 1;
					}
				}
			}
			j += 1;
		}
	} else {
		if depth == 16 {
			let mut cur: *mut u8 = (*a)._out_;
			let mut cur16: *mut u16 = ((cur) as *mut u16);
			i = (((0) as u32) as u32);
			while (i < x * y * ((out_n) as u32)) {
				*cur16 = ((((((*cur.offset((0) as isize)) as i32) << 8) | ((*cur.offset((1) as isize)) as i32)) as u16) as u16);
				i += 1;
				(cur16 = cur16.offset(1));
				cur = cur.offset((((2) as *mut u8)) as isize);
			}
		}
	}
	return 1;
}

pub unsafe fn stbi__create_png_image(mut a: *mut stbi__png, mut image_data: *mut u8, mut image_data_len: u32, mut out_n: i32, mut depth: i32, mut color: i32, mut interlaced: i32) -> i32 {
	let mut bytes: i32 = (if depth == 16 { 2 } else { 1 });
	let mut out_bytes: i32 = out_n * bytes;
	let mut _final_: *mut u8;
	let mut p: i32 = std::mem::uninitialized();
	if interlaced == 0 { return stbi__create_png_image_raw(((a) as *mut stbi__png), ((image_data) as *mut u8), ((image_data_len) as u32), ((out_n) as i32), (((*(*a).s).img_x) as u32), (((*(*a).s).img_y) as u32), ((depth) as i32), ((color) as i32)); }
	_final_ = stbi__malloc_mad3(((((*(*a).s).img_x) as i32) as i32), ((((*(*a).s).img_y) as i32) as i32), ((out_bytes) as i32), ((0) as i32));
	p = ((0) as i32);
	while (p < 7) {
		let mut xorig: [i32; 7] = [0, 4, 0, 2, 0, 1, 0];
		let mut yorig: [i32; 7] = [0, 0, 4, 0, 2, 0, 1];
		let mut xspc: [i32; 7] = [8, 8, 4, 4, 2, 2, 1];
		let mut yspc: [i32; 7] = [8, 8, 8, 4, 4, 2, 2];
		let mut i: i32 = std::mem::uninitialized();
		let mut j: i32 = std::mem::uninitialized();
		let mut x: i32 = std::mem::uninitialized();
		let mut y: i32 = std::mem::uninitialized();
		x = (((((*(*a).s).img_x - ((*xorig.as_mut_ptr().offset((p) as isize)) as u32) + ((*xspc.as_mut_ptr().offset((p) as isize)) as u32) - ((1) as u32)) / ((*xspc.as_mut_ptr().offset((p) as isize)) as u32)) as i32) as i32);
		y = (((((*(*a).s).img_y - ((*yorig.as_mut_ptr().offset((p) as isize)) as u32) + ((*yspc.as_mut_ptr().offset((p) as isize)) as u32) - ((1) as u32)) / ((*yspc.as_mut_ptr().offset((p) as isize)) as u32)) as i32) as i32);
		if (x) != 0 && (y) != 0 {
			let mut img_len: u32 = (((((((*(*a).s).img_n * x * depth) + 7) >> 3) + 1) * y) as u32);
			if stbi__create_png_image_raw(((a) as *mut stbi__png), ((image_data) as *mut u8), ((image_data_len) as u32), ((out_n) as i32), (((x) as u32) as u32), (((y) as u32) as u32), ((depth) as i32), ((color) as i32)) == 0 {
				c_runtime::free(((_final_) as *mut u8));
				return 0;
			}
			j = ((0) as i32);
			while (j < y) {
				i = ((0) as i32);
				while (i < x) {
					let mut out_y: i32 = j * *yspc.as_mut_ptr().offset((p) as isize) + *yorig.as_mut_ptr().offset((p) as isize);
					let mut out_x: i32 = i * *xspc.as_mut_ptr().offset((p) as isize) + *xorig.as_mut_ptr().offset((p) as isize);
					c_runtime::memcpy(((((_final_).offset((((out_y) as u32) * (*(*a).s).img_x * ((out_bytes) as u32)) as isize)).offset((out_x * out_bytes) as isize)) as *mut u8), ((((*a)._out_).offset(((j * x + i) * out_bytes) as isize)) as *mut u8), (((out_bytes) as u64) as u64));
					i += 1;
				}
				j += 1;
			}
			c_runtime::free((((*a)._out_) as *mut u8));
			image_data = image_data.offset((((img_len) as *mut u8)) as isize);
			image_data_len -= ((img_len) as u32);
		}
		p += 1;
	}
	(*a)._out_ = _final_;
	return 1;
}

pub unsafe fn stbi__compute_transparency(mut z: *mut stbi__png, mut tc: *mut u8, mut out_n: i32) -> i32 {
	let mut s: *mut stbi__context = (*z).s;
	let mut i: u32 = std::mem::uninitialized();
	let mut pixel_count: u32 = (*s).img_x * (*s).img_y;
	let mut p: *mut u8 = (*z)._out_;
	if out_n == 2 {
		i = (((0) as u32) as u32);
		while (i < pixel_count) {
			*p.offset((1) as isize) = (((if ((*p.offset((0) as isize)) as i32) == ((*tc.offset((0) as isize)) as i32) { 0 } else { 255 }) as u8) as u8);
			p = p.offset((((2) as *mut u8)) as isize);
			i += 1;
		}
	} else {
		i = (((0) as u32) as u32);
		while (i < pixel_count) {
			if ((*p.offset((0) as isize)) as i32) == ((*tc.offset((0) as isize)) as i32) && ((*p.offset((1) as isize)) as i32) == ((*tc.offset((1) as isize)) as i32) && ((*p.offset((2) as isize)) as i32) == ((*tc.offset((2) as isize)) as i32) { *p.offset((3) as isize) = (((0) as u8) as u8); }
			p = p.offset((((4) as *mut u8)) as isize);
			i += 1;
		}
	}
	return 1;
}

pub unsafe fn stbi__compute_transparency16(mut z: *mut stbi__png, mut tc: *mut u16, mut out_n: i32) -> i32 {
	let mut s: *mut stbi__context = (*z).s;
	let mut i: u32 = std::mem::uninitialized();
	let mut pixel_count: u32 = (*s).img_x * (*s).img_y;
	let mut p: *mut u16 = (((*z)._out_) as *mut u16);
	if out_n == 2 {
		i = (((0) as u32) as u32);
		while (i < pixel_count) {
			*p.offset((1) as isize) = (((if ((*p.offset((0) as isize)) as i32) == ((*tc.offset((0) as isize)) as i32) { 0 } else { 65535 }) as u16) as u16);
			p = p.offset((((2) as *mut u16)) as isize);
			i += 1;
		}
	} else {
		i = (((0) as u32) as u32);
		while (i < pixel_count) {
			if ((*p.offset((0) as isize)) as i32) == ((*tc.offset((0) as isize)) as i32) && ((*p.offset((1) as isize)) as i32) == ((*tc.offset((1) as isize)) as i32) && ((*p.offset((2) as isize)) as i32) == ((*tc.offset((2) as isize)) as i32) { *p.offset((3) as isize) = (((0) as u16) as u16); }
			p = p.offset((((4) as *mut u16)) as isize);
			i += 1;
		}
	}
	return 1;
}

pub unsafe fn stbi__expand_png_palette(mut a: *mut stbi__png, mut palette: *mut u8, mut len: i32, mut pal_img_n: i32) -> i32 {
	let mut i: u32 = std::mem::uninitialized();
	let mut pixel_count: u32 = (*(*a).s).img_x * (*(*a).s).img_y;
	let mut p: *mut u8;
	let mut temp_out: *mut u8;
	let mut orig: *mut u8 = (*a)._out_;
	p = stbi__malloc_mad2((((pixel_count) as i32) as i32), ((pal_img_n) as i32), ((0) as i32));
	if p == (std::ptr::null_mut()) { return stbi__err((("outofmem"))); }
	temp_out = p;
	if pal_img_n == 3 {
		i = (((0) as u32) as u32);
		while (i < pixel_count) {
			let mut n: i32 = ((*orig.offset((i) as isize)) as i32) * 4;
			*p.offset((0) as isize) = ((*palette.offset((n) as isize)) as u8);
			*p.offset((1) as isize) = ((*palette.offset((n + 1) as isize)) as u8);
			*p.offset((2) as isize) = ((*palette.offset((n + 2) as isize)) as u8);
			p = p.offset((((3) as *mut u8)) as isize);
			i += 1;
		}
	} else {
		i = (((0) as u32) as u32);
		while (i < pixel_count) {
			let mut n: i32 = ((*orig.offset((i) as isize)) as i32) * 4;
			*p.offset((0) as isize) = ((*palette.offset((n) as isize)) as u8);
			*p.offset((1) as isize) = ((*palette.offset((n + 1) as isize)) as u8);
			*p.offset((2) as isize) = ((*palette.offset((n + 2) as isize)) as u8);
			*p.offset((3) as isize) = ((*palette.offset((n + 3) as isize)) as u8);
			p = p.offset((((4) as *mut u8)) as isize);
			i += 1;
		}
	}
	c_runtime::free((((*a)._out_) as *mut u8));
	(*a)._out_ = temp_out;
	return 1;
}

pub unsafe fn stbi_set_unpremultiply_on_load(mut flag_true_if_should_unpremultiply: i32) {
	stbi__unpremultiply_on_load = ((flag_true_if_should_unpremultiply) as i32);
}

pub unsafe fn stbi_convert_iphone_png_to_rgb(mut flag_true_if_should_convert: i32) {
	stbi__de_iphone_flag = ((flag_true_if_should_convert) as i32);
}

pub unsafe fn stbi__de_iphone(mut z: *mut stbi__png) {
	let mut s: *mut stbi__context = (*z).s;
	let mut i: u32 = std::mem::uninitialized();
	let mut pixel_count: u32 = (*s).img_x * (*s).img_y;
	let mut p: *mut u8 = (*z)._out_;
	if (*s).img_out_n == 3 {
		i = (((0) as u32) as u32);
		while (i < pixel_count) {
			let mut t: u8 = *p.offset((0) as isize);
			*p.offset((0) as isize) = ((*p.offset((2) as isize)) as u8);
			*p.offset((2) as isize) = ((t) as u8);
			p = p.offset((((3) as *mut u8)) as isize);
			i += 1;
		}
	} else {
		if (stbi__unpremultiply_on_load) != 0 {
			i = (((0) as u32) as u32);
			while (i < pixel_count) {
				let mut a: u8 = *p.offset((3) as isize);
				let mut t: u8 = *p.offset((0) as isize);
				if (a) != 0 {
					let mut half: u8 = ((((a) as i32) / 2) as u8);
					*p.offset((0) as isize) = ((((((*p.offset((2) as isize)) as i32) * 255 + ((half) as i32)) / ((a) as i32)) as u8) as u8);
					*p.offset((1) as isize) = ((((((*p.offset((1) as isize)) as i32) * 255 + ((half) as i32)) / ((a) as i32)) as u8) as u8);
					*p.offset((2) as isize) = ((((((t) as i32) * 255 + ((half) as i32)) / ((a) as i32)) as u8) as u8);
				} else {
					*p.offset((0) as isize) = ((*p.offset((2) as isize)) as u8);
					*p.offset((2) as isize) = ((t) as u8);
				}
				p = p.offset((((4) as *mut u8)) as isize);
				i += 1;
			}
		} else {
			i = (((0) as u32) as u32);
			while (i < pixel_count) {
				let mut t: u8 = *p.offset((0) as isize);
				*p.offset((0) as isize) = ((*p.offset((2) as isize)) as u8);
				*p.offset((2) as isize) = ((t) as u8);
				p = p.offset((((4) as *mut u8)) as isize);
				i += 1;
			}
		}
	}
}

pub unsafe fn stbi__parse_png_file(mut z: *mut stbi__png, mut scan: i32, mut req_comp: i32) -> i32 {
	let mut palette: [u8; 1024] = std::mem::uninitialized();
	let mut pal_img_n: u8 = ((0) as u8);
	let mut has_trans: u8 = ((0) as u8);
	let mut tc: [u8; 3] = std::mem::uninitialized();
	let mut tc16: [u16; 3] = std::mem::uninitialized();
	let mut ioff: u32 = ((0) as u32);
	let mut idata_limit: u32 = ((0) as u32);
	let mut i: u32 = std::mem::uninitialized();
	let mut pal_len: u32 = ((0) as u32);
	let mut first: i32 = 1;
	let mut k: i32 = std::mem::uninitialized();
	let mut interlace: i32 = 0;
	let mut color: i32 = 0;
	let mut is_iphone: i32 = 0;
	let mut s: *mut stbi__context = (*z).s;
	(*z).expanded = (std::ptr::null_mut());
	(*z).idata = (std::ptr::null_mut());
	(*z)._out_ = (std::ptr::null_mut());
	if stbi__check_png_header(((s) as *mut stbi__context)) == 0 { return 0; }
	if scan == STBI__SCAN_type { return 1; }
	;
	while (true) {
		let mut c: stbi__pngchunk = stbi__get_chunk_header(((s) as *mut stbi__context));
		{
			if c._type_ == ((((('C') as i32) << 24) + ((('g') as i32) << 16) + ((('B') as i32) << 8) + (('I') as i32)) as u32) {
				is_iphone = ((1) as i32);
				stbi__skip(((s) as *mut stbi__context), (((c.length) as i32) as i32));
			} else if c._type_ == ((((('I') as i32) << 24) + ((('H') as i32) << 16) + ((('D') as i32) << 8) + (('R') as i32)) as u32) {
				{
					let mut comp: i32 = std::mem::uninitialized();
					let mut filter: i32 = std::mem::uninitialized();
					if first == 0 { return stbi__err((("multiple IHDR"))); }
					first = ((0) as i32);
					if c.length != ((13) as u32) { return stbi__err((("bad IHDR len"))); }
					(*s).img_x = ((stbi__get32be(((s) as *mut stbi__context))) as u32);
					if (*s).img_x > ((1 << 24) as u32) { return stbi__err((("too large"))); }
					(*s).img_y = ((stbi__get32be(((s) as *mut stbi__context))) as u32);
					if (*s).img_y > ((1 << 24) as u32) { return stbi__err((("too large"))); }
					(*z).depth = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
					if (*z).depth != 1 && (*z).depth != 2 && (*z).depth != 4 && (*z).depth != 8 && (*z).depth != 16 { return stbi__err((("1/2/4/8/16-bit only"))); }
					color = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
					if color > 6 { return stbi__err((("bad ctype"))); }
					if color == 3 && (*z).depth == 16 { return stbi__err((("bad ctype"))); }
					if color == 3 { pal_img_n = (((3) as u8) as u8); } else { if (color & 1) != 0 { return stbi__err((("bad ctype"))); } }
					comp = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
					if (comp) != 0 { return stbi__err((("bad comp method"))); }
					filter = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
					if (filter) != 0 { return stbi__err((("bad filter method"))); }
					interlace = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
					if interlace > 1 { return stbi__err((("bad interlace method"))); }
					if (*s).img_x == 0 || (*s).img_y == 0 { return stbi__err((("0-pixel image"))); }
					if pal_img_n == 0 {
						(*s).img_n = (((if (color & 2) != 0 { 3 } else { 1 }) + (if (color & 4) != 0 { 1 } else { 0 })) as i32);
						if ((1 << 30) as u32) / (*s).img_x / (((*s).img_n) as u32) < (*s).img_y { return stbi__err((("too large"))); }
						if scan == STBI__SCAN_header { return 1; }
					} else {
						(*s).img_n = ((1) as i32);
						if ((1 << 30) as u32) / (*s).img_x / ((4) as u32) < (*s).img_y { return stbi__err((("too large"))); }
					}
				}
			} else if c._type_ == ((((('P') as i32) << 24) + ((('L') as i32) << 16) + ((('T') as i32) << 8) + (('E') as i32)) as u32) {
				{
					if (first) != 0 { return stbi__err((("first not IHDR"))); }
					if c.length > ((256 * 3) as u32) { return stbi__err((("invalid PLTE"))); }
					pal_len = ((c.length / ((3) as u32)) as u32);
					if pal_len * ((3) as u32) != c.length { return stbi__err((("invalid PLTE"))); }
					i = (((0) as u32) as u32);
					while (i < pal_len) {
						*palette.as_mut_ptr().offset((i * ((4) as u32) + ((0) as u32)) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
						*palette.as_mut_ptr().offset((i * ((4) as u32) + ((1) as u32)) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
						*palette.as_mut_ptr().offset((i * ((4) as u32) + ((2) as u32)) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
						*palette.as_mut_ptr().offset((i * ((4) as u32) + ((3) as u32)) as isize) = (((255) as u8) as u8);
						i += 1;
					}
				}
			} else if c._type_ == ((((('t') as i32) << 24) + ((('R') as i32) << 16) + ((('N') as i32) << 8) + (('S') as i32)) as u32) {
				{
					if (first) != 0 { return stbi__err((("first not IHDR"))); }
					if ((*z).idata) != std::ptr::null_mut() { return stbi__err((("tRNS after IDAT"))); }
					if (pal_img_n) != 0 {
						if scan == STBI__SCAN_header {
							(*s).img_n = ((4) as i32);
							return 1;
						}
						if pal_len == ((0) as u32) { return stbi__err((("tRNS before PLTE"))); }
						if c.length > pal_len { return stbi__err((("bad tRNS len"))); }
						pal_img_n = (((4) as u8) as u8);
						i = (((0) as u32) as u32);
						while (i < c.length) {
							*palette.as_mut_ptr().offset((i * ((4) as u32) + ((3) as u32)) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
							i += 1;
						}
					} else {
						if ((*s).img_n & 1) == 0 { return stbi__err((("tRNS with alpha"))); }
						if c.length != (((*s).img_n) as u32) * ((2) as u32) { return stbi__err((("bad tRNS len"))); }
						has_trans = (((1) as u8) as u8);
						if (*z).depth == 16 {
							k = ((0) as i32);
							while (k < (*s).img_n) {
								*tc16.as_mut_ptr().offset((k) as isize) = (((stbi__get16be(((s) as *mut stbi__context))) as u16) as u16);
								k += 1;
							}
						} else {
							k = ((0) as i32);
							while (k < (*s).img_n) {
								*tc.as_mut_ptr().offset((k) as isize) = ((((((stbi__get16be(((s) as *mut stbi__context)) & 255) as u8) as i32) * ((*stbi__depth_scale_table.as_mut_ptr().offset(((*z).depth) as isize)) as i32)) as u8) as u8);
								k += 1;
							}
						}
					}
				}
			} else if c._type_ == ((((('I') as i32) << 24) + ((('D') as i32) << 16) + ((('A') as i32) << 8) + (('T') as i32)) as u32) {
				{
					if (first) != 0 { return stbi__err((("first not IHDR"))); }
					if ((pal_img_n) as i32) != 0 && pal_len == 0 { return stbi__err((("no PLTE"))); }
					if scan == STBI__SCAN_header {
						(*s).img_n = (((pal_img_n) as i32) as i32);
						return 1;
					}
					if ((ioff + c.length) as i32) < ((ioff) as i32) { return 0; }
					if ioff + c.length > idata_limit {
						let mut idata_limit_old: u32 = idata_limit;
						let mut p: *mut u8;
						if idata_limit == ((0) as u32) { idata_limit = ((if c.length > ((4096) as u32) { c.length } else { ((4096) as u32) }) as u32); }
						while (ioff + c.length > idata_limit) { idata_limit *= (((2) as u32) as u32); }
						p = c_runtime::realloc((((*z).idata) as *mut u8), (((idata_limit) as u64) as u64));
						if p == (std::ptr::null_mut()) { return stbi__err((("outofmem"))); }
						(*z).idata = p;
					}
					if stbi__getn(((s) as *mut stbi__context), ((((*z).idata).offset((ioff) as isize)) as *mut u8), (((c.length) as i32) as i32)) == 0 { return stbi__err((("outofdata"))); }
					ioff += ((c.length) as u32);
				}
			} else if c._type_ == ((((('I') as i32) << 24) + ((('E') as i32) << 16) + ((('N') as i32) << 8) + (('D') as i32)) as u32) {
				{
					let mut raw_len: u32 = std::mem::uninitialized();
					let mut bpl: u32 = std::mem::uninitialized();
					if (first) != 0 { return stbi__err((("first not IHDR"))); }
					if scan != STBI__SCAN_load { return 1; }
					if (*z).idata == (std::ptr::null_mut()) { return stbi__err((("no IDAT"))); }
					bpl = ((((*s).img_x * (((*z).depth) as u32) + ((7) as u32)) / ((8) as u32)) as u32);
					raw_len = ((bpl * (*s).img_y * (((*s).img_n) as u32) + (*s).img_y) as u32);
					(*z).expanded = ((stbi_zlib_decode_malloc_guesssize_headerflag(((((*z).idata) as *mut i8) as *mut i8), (((ioff) as i32) as i32), (((raw_len) as i32) as i32), (((&mut raw_len) as *mut u32) as *mut i32), ((!is_iphone) as i32))) as *mut u8);
					if (*z).expanded == (std::ptr::null_mut()) { return 0; }
					c_runtime::free((((*z).idata) as *mut u8));
					(*z).idata = (std::ptr::null_mut());
					if (req_comp == (*s).img_n + 1 && req_comp != 3 && pal_img_n == 0) || ((has_trans) as i32) != 0 { (*s).img_out_n = (((*s).img_n + 1) as i32); } else { (*s).img_out_n = (((*s).img_n) as i32); }
					if stbi__create_png_image(((z) as *mut stbi__png), (((*z).expanded) as *mut u8), ((raw_len) as u32), (((*s).img_out_n) as i32), (((*z).depth) as i32), ((color) as i32), ((interlace) as i32)) == 0 { return 0; }
					if (has_trans) != 0 {
						if (*z).depth == 16 {
							if stbi__compute_transparency16(((z) as *mut stbi__png), ((tc16.as_mut_ptr()) as *mut u16), (((*s).img_out_n) as i32)) == 0 { return 0; }
						} else {
							if stbi__compute_transparency(((z) as *mut stbi__png), ((tc.as_mut_ptr()) as *mut u8), (((*s).img_out_n) as i32)) == 0 { return 0; }
						}
					}
					if (is_iphone) != 0 && (stbi__de_iphone_flag) != 0 && (*s).img_out_n > 2 { stbi__de_iphone(((z) as *mut stbi__png)); }
					if (pal_img_n) != 0 {
						(*s).img_n = (((pal_img_n) as i32) as i32);
						(*s).img_out_n = (((pal_img_n) as i32) as i32);
						if req_comp >= 3 { (*s).img_out_n = ((req_comp) as i32); }
						if stbi__expand_png_palette(((z) as *mut stbi__png), ((palette.as_mut_ptr()) as *mut u8), (((pal_len) as i32) as i32), (((*s).img_out_n) as i32)) == 0 { return 0; }
					} else {
						if (has_trans) != 0 {
							(*s).img_n += 1;
						}
					}
					c_runtime::free((((*z).expanded) as *mut u8));
					(*z).expanded = (std::ptr::null_mut());
					return 1;
				}
			} else {
				if (first) != 0 { return stbi__err((("first not IHDR"))); }
				if (c._type_ & ((1 << 29) as u32)) == ((0) as u32) {
					return stbi__err((("XXXX PNG chunk not known")));
				}
				stbi__skip(((s) as *mut stbi__context), (((c.length) as i32) as i32));
			}
		}
		stbi__get32be(((s) as *mut stbi__context));
	}
	return 0;
}

pub unsafe fn stbi__do_png(mut p: *mut stbi__png, mut x: *mut i32, mut y: *mut i32, mut n: *mut i32, mut req_comp: i32, mut ri: *mut stbi__result_info) -> *mut u8 {
	let mut result: *mut u8 = (std::ptr::null_mut());
	if req_comp < 0 || req_comp > 4 { return (if stbi__err((("bad req_comp"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	if (stbi__parse_png_file(((p) as *mut stbi__png), ((STBI__SCAN_load) as i32), ((req_comp) as i32))) != 0 {
		if (*p).depth < 8 { (*ri).bits_per_channel = ((8) as i32); } else { (*ri).bits_per_channel = (((*p).depth) as i32); }
		result = (*p)._out_;
		(*p)._out_ = (std::ptr::null_mut());
		if (req_comp) != 0 && req_comp != (*(*p).s).img_out_n {
			if (*ri).bits_per_channel == 8 { result = stbi__convert_format(((result) as *mut u8), (((*(*p).s).img_out_n) as i32), ((req_comp) as i32), (((*(*p).s).img_x) as u32), (((*(*p).s).img_y) as u32)); } else { result = stbi__convert_format16((((result) as *mut u16) as *mut u16), (((*(*p).s).img_out_n) as i32), ((req_comp) as i32), (((*(*p).s).img_x) as u32), (((*(*p).s).img_y) as u32)) as *mut u8; }
			(*(*p).s).img_out_n = ((req_comp) as i32);
			if result == (std::ptr::null_mut()) { return result; }
		}
		*x = ((((*(*p).s).img_x) as i32) as i32);
		*y = ((((*(*p).s).img_y) as i32) as i32);
		if (n) != std::ptr::null_mut() { *n = (((*(*p).s).img_n) as i32); }
	}
	c_runtime::free((((*p)._out_) as *mut u8));
	(*p)._out_ = (std::ptr::null_mut());
	c_runtime::free((((*p).expanded) as *mut u8));
	(*p).expanded = (std::ptr::null_mut());
	c_runtime::free((((*p).idata) as *mut u8));
	(*p).idata = (std::ptr::null_mut());
	return result;
}

pub unsafe fn stbi__png_load(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32, mut ri: *mut stbi__result_info) -> *mut u8 {
	let mut p: stbi__png = std::mem::uninitialized();
	p.s = s;
	return stbi__do_png(((&mut p) as *mut stbi__png), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32), ((req_comp) as i32), ((ri) as *mut stbi__result_info));
}

pub unsafe fn stbi__png_test(mut s: *mut stbi__context) -> i32 {
	let mut r: i32 = std::mem::uninitialized();
	r = ((stbi__check_png_header(((s) as *mut stbi__context))) as i32);
	stbi__rewind(((s) as *mut stbi__context));
	return r;
}

pub unsafe fn stbi__png_info_raw(mut p: *mut stbi__png, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
	if stbi__parse_png_file(((p) as *mut stbi__png), ((STBI__SCAN_header) as i32), ((0) as i32)) == 0 {
		stbi__rewind((((*p).s) as *mut stbi__context));
		return 0;
	}
	if (x) != std::ptr::null_mut() { *x = ((((*(*p).s).img_x) as i32) as i32); }
	if (y) != std::ptr::null_mut() { *y = ((((*(*p).s).img_y) as i32) as i32); }
	if (comp) != std::ptr::null_mut() { *comp = (((*(*p).s).img_n) as i32); }
	return 1;
}

pub unsafe fn stbi__png_info(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
	let mut p: stbi__png = std::mem::uninitialized();
	p.s = s;
	return stbi__png_info_raw(((&mut p) as *mut stbi__png), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32));
}

pub unsafe fn stbi__bmp_test_raw(mut s: *mut stbi__context) -> i32 {
	let mut r: i32 = std::mem::uninitialized();
	let mut sz: i32 = std::mem::uninitialized();
	if ((stbi__get8(((s) as *mut stbi__context))) as i32) != 'B' { return 0; }
	if ((stbi__get8(((s) as *mut stbi__context))) as i32) != 'M' { return 0; }
	stbi__get32le(((s) as *mut stbi__context));
	stbi__get16le(((s) as *mut stbi__context));
	stbi__get16le(((s) as *mut stbi__context));
	stbi__get32le(((s) as *mut stbi__context));
	sz = (((stbi__get32le(((s) as *mut stbi__context))) as i32) as i32);
	r = ((sz == 12 || sz == 40 || sz == 56 || sz == 108 || sz == 124) as i32);
	return r;
}

pub unsafe fn stbi__bmp_test(mut s: *mut stbi__context) -> i32 {
	let mut r: i32 = stbi__bmp_test_raw(((s) as *mut stbi__context));
	stbi__rewind(((s) as *mut stbi__context));
	return r;
}

pub unsafe fn stbi__high_bit(mut z: u32) -> i32 {
	let mut n: i32 = 0;
	if z == ((0) as u32) { return -1; }
	if z >= ((0x10000) as u32) {
		n += ((16) as i32);
		z >>= 16;
	}
	if z >= ((0x00100) as u32) {
		n += ((8) as i32);
		z >>= 8;
	}
	if z >= ((0x00010) as u32) {
		n += ((4) as i32);
		z >>= 4;
	}
	if z >= ((0x00004) as u32) {
		n += ((2) as i32);
		z >>= 2;
	}
	if z >= ((0x00002) as u32) {
		n += ((1) as i32);
		z >>= 1;
	}
	return n;
}

pub unsafe fn stbi__bitcount(mut a: u32) -> i32 {
	a = (((a & ((0x55555555) as u32)) + ((a >> 1) & ((0x55555555) as u32))) as u32);
	a = (((a & ((0x33333333) as u32)) + ((a >> 2) & ((0x33333333) as u32))) as u32);
	a = (((a + (a >> 4)) & ((0x0f0f0f0f) as u32)) as u32);
	a = ((a + (a >> 8)) as u32);
	a = ((a + (a >> 16)) as u32);
	return ((a & ((0xff) as u32)) as i32);
}

pub unsafe fn stbi__shiftsigned(mut v: i32, mut shift: i32, mut bits: i32) -> i32 {
	let mut result: i32 = std::mem::uninitialized();
	let mut z: i32 = 0;
	if shift < 0 { v <<= -shift; } else { v >>= shift; }
	result = ((v) as i32);
	z = ((bits) as i32);
	while (z < 8) {
		result += ((v >> z) as i32);
		z += ((bits) as i32);
	}
	return result;
}

pub unsafe fn stbi__bmp_parse_header(mut s: *mut stbi__context, mut info: *mut stbi__bmp_data) -> *mut u8 {
	let mut hsz: i32 = std::mem::uninitialized();
	if ((stbi__get8(((s) as *mut stbi__context))) as i32) != 'B' || ((stbi__get8(((s) as *mut stbi__context))) as i32) != 'M' { return (if stbi__err((("not BMP"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	stbi__get32le(((s) as *mut stbi__context));
	stbi__get16le(((s) as *mut stbi__context));
	stbi__get16le(((s) as *mut stbi__context));
	(*info).offset = (((stbi__get32le(((s) as *mut stbi__context))) as i32) as i32);
	(*info).hsz = ((stbi__get32le(((s) as *mut stbi__context))) as i32);
	hsz = ((stbi__get32le(((s) as *mut stbi__context))) as i32);
	(*info).mr = ((0) as u32);
	(*info).mg = ((0) as u32);
	(*info).mb = ((0) as u32);
	(*info).ma = ((0) as u32);
	if hsz != 12 && hsz != 40 && hsz != 56 && hsz != 108 && hsz != 124 { return (if stbi__err((("unknown BMP"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	if hsz == 12 {
		(*s).img_x = (((stbi__get16le(((s) as *mut stbi__context))) as u32) as u32);
		(*s).img_y = (((stbi__get16le(((s) as *mut stbi__context))) as u32) as u32);
	} else {
		(*s).img_x = ((stbi__get32le(((s) as *mut stbi__context))) as u32);
		(*s).img_y = ((stbi__get32le(((s) as *mut stbi__context))) as u32);
	}
	if stbi__get16le(((s) as *mut stbi__context)) != 1 { return (if stbi__err((("bad BMP"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	(*info).bpp = ((stbi__get16le(((s) as *mut stbi__context))) as i32);
	if (*info).bpp == 1 { return (if stbi__err((("monochrome"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	if hsz != 12 {
		let mut compress: i32 = ((stbi__get32le(((s) as *mut stbi__context))) as i32);
		if compress == 1 || compress == 2 { return (if stbi__err((("BMP RLE"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
		stbi__get32le(((s) as *mut stbi__context));
		stbi__get32le(((s) as *mut stbi__context));
		stbi__get32le(((s) as *mut stbi__context));
		stbi__get32le(((s) as *mut stbi__context));
		stbi__get32le(((s) as *mut stbi__context));
		if hsz == 40 || hsz == 56 {
			if hsz == 56 {
				stbi__get32le(((s) as *mut stbi__context));
				stbi__get32le(((s) as *mut stbi__context));
				stbi__get32le(((s) as *mut stbi__context));
				stbi__get32le(((s) as *mut stbi__context));
			}
			if (*info).bpp == 16 || (*info).bpp == 32 {
				if compress == 0 {
					if (*info).bpp == 32 {
						(*info).mr = ((0xff << 16) as u32);
						(*info).mg = ((0xff << 8) as u32);
						(*info).mb = ((0xff << 0) as u32);
						(*info).ma = ((0xff << 24) as u32);
						(*info).all_a = (((0) as u32) as u32);
					} else {
						(*info).mr = ((31 << 10) as u32);
						(*info).mg = ((31 << 5) as u32);
						(*info).mb = ((31 << 0) as u32);
					}
				} else {
					if compress == 3 {
						(*info).mr = ((stbi__get32le(((s) as *mut stbi__context))) as u32);
						(*info).mg = ((stbi__get32le(((s) as *mut stbi__context))) as u32);
						(*info).mb = ((stbi__get32le(((s) as *mut stbi__context))) as u32);
						if (*info).mr == (*info).mg && (*info).mg == (*info).mb {
							return (if stbi__err((("bad BMP"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
						}
					} else { return (if stbi__err((("bad BMP"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
				}
			}
		} else {
			let mut i: i32 = std::mem::uninitialized();
			if hsz != 108 && hsz != 124 { return (if stbi__err((("bad BMP"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
			(*info).mr = ((stbi__get32le(((s) as *mut stbi__context))) as u32);
			(*info).mg = ((stbi__get32le(((s) as *mut stbi__context))) as u32);
			(*info).mb = ((stbi__get32le(((s) as *mut stbi__context))) as u32);
			(*info).ma = ((stbi__get32le(((s) as *mut stbi__context))) as u32);
			stbi__get32le(((s) as *mut stbi__context));
			i = ((0) as i32);
			while (i < 12) {
				stbi__get32le(((s) as *mut stbi__context));
				i += 1;
			}
			if hsz == 124 {
				stbi__get32le(((s) as *mut stbi__context));
				stbi__get32le(((s) as *mut stbi__context));
				stbi__get32le(((s) as *mut stbi__context));
				stbi__get32le(((s) as *mut stbi__context));
			}
		}
	}
	return ((1) as *mut u8);
}

pub unsafe fn stbi__bmp_load(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32, mut ri: *mut stbi__result_info) -> *mut u8 {
	let mut _out_: *mut u8;
	let mut mr: u32 = ((0) as u32);
	let mut mg: u32 = ((0) as u32);
	let mut mb: u32 = ((0) as u32);
	let mut ma: u32 = ((0) as u32);
	let mut all_a: u32 = std::mem::uninitialized();
	let mut pal: [u8; 256] = std::mem::uninitialized();
	let mut psize: i32 = 0;
	let mut i: i32 = std::mem::uninitialized();
	let mut j: i32 = std::mem::uninitialized();
	let mut width: i32 = std::mem::uninitialized();
	let mut flip_vertically: i32 = std::mem::uninitialized();
	let mut pad: i32 = std::mem::uninitialized();
	let mut target: i32 = std::mem::uninitialized();
	let mut info: stbi__bmp_data = std::mem::uninitialized();
	info.all_a = (((255) as u32) as u32);
	if stbi__bmp_parse_header(((s) as *mut stbi__context), ((&mut info) as *mut stbi__bmp_data)) == (std::ptr::null_mut()) { return (std::ptr::null_mut()); }
	flip_vertically = (((((*s).img_y) as i32) > 0) as i32);
	(*s).img_y = (((c_runtime::abs(((((*s).img_y) as i32) as i32))) as u32) as u32);
	mr = ((info.mr) as u32);
	mg = ((info.mg) as u32);
	mb = ((info.mb) as u32);
	ma = ((info.ma) as u32);
	all_a = ((info.all_a) as u32);
	if info.hsz == 12 {
		if info.bpp < 24 { psize = (((info.offset - 14 - 24) / 3) as i32); }
	} else {
		if info.bpp < 16 { psize = (((info.offset - 14 - info.hsz) >> 2) as i32); }
	}
	(*s).img_n = ((if (ma) != 0 { 4 } else { 3 }) as i32);
	if (req_comp) != 0 && req_comp >= 3 { target = ((req_comp) as i32); } else { target = (((*s).img_n) as i32); }
	if stbi__mad3sizes_valid(((target) as i32), ((((*s).img_x) as i32) as i32), ((((*s).img_y) as i32) as i32), ((0) as i32)) == 0 { return (if stbi__err((("too large"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	_out_ = stbi__malloc_mad3(((target) as i32), ((((*s).img_x) as i32) as i32), ((((*s).img_y) as i32) as i32), ((0) as i32));
	if _out_ == std::ptr::null_mut() { return (if stbi__err((("outofmem"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	if info.bpp < 16 {
		let mut z: i32 = 0;
		if psize == 0 || psize > 256 {
			c_runtime::free(((_out_) as *mut u8));
			return (if stbi__err((("invalid"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
		}
		i = ((0) as i32);
		while (i < psize) {
			**pal.as_mut_ptr().offset((i) as isize).as_mut_ptr().offset((2) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
			**pal.as_mut_ptr().offset((i) as isize).as_mut_ptr().offset((1) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
			**pal.as_mut_ptr().offset((i) as isize).as_mut_ptr().offset((0) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
			if info.hsz != 12 { stbi__get8(((s) as *mut stbi__context)); }
			**pal.as_mut_ptr().offset((i) as isize).as_mut_ptr().offset((3) as isize) = (((255) as u8) as u8);
			i += 1;
		}
		stbi__skip(((s) as *mut stbi__context), ((info.offset - 14 - info.hsz - psize * (if info.hsz == 12 { 3 } else { 4 })) as i32));
		if info.bpp == 4 { width = (((((*s).img_x + ((1) as u32)) >> 1) as i32) as i32); } else {
			if info.bpp == 8 { width = ((((*s).img_x) as i32) as i32); } else {
				c_runtime::free(((_out_) as *mut u8));
				return (if stbi__err((("bad bpp"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
			}
		}
		pad = (((-width) & 3) as i32);
		j = ((0) as i32);
		while (j < (((*s).img_y) as i32)) {
			i = ((0) as i32);
			while (i < (((*s).img_x) as i32)) {
				let mut v: i32 = ((stbi__get8(((s) as *mut stbi__context))) as i32);
				let mut v2: i32 = 0;
				if info.bpp == 4 {
					v2 = ((v & 15) as i32);
					v >>= 4;
				}
				*_out_.offset((z) as isize) = ((**pal.as_mut_ptr().offset((v) as isize).as_mut_ptr().offset((0) as isize)) as u8);
				z += 1;
				*_out_.offset((z) as isize) = ((**pal.as_mut_ptr().offset((v) as isize).as_mut_ptr().offset((1) as isize)) as u8);
				z += 1;
				*_out_.offset((z) as isize) = ((**pal.as_mut_ptr().offset((v) as isize).as_mut_ptr().offset((2) as isize)) as u8);
				z += 1;
				if target == 4 {
					*_out_.offset((z) as isize) = (((255) as u8) as u8);
					z += 1;
				}
				if i + 1 == (((*s).img_x) as i32) { break; }
				v = ((if (info.bpp == 8) { ((stbi__get8(((s) as *mut stbi__context))) as i32) } else { v2 }) as i32);
				*_out_.offset((z) as isize) = ((**pal.as_mut_ptr().offset((v) as isize).as_mut_ptr().offset((0) as isize)) as u8);
				z += 1;
				*_out_.offset((z) as isize) = ((**pal.as_mut_ptr().offset((v) as isize).as_mut_ptr().offset((1) as isize)) as u8);
				z += 1;
				*_out_.offset((z) as isize) = ((**pal.as_mut_ptr().offset((v) as isize).as_mut_ptr().offset((2) as isize)) as u8);
				z += 1;
				if target == 4 {
					*_out_.offset((z) as isize) = (((255) as u8) as u8);
					z += 1;
				}
				i += ((2) as i32);
			}
			stbi__skip(((s) as *mut stbi__context), ((pad) as i32));
			j += 1;
		}
	} else {
		let mut rshift: i32 = 0;
		let mut gshift: i32 = 0;
		let mut bshift: i32 = 0;
		let mut ashift: i32 = 0;
		let mut rcount: i32 = 0;
		let mut gcount: i32 = 0;
		let mut bcount: i32 = 0;
		let mut acount: i32 = 0;
		let mut z: i32 = 0;
		let mut easy: i32 = 0;
		stbi__skip(((s) as *mut stbi__context), ((info.offset - 14 - info.hsz) as i32));
		if info.bpp == 24 { width = (((((3) as u32) * (*s).img_x) as i32) as i32); } else { if info.bpp == 16 { width = (((((2) as u32) * (*s).img_x) as i32) as i32); } else { width = ((0) as i32); } }
		pad = (((-width) & 3) as i32);
		if info.bpp == 24 {
			easy = ((1) as i32);
		} else {
			if info.bpp == 32 {
				if mb == ((0xff) as u32) && mg == ((0xff00) as u32) && mr == ((0x00ff0000) as u32) && ma == 0xff000000 { easy = ((2) as i32); }
			}
		}
		if easy == 0 {
			if mr == 0 || mg == 0 || mb == 0 {
				c_runtime::free(((_out_) as *mut u8));
				return (if stbi__err((("bad masks"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
			}
			rshift = ((stbi__high_bit(((mr) as u32)) - 7) as i32);
			rcount = ((stbi__bitcount(((mr) as u32))) as i32);
			gshift = ((stbi__high_bit(((mg) as u32)) - 7) as i32);
			gcount = ((stbi__bitcount(((mg) as u32))) as i32);
			bshift = ((stbi__high_bit(((mb) as u32)) - 7) as i32);
			bcount = ((stbi__bitcount(((mb) as u32))) as i32);
			ashift = ((stbi__high_bit(((ma) as u32)) - 7) as i32);
			acount = ((stbi__bitcount(((ma) as u32))) as i32);
		}
		j = ((0) as i32);
		while (j < (((*s).img_y) as i32)) {
			if (easy) != 0 {
				i = ((0) as i32);
				while (i < (((*s).img_x) as i32)) {
					let mut a: u8 = std::mem::uninitialized();
					*_out_.offset((z + 2) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
					*_out_.offset((z + 1) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
					*_out_.offset((z + 0) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
					z += ((3) as i32);
					a = (((if easy == 2 { ((stbi__get8(((s) as *mut stbi__context))) as i32) } else { 255 }) as u8) as u8);
					all_a |= (((a) as u32) as u32);
					if target == 4 {
						*_out_.offset((z) as isize) = ((a) as u8);
						z += 1;
					}
					i += 1;
				}
			} else {
				let mut bpp: i32 = info.bpp;
				i = ((0) as i32);
				while (i < (((*s).img_x) as i32)) {
					let mut v: u32 = (if bpp == 16 { ((stbi__get16le(((s) as *mut stbi__context))) as u32) } else { stbi__get32le(((s) as *mut stbi__context)) });
					let mut a: i32 = std::mem::uninitialized();
					*_out_.offset((z) as isize) = ((((stbi__shiftsigned((((v & mr) as i32) as i32), ((rshift) as i32), ((rcount) as i32))) & 255) as u8) as u8);
					z += 1;
					*_out_.offset((z) as isize) = ((((stbi__shiftsigned((((v & mg) as i32) as i32), ((gshift) as i32), ((gcount) as i32))) & 255) as u8) as u8);
					z += 1;
					*_out_.offset((z) as isize) = ((((stbi__shiftsigned((((v & mb) as i32) as i32), ((bshift) as i32), ((bcount) as i32))) & 255) as u8) as u8);
					z += 1;
					a = ((if (ma) != 0 { stbi__shiftsigned((((v & ma) as i32) as i32), ((ashift) as i32), ((acount) as i32)) } else { 255 }) as i32);
					all_a |= (((a) as u32) as u32);
					if target == 4 {
						*_out_.offset((z) as isize) = ((((a) & 255) as u8) as u8);
						z += 1;
					}
					i += 1;
				}
			}
			stbi__skip(((s) as *mut stbi__context), ((pad) as i32));
			j += 1;
		}
	}
	if target == 4 && all_a == ((0) as u32) {
		i = (((((4) as u32) * (*s).img_x * (*s).img_y - ((1) as u32)) as i32) as i32);
		while (i >= 0) {
			*_out_.offset((i) as isize) = (((255) as u8) as u8);
			i -= ((4) as i32);
		}
	}
	if (flip_vertically) != 0 {
		let mut t: u8 = std::mem::uninitialized();
		j = ((0) as i32);
		while (j < ((((*s).img_y) as i32) >> 1)) {
			let mut p1: *mut u8 = (_out_).offset((((j) as u32) * (*s).img_x * ((target) as u32)) as isize);
			let mut p2: *mut u8 = (_out_).offset((((*s).img_y - ((1) as u32) - ((j) as u32)) * (*s).img_x * ((target) as u32)) as isize);
			i = ((0) as i32);
			while (i < (((*s).img_x) as i32) * target) {
				t = ((*p1.offset((i) as isize)) as u8);
				*p1.offset((i) as isize) = ((*p2.offset((i) as isize)) as u8);
				*p2.offset((i) as isize) = ((t) as u8);
				i += 1;
			}
			j += 1;
		}
	}
	if (req_comp) != 0 && req_comp != target {
		_out_ = stbi__convert_format(((_out_) as *mut u8), ((target) as i32), ((req_comp) as i32), (((*s).img_x) as u32), (((*s).img_y) as u32));
		if _out_ == (std::ptr::null_mut()) { return _out_; }
	}
	*x = ((((*s).img_x) as i32) as i32);
	*y = ((((*s).img_y) as i32) as i32);
	if (comp) != std::ptr::null_mut() { *comp = (((*s).img_n) as i32); }
	return _out_;
}

pub unsafe fn stbi__tga_get_comp(mut bits_per_pixel: i32, mut is_grey: i32, mut is_rgb16: *mut i32) -> i32 {
	if (is_rgb16) != std::ptr::null_mut() { *is_rgb16 = ((0) as i32); }
	{
		if bits_per_pixel == 8 { return STBI_grey; } else if bits_per_pixel == 15 {} else if bits_per_pixel == 16 {
			if bits_per_pixel == 16 && (is_grey) != 0 { return STBI_grey_alpha; }
			if (is_rgb16) != std::ptr::null_mut() { *is_rgb16 = ((1) as i32); }
			return STBI_rgb;
		} else if bits_per_pixel == 24 {} else if bits_per_pixel == 32 { return bits_per_pixel / 8; } else { return 0; }
	}
}

pub unsafe fn stbi__tga_info(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
	let mut tga_w: i32 = std::mem::uninitialized();
	let mut tga_h: i32 = std::mem::uninitialized();
	let mut tga_comp: i32 = std::mem::uninitialized();
	let mut tga_image_type: i32 = std::mem::uninitialized();
	let mut tga_bits_per_pixel: i32 = std::mem::uninitialized();
	let mut tga_colormap_bpp: i32 = std::mem::uninitialized();
	let mut sz: i32 = std::mem::uninitialized();
	let mut tga_colormap_type: i32 = std::mem::uninitialized();
	stbi__get8(((s) as *mut stbi__context));
	tga_colormap_type = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
	if tga_colormap_type > 1 {
		stbi__rewind(((s) as *mut stbi__context));
		return 0;
	}
	tga_image_type = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
	if tga_colormap_type == 1 {
		if tga_image_type != 1 && tga_image_type != 9 {
			stbi__rewind(((s) as *mut stbi__context));
			return 0;
		}
		stbi__skip(((s) as *mut stbi__context), ((4) as i32));
		sz = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
		if (sz != 8) && (sz != 15) && (sz != 16) && (sz != 24) && (sz != 32) {
			stbi__rewind(((s) as *mut stbi__context));
			return 0;
		}
		stbi__skip(((s) as *mut stbi__context), ((4) as i32));
		tga_colormap_bpp = ((sz) as i32);
	} else {
		if (tga_image_type != 2) && (tga_image_type != 3) && (tga_image_type != 10) && (tga_image_type != 11) {
			stbi__rewind(((s) as *mut stbi__context));
			return 0;
		}
		stbi__skip(((s) as *mut stbi__context), ((9) as i32));
		tga_colormap_bpp = ((0) as i32);
	}
	tga_w = ((stbi__get16le(((s) as *mut stbi__context))) as i32);
	if tga_w < 1 {
		stbi__rewind(((s) as *mut stbi__context));
		return 0;
	}
	tga_h = ((stbi__get16le(((s) as *mut stbi__context))) as i32);
	if tga_h < 1 {
		stbi__rewind(((s) as *mut stbi__context));
		return 0;
	}
	tga_bits_per_pixel = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
	stbi__get8(((s) as *mut stbi__context));
	if tga_colormap_bpp != 0 {
		if (tga_bits_per_pixel != 8) && (tga_bits_per_pixel != 16) {
			stbi__rewind(((s) as *mut stbi__context));
			return 0;
		}
		tga_comp = ((stbi__tga_get_comp(((tga_colormap_bpp) as i32), ((0) as i32), ((std::ptr::null_mut()) as *mut i32))) as i32);
	} else {
		tga_comp = ((stbi__tga_get_comp(((tga_bits_per_pixel) as i32), (((tga_image_type == 3) || (tga_image_type == 11)) as i32), ((std::ptr::null_mut()) as *mut i32))) as i32);
	}
	if tga_comp == 0 {
		stbi__rewind(((s) as *mut stbi__context));
		return 0;
	}
	if (x) != std::ptr::null_mut() { *x = ((tga_w) as i32); }
	if (y) != std::ptr::null_mut() { *y = ((tga_h) as i32); }
	if (comp) != std::ptr::null_mut() { *comp = ((tga_comp) as i32); }
	return 1;
}

pub unsafe fn stbi__tga_read_rgb16(mut s: *mut stbi__context, mut _out_: *mut u8) {
	let mut px: u16 = ((stbi__get16le(((s) as *mut stbi__context))) as u16);
	let mut fiveBitMask: u16 = ((31) as u16);
	let mut r: i32 = (((px) as i32) >> 10) & ((fiveBitMask) as i32);
	let mut g: i32 = (((px) as i32) >> 5) & ((fiveBitMask) as i32);
	let mut b: i32 = ((px) as i32) & ((fiveBitMask) as i32);
	*_out_.offset((0) as isize) = ((((r * 255) / 31) as u8) as u8);
	*_out_.offset((1) as isize) = ((((g * 255) / 31) as u8) as u8);
	*_out_.offset((2) as isize) = ((((b * 255) / 31) as u8) as u8);
}

pub unsafe fn stbi__tga_load(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32, mut ri: *mut stbi__result_info) -> *mut u8 {
	let mut tga_offset: i32 = ((stbi__get8(((s) as *mut stbi__context))) as i32);
	let mut tga_indexed: i32 = ((stbi__get8(((s) as *mut stbi__context))) as i32);
	let mut tga_image_type: i32 = ((stbi__get8(((s) as *mut stbi__context))) as i32);
	let mut tga_is_RLE: i32 = 0;
	let mut tga_palette_start: i32 = stbi__get16le(((s) as *mut stbi__context));
	let mut tga_palette_len: i32 = stbi__get16le(((s) as *mut stbi__context));
	let mut tga_palette_bits: i32 = ((stbi__get8(((s) as *mut stbi__context))) as i32);
	let mut tga_x_origin: i32 = stbi__get16le(((s) as *mut stbi__context));
	let mut tga_y_origin: i32 = stbi__get16le(((s) as *mut stbi__context));
	let mut tga_width: i32 = stbi__get16le(((s) as *mut stbi__context));
	let mut tga_height: i32 = stbi__get16le(((s) as *mut stbi__context));
	let mut tga_bits_per_pixel: i32 = ((stbi__get8(((s) as *mut stbi__context))) as i32);
	let mut tga_comp: i32 = std::mem::uninitialized();
	let mut tga_rgb16: i32 = 0;
	let mut tga_inverted: i32 = ((stbi__get8(((s) as *mut stbi__context))) as i32);
	let mut tga_data: *mut u8;
	let mut tga_palette: *mut u8 = (std::ptr::null_mut());
	let mut i: i32 = std::mem::uninitialized();
	let mut j: i32 = std::mem::uninitialized();
	let mut raw_data: [u8; 4] = [((0) as u8)];
	let mut RLE_count: i32 = 0;
	let mut RLE_repeating: i32 = 0;
	let mut read_next_pixel: i32 = 1;
	if tga_image_type >= 8 {
		tga_image_type -= ((8) as i32);
		tga_is_RLE = ((1) as i32);
	}
	tga_inverted = ((1 - ((tga_inverted >> 5) & 1)) as i32);
	if (tga_indexed) != 0 { tga_comp = ((stbi__tga_get_comp(((tga_palette_bits) as i32), ((0) as i32), ((&mut tga_rgb16) as *mut i32))) as i32); } else { tga_comp = ((stbi__tga_get_comp(((tga_bits_per_pixel) as i32), ((tga_image_type == 3) as i32), ((&mut tga_rgb16) as *mut i32))) as i32); }
	if tga_comp == 0 { return (if stbi__err((("bad format"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	*x = ((tga_width) as i32);
	*y = ((tga_height) as i32);
	if (comp) != std::ptr::null_mut() { *comp = ((tga_comp) as i32); }
	if stbi__mad3sizes_valid(((tga_width) as i32), ((tga_height) as i32), ((tga_comp) as i32), ((0) as i32)) == 0 { return (if stbi__err((("too large"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	tga_data = stbi__malloc_mad3(((tga_width) as i32), ((tga_height) as i32), ((tga_comp) as i32), ((0) as i32));
	if tga_data == std::ptr::null_mut() { return (if stbi__err((("outofmem"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	stbi__skip(((s) as *mut stbi__context), ((tga_offset) as i32));
	if tga_indexed == 0 && tga_is_RLE == 0 && tga_rgb16 == 0 {
		i = ((0) as i32);
		while (i < tga_height) {
			let mut row: i32 = if (tga_inverted) != 0 { tga_height - i - 1 } else { i };
			let mut tga_row: *mut u8 = (tga_data).offset((row * tga_width * tga_comp) as isize);
			stbi__getn(((s) as *mut stbi__context), ((tga_row) as *mut u8), ((tga_width * tga_comp) as i32));
			i += 1;
		}
	} else {
		if (tga_indexed) != 0 {
			stbi__skip(((s) as *mut stbi__context), ((tga_palette_start) as i32));
			tga_palette = stbi__malloc_mad2(((tga_palette_len) as i32), ((tga_comp) as i32), ((0) as i32));
			if tga_palette == std::ptr::null_mut() {
				c_runtime::free(((tga_data) as *mut u8));
				return (if stbi__err((("outofmem"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
			}
			if (tga_rgb16) != 0 {
				let mut pal_entry: *mut u8 = tga_palette;
				i = ((0) as i32);
				while (i < tga_palette_len) {
					stbi__tga_read_rgb16(((s) as *mut stbi__context), ((pal_entry) as *mut u8));
					pal_entry = pal_entry.offset((((tga_comp) as *mut u8)) as isize);
					i += 1;
				}
			} else {
				if stbi__getn(((s) as *mut stbi__context), ((tga_palette) as *mut u8), ((tga_palette_len * tga_comp) as i32)) == 0 {
					c_runtime::free(((tga_data) as *mut u8));
					c_runtime::free(((tga_palette) as *mut u8));
					return (if stbi__err((("bad palette"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
				}
			}
		}
		i = ((0) as i32);
		while (i < tga_width * tga_height) {
			if (tga_is_RLE) != 0 {
				if RLE_count == 0 {
					let mut RLE_cmd: i32 = ((stbi__get8(((s) as *mut stbi__context))) as i32);
					RLE_count = ((1 + (RLE_cmd & 127)) as i32);
					RLE_repeating = ((RLE_cmd >> 7) as i32);
					read_next_pixel = ((1) as i32);
				} else {
					if RLE_repeating == 0 {
						read_next_pixel = ((1) as i32);
					}
				}
			} else {
				read_next_pixel = ((1) as i32);
			}
			if (read_next_pixel) != 0 {
				if (tga_indexed) != 0 {
					let mut pal_idx: i32 = if (tga_bits_per_pixel == 8) { ((stbi__get8(((s) as *mut stbi__context))) as i32) } else { stbi__get16le(((s) as *mut stbi__context)) };
					if pal_idx >= tga_palette_len {
						pal_idx = ((0) as i32);
					}
					pal_idx *= ((tga_comp) as i32);
					j = ((0) as i32);
					while (j < tga_comp) {
						*raw_data.as_mut_ptr().offset((j) as isize) = ((*tga_palette.offset((pal_idx + j) as isize)) as u8);
						j += 1;
					}
				} else {
					if (tga_rgb16) != 0 {
						stbi__tga_read_rgb16(((s) as *mut stbi__context), ((raw_data.as_mut_ptr()) as *mut u8));
					} else {
						j = ((0) as i32);
						while (j < tga_comp) {
							*raw_data.as_mut_ptr().offset((j) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
							j += 1;
						}
					}
				}
				read_next_pixel = ((0) as i32);
			}
			j = ((0) as i32);
			while (j < tga_comp) {
				*tga_data.offset((i * tga_comp + j) as isize) = ((*raw_data.as_mut_ptr().offset((j) as isize)) as u8);
				j += 1;
			}
			RLE_count -= 1;
			i += 1;
		}
		if (tga_inverted) != 0 {
			j = ((0) as i32);
			while (j * 2 < tga_height) {
				let mut index1: i32 = j * tga_width * tga_comp;
				let mut index2: i32 = (tga_height - 1 - j) * tga_width * tga_comp;
				i = ((tga_width * tga_comp) as i32);
				while (i > 0) {
					let mut temp: u8 = *tga_data.offset((index1) as isize);
					*tga_data.offset((index1) as isize) = ((*tga_data.offset((index2) as isize)) as u8);
					*tga_data.offset((index2) as isize) = ((temp) as u8);
					index1 += 1;
					index2 += 1;
					i -= 1;
				}
				j += 1;
			}
		}
		if tga_palette != (std::ptr::null_mut()) {
			c_runtime::free(((tga_palette) as *mut u8));
		}
	}
	if tga_comp >= 3 && tga_rgb16 == 0 {
		let mut tga_pixel: *mut u8 = tga_data;
		i = ((0) as i32);
		while (i < tga_width * tga_height) {
			let mut temp: u8 = *tga_pixel.offset((0) as isize);
			*tga_pixel.offset((0) as isize) = ((*tga_pixel.offset((2) as isize)) as u8);
			*tga_pixel.offset((2) as isize) = ((temp) as u8);
			tga_pixel = tga_pixel.offset((((tga_comp) as *mut u8)) as isize);
			i += 1;
		}
	}
	if (req_comp) != 0 && req_comp != tga_comp { tga_data = stbi__convert_format(((tga_data) as *mut u8), ((tga_comp) as i32), ((req_comp) as i32), (((tga_width) as u32) as u32), (((tga_height) as u32) as u32)); }
	tga_palette_start = 0;
	tga_palette_len = 0;
	tga_palette_bits = 0;
	tga_x_origin = 0;
	tga_y_origin = 0;
	return tga_data;
}

pub unsafe fn stbi__psd_test(mut s: *mut stbi__context) -> i32 {
	let mut r: i32 = (stbi__get32be(((s) as *mut stbi__context)) == ((0x38425053) as u32));
	stbi__rewind(((s) as *mut stbi__context));
	return r;
}

pub unsafe fn stbi__psd_decode_rle(mut s: *mut stbi__context, mut p: *mut u8, mut pixelCount: i32) -> i32 {
	let mut count: i32 = std::mem::uninitialized();
	let mut nleft: i32 = std::mem::uninitialized();
	let mut len: i32 = std::mem::uninitialized();
	count = ((0) as i32);
	while ((pixelCount - count) > 0) {
		nleft = ((pixelCount - count) as i32);
		len = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
		if len == 128 {} else {
			if len < 128 {
				len += 1;
				if len > nleft { return 0; }
				count += ((len) as i32);
				while ((len) != 0) {
					*p = ((stbi__get8(((s) as *mut stbi__context))) as u8);
					p = p.offset((((4) as *mut u8)) as isize);
					len -= 1;
				}
			} else {
				if len > 128 {
					let mut val: u8 = std::mem::uninitialized();
					len = ((257 - len) as i32);
					if len > nleft { return 0; }
					val = ((stbi__get8(((s) as *mut stbi__context))) as u8);
					count += ((len) as i32);
					while ((len) != 0) {
						*p = ((val) as u8);
						p = p.offset((((4) as *mut u8)) as isize);
						len -= 1;
					}
				}
			}
		}
	}
	return 1;
}

pub unsafe fn stbi__psd_load(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32, mut ri: *mut stbi__result_info, mut bpc: i32) -> *mut u8 {
	let mut pixelCount: i32 = std::mem::uninitialized();
	let mut channelCount: i32 = std::mem::uninitialized();
	let mut compression: i32 = std::mem::uninitialized();
	let mut channel: i32 = std::mem::uninitialized();
	let mut i: i32 = std::mem::uninitialized();
	let mut bitdepth: i32 = std::mem::uninitialized();
	let mut w: i32 = std::mem::uninitialized();
	let mut h: i32 = std::mem::uninitialized();
	let mut _out_: *mut u8;
	if stbi__get32be(((s) as *mut stbi__context)) != ((0x38425053) as u32) { return (if stbi__err((("not PSD"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	if stbi__get16be(((s) as *mut stbi__context)) != 1 { return (if stbi__err((("wrong version"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	stbi__skip(((s) as *mut stbi__context), ((6) as i32));
	channelCount = ((stbi__get16be(((s) as *mut stbi__context))) as i32);
	if channelCount < 0 || channelCount > 16 { return (if stbi__err((("wrong channel count"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	h = (((stbi__get32be(((s) as *mut stbi__context))) as i32) as i32);
	w = (((stbi__get32be(((s) as *mut stbi__context))) as i32) as i32);
	bitdepth = ((stbi__get16be(((s) as *mut stbi__context))) as i32);
	if bitdepth != 8 && bitdepth != 16 { return (if stbi__err((("unsupported bit depth"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	if stbi__get16be(((s) as *mut stbi__context)) != 3 { return (if stbi__err((("wrong color format"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	stbi__skip(((s) as *mut stbi__context), (((stbi__get32be(((s) as *mut stbi__context))) as i32) as i32));
	stbi__skip(((s) as *mut stbi__context), (((stbi__get32be(((s) as *mut stbi__context))) as i32) as i32));
	stbi__skip(((s) as *mut stbi__context), (((stbi__get32be(((s) as *mut stbi__context))) as i32) as i32));
	compression = ((stbi__get16be(((s) as *mut stbi__context))) as i32);
	if compression > 1 { return (if stbi__err((("bad compression"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	if stbi__mad3sizes_valid(((4) as i32), ((w) as i32), ((h) as i32), ((0) as i32)) == 0 { return (if stbi__err((("too large"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	if compression == 0 && bitdepth == 16 && bpc == 16 {
		_out_ = stbi__malloc_mad3(((8) as i32), ((w) as i32), ((h) as i32), ((0) as i32));
		(*ri).bits_per_channel = ((16) as i32);
	} else { _out_ = stbi__malloc((((4 * w * h) as u64) as u64)); }
	if _out_ == std::ptr::null_mut() { return (if stbi__err((("outofmem"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	pixelCount = ((w * h) as i32);
	if (compression) != 0 {
		stbi__skip(((s) as *mut stbi__context), ((h * channelCount * 2) as i32));
		channel = ((0) as i32);
		while (channel < 4) {
			let mut p: *mut u8;
			p = (_out_).offset((channel) as isize);
			if channel >= channelCount {
				i = ((0) as i32);
				while (i < pixelCount) {
					*p = (((if channel == 3 { 255 } else { 0 }) as u8) as u8);
					i += 1;
					p = p.offset((((4) as *mut u8)) as isize);
				}
			} else {
				if stbi__psd_decode_rle(((s) as *mut stbi__context), ((p) as *mut u8), ((pixelCount) as i32)) == 0 {
					c_runtime::free(((_out_) as *mut u8));
					return (if stbi__err((("corrupt"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
				}
			}
			channel += 1;
		}
	} else {
		channel = ((0) as i32);
		while (channel < 4) {
			if channel >= channelCount {
				if bitdepth == 16 && bpc == 16 {
					let mut q: *mut u16 = (((_out_) as *mut u16)).offset((channel) as isize);
					let mut val: u16 = ((if channel == 3 { 65535 } else { 0 }) as u16);
					i = ((0) as i32);
					while (i < pixelCount) {
						*q = ((val) as u16);
						i += 1;
						q = q.offset((((4) as *mut u16)) as isize);
					}
				} else {
					let mut p: *mut u8 = (_out_).offset((channel) as isize);
					let mut val: u8 = ((if channel == 3 { 255 } else { 0 }) as u8);
					i = ((0) as i32);
					while (i < pixelCount) {
						*p = ((val) as u8);
						i += 1;
						p = p.offset((((4) as *mut u8)) as isize);
					}
				}
			} else {
				if (*ri).bits_per_channel == 16 {
					let mut q: *mut u16 = (((_out_) as *mut u16)).offset((channel) as isize);
					i = ((0) as i32);
					while (i < pixelCount) {
						*q = (((stbi__get16be(((s) as *mut stbi__context))) as u16) as u16);
						i += 1;
						q = q.offset((((4) as *mut u16)) as isize);
					}
				} else {
					let mut p: *mut u8 = (_out_).offset((channel) as isize);
					if bitdepth == 16 {
						i = ((0) as i32);
						while (i < pixelCount) {
							*p = (((stbi__get16be(((s) as *mut stbi__context)) >> 8) as u8) as u8);
							i += 1;
							p = p.offset((((4) as *mut u8)) as isize);
						}
					} else {
						i = ((0) as i32);
						while (i < pixelCount) {
							*p = ((stbi__get8(((s) as *mut stbi__context))) as u8);
							i += 1;
							p = p.offset((((4) as *mut u8)) as isize);
						}
					}
				}
			}
			channel += 1;
		}
	}
	if channelCount >= 4 {
		if (*ri).bits_per_channel == 16 {
			i = ((0) as i32);
			while (i < w * h) {
				let mut pixel: *mut u16 = (((_out_) as *mut u16)).offset((4 * i) as isize);
				if ((*pixel.offset((3) as isize)) as i32) != 0 && ((*pixel.offset((3) as isize)) as i32) != 65535 {
					let mut a: f32 = (((*pixel.offset((3) as isize)) as i32) as f32) / 65535.0f32;
					let mut ra: f32 = 1.0f32 / a;
					let mut inv_a: f32 = 65535.0f32 * (((1) as f32) - ra);
					*pixel.offset((0) as isize) = ((((((*pixel.offset((0) as isize)) as i32) as f32) * ra + inv_a) as u16) as u16);
					*pixel.offset((1) as isize) = ((((((*pixel.offset((1) as isize)) as i32) as f32) * ra + inv_a) as u16) as u16);
					*pixel.offset((2) as isize) = ((((((*pixel.offset((2) as isize)) as i32) as f32) * ra + inv_a) as u16) as u16);
				}
				i += 1;
			}
		} else {
			i = ((0) as i32);
			while (i < w * h) {
				let mut pixel: *mut u8 = (_out_).offset((4 * i) as isize);
				if ((*pixel.offset((3) as isize)) as i32) != 0 && ((*pixel.offset((3) as isize)) as i32) != 255 {
					let mut a: f32 = (((*pixel.offset((3) as isize)) as i32) as f32) / 255.0f32;
					let mut ra: f32 = 1.0f32 / a;
					let mut inv_a: f32 = 255.0f32 * (((1) as f32) - ra);
					*pixel.offset((0) as isize) = ((((((*pixel.offset((0) as isize)) as i32) as f32) * ra + inv_a) as u8) as u8);
					*pixel.offset((1) as isize) = ((((((*pixel.offset((1) as isize)) as i32) as f32) * ra + inv_a) as u8) as u8);
					*pixel.offset((2) as isize) = ((((((*pixel.offset((2) as isize)) as i32) as f32) * ra + inv_a) as u8) as u8);
				}
				i += 1;
			}
		}
	}
	if (req_comp) != 0 && req_comp != 4 {
		if (*ri).bits_per_channel == 16 { _out_ = ((stbi__convert_format16((((_out_) as *mut u16) as *mut u16), ((4) as i32), ((req_comp) as i32), (((w) as u32) as u32), (((h) as u32) as u32))) as *mut u8); } else { _out_ = stbi__convert_format(((_out_) as *mut u8), ((4) as i32), ((req_comp) as i32), (((w) as u32) as u32), (((h) as u32) as u32)); }
		if _out_ == (std::ptr::null_mut()) { return _out_; }
	}
	if (comp) != std::ptr::null_mut() { *comp = ((4) as i32); }
	*y = ((h) as i32);
	*x = ((w) as i32);
	return _out_;
}

pub unsafe fn stbi__gif_test_raw(mut s: *mut stbi__context) -> i32 {
	let mut sz: i32 = std::mem::uninitialized();
	if ((stbi__get8(((s) as *mut stbi__context))) as i32) != 'G' || ((stbi__get8(((s) as *mut stbi__context))) as i32) != 'I' || ((stbi__get8(((s) as *mut stbi__context))) as i32) != 'F' || ((stbi__get8(((s) as *mut stbi__context))) as i32) != '8' { return 0; }
	sz = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
	if sz != '9' && sz != '7' { return 0; }
	if ((stbi__get8(((s) as *mut stbi__context))) as i32) != 'a' { return 0; }
	return 1;
}

pub unsafe fn stbi__gif_test(mut s: *mut stbi__context) -> i32 {
	let mut r: i32 = stbi__gif_test_raw(((s) as *mut stbi__context));
	stbi__rewind(((s) as *mut stbi__context));
	return r;
}

pub unsafe fn stbi__gif_parse_colortable(mut s: *mut stbi__context, mut pal: *mut *mut u8, mut num_entries: i32, mut transp: i32) {
	let mut i: i32 = std::mem::uninitialized();
	i = ((0) as i32);
	while (i < num_entries) {
		**pal.offset((i) as isize).as_mut_ptr().offset((2) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
		**pal.offset((i) as isize).as_mut_ptr().offset((1) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
		**pal.offset((i) as isize).as_mut_ptr().offset((0) as isize) = ((stbi__get8(((s) as *mut stbi__context))) as u8);
		**pal.offset((i) as isize).as_mut_ptr().offset((3) as isize) = (((if transp == i { 0 } else { 255 }) as u8) as u8);
		i += 1;
	}
}

pub unsafe fn stbi__gif_header(mut s: *mut stbi__context, mut g: *mut stbi__gif, mut comp: *mut i32, mut is_info: i32) -> i32 {
	let mut version: u8 = std::mem::uninitialized();
	if ((stbi__get8(((s) as *mut stbi__context))) as i32) != 'G' || ((stbi__get8(((s) as *mut stbi__context))) as i32) != 'I' || ((stbi__get8(((s) as *mut stbi__context))) as i32) != 'F' || ((stbi__get8(((s) as *mut stbi__context))) as i32) != '8' { return stbi__err((("not GIF"))); }
	version = ((stbi__get8(((s) as *mut stbi__context))) as u8);
	if ((version) as i32) != '7' && ((version) as i32) != '9' { return stbi__err((("not GIF"))); }
	if ((stbi__get8(((s) as *mut stbi__context))) as i32) != 'a' { return stbi__err((("not GIF"))); }
	stbi__g_failure_reason = "";
	(*g).w = ((stbi__get16le(((s) as *mut stbi__context))) as i32);
	(*g).h = ((stbi__get16le(((s) as *mut stbi__context))) as i32);
	(*g).flags = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
	(*g).bgindex = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
	(*g).ratio = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
	(*g).transparent = ((-1) as i32);
	if comp != std::ptr::null_mut() { *comp = ((4) as i32); }
	if (is_info) != 0 { return 1; }
	if ((*g).flags & 0x80) != 0 { stbi__gif_parse_colortable(((s) as *mut stbi__context), (((*g).pal.as_mut_ptr()) as *mut [u8; 4]), ((2 << ((*g).flags & 7)) as i32), ((-1) as i32)); }
	return 1;
}

pub unsafe fn stbi__gif_info_raw(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
	let mut g: *mut stbi__gif = ((stbi__malloc(((std::mem::size_of::<stbi__gif>()) as u64))) as *mut stbi__gif);
	if stbi__gif_header(((s) as *mut stbi__context), ((g) as *mut stbi__gif), ((comp) as *mut i32), ((1) as i32)) == 0 {
		c_runtime::free(((g) as *mut stbi__gif));
		stbi__rewind(((s) as *mut stbi__context));
		return 0;
	}
	if (x) != std::ptr::null_mut() { *x = (((*g).w) as i32); }
	if (y) != std::ptr::null_mut() { *y = (((*g).h) as i32); }
	c_runtime::free(((g) as *mut stbi__gif));
	return 1;
}

pub unsafe fn stbi__out_gif_code(mut g: *mut stbi__gif, mut code: u16) {
	let mut p: *mut u8;
	let mut c: *mut u8;
	if ((*(*g).codes.as_mut_ptr().offset((code) as isize).prefix) as i32) >= 0 { stbi__out_gif_code(((g) as *mut stbi__gif), (((*(*g).codes.as_mut_ptr().offset((code) as isize).prefix) as u16) as u16)); }
	if (*g).cur_y >= (*g).max_y { return; }
	p = &mut *(*g)._out_.offset(((*g).cur_x + (*g).cur_y) as isize);
	c = &mut *(*g).color_table.offset((((*(*g).codes.as_mut_ptr().offset((code) as isize).suffix) as i32) * 4) as isize);
	if ((*c.offset((3) as isize)) as i32) >= 128 {
		*p.offset((0) as isize) = ((*c.offset((2) as isize)) as u8);
		*p.offset((1) as isize) = ((*c.offset((1) as isize)) as u8);
		*p.offset((2) as isize) = ((*c.offset((0) as isize)) as u8);
		*p.offset((3) as isize) = ((*c.offset((3) as isize)) as u8);
	}
	(*g).cur_x += ((4) as i32);
	if (*g).cur_x >= (*g).max_x {
		(*g).cur_x = (((*g).start_x) as i32);
		(*g).cur_y += (((*g).step) as i32);
		while ((*g).cur_y >= (*g).max_y && (*g).parse > 0) {
			(*g).step = (((1 << (*g).parse) * (*g).line_size) as i32);
			(*g).cur_y = (((*g).start_y + ((*g).step >> 1)) as i32);
			(*g).parse -= 1;
		}
	}
}

pub unsafe fn stbi__process_gif_raster(mut s: *mut stbi__context, mut g: *mut stbi__gif) -> *mut u8 {
	let mut lzw_cs: u8 = std::mem::uninitialized();
	let mut len: i32 = std::mem::uninitialized();
	let mut init_code: i32 = std::mem::uninitialized();
	let mut first: u32 = std::mem::uninitialized();
	let mut codesize: i32 = std::mem::uninitialized();
	let mut codemask: i32 = std::mem::uninitialized();
	let mut avail: i32 = std::mem::uninitialized();
	let mut oldcode: i32 = std::mem::uninitialized();
	let mut bits: i32 = std::mem::uninitialized();
	let mut valid_bits: i32 = std::mem::uninitialized();
	let mut clear: i32 = std::mem::uninitialized();
	let mut p: *mut stbi__gif_lzw;
	lzw_cs = ((stbi__get8(((s) as *mut stbi__context))) as u8);
	if ((lzw_cs) as i32) > 12 { return (std::ptr::null_mut()); }
	clear = ((1 << ((lzw_cs) as i32)) as i32);
	first = (((1) as u32) as u32);
	codesize = ((((lzw_cs) as i32) + 1) as i32);
	codemask = (((1 << codesize) - 1) as i32);
	bits = ((0) as i32);
	valid_bits = ((0) as i32);
	init_code = ((0) as i32);
	while (init_code < clear) {
		*(*g).codes.as_mut_ptr().offset((init_code) as isize).prefix = (((-1) as i16) as i16);
		*(*g).codes.as_mut_ptr().offset((init_code) as isize).first = (((init_code) as u8) as u8);
		*(*g).codes.as_mut_ptr().offset((init_code) as isize).suffix = (((init_code) as u8) as u8);
		init_code += 1;
	}
	avail = ((clear + 2) as i32);
	oldcode = ((-1) as i32);
	len = ((0) as i32);
	;
	while (true) {
		if valid_bits < codesize {
			if len == 0 {
				len = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
				if len == 0 { return (*g)._out_; }
			}
			len -= 1;
			bits |= ((((stbi__get8(((s) as *mut stbi__context))) as i32) << valid_bits) as i32);
			valid_bits += ((8) as i32);
		} else {
			let mut code: i32 = bits & codemask;
			bits >>= codesize;
			valid_bits -= ((codesize) as i32);
			if code == clear {
				codesize = ((((lzw_cs) as i32) + 1) as i32);
				codemask = (((1 << codesize) - 1) as i32);
				avail = ((clear + 2) as i32);
				oldcode = ((-1) as i32);
				first = (((0) as u32) as u32);
			} else {
				if code == clear + 1 {
					stbi__skip(((s) as *mut stbi__context), ((len) as i32));
					len = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
					while (len > 0) {
						stbi__skip(((s) as *mut stbi__context), ((len) as i32));
						len = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
					}
					return (*g)._out_;
				} else {
					if code <= avail {
						if (first) != 0 { return (if stbi__err((("no clear code"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
						if oldcode >= 0 {
							p = &mut *(*g).codes.as_mut_ptr().offset((avail) as isize);
							avail += 1;
							if avail > 4096 { return (if stbi__err((("too many codes"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
							(*p).prefix = (((oldcode) as i16) as i16);
							(*p).first = ((*(*g).codes.as_mut_ptr().offset((oldcode) as isize).first) as u8);
							(*p).suffix = (((if (code == avail) { (((*p).first) as i32) } else { ((*(*g).codes.as_mut_ptr().offset((code) as isize).first) as i32) }) as u8) as u8);
						} else { if code == avail { return (if stbi__err((("illegal code in raster"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); } }
						stbi__out_gif_code(((g) as *mut stbi__gif), (((code) as u16) as u16));
						if (avail & codemask) == 0 && avail <= 0x0FFF {
							codesize += 1;
							codemask = (((1 << codesize) - 1) as i32);
						}
						oldcode = ((code) as i32);
					} else {
						return (if stbi__err((("illegal code in raster"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) });
					}
				}
			}
		}
	}
}

pub unsafe fn stbi__fill_gif_background(mut g: *mut stbi__gif, mut x0: i32, mut y0: i32, mut x1: i32, mut y1: i32) {
	let mut x: i32 = std::mem::uninitialized();
	let mut y: i32 = std::mem::uninitialized();
	let mut c: *mut u8 = *(*g).pal.as_mut_ptr().offset(((*g).bgindex) as isize).as_mut_ptr();
	y = ((y0) as i32);
	while (y < y1) {
		x = ((x0) as i32);
		while (x < x1) {
			let mut p: *mut u8 = &mut *(*g)._out_.offset((y + x) as isize);
			*p.offset((0) as isize) = ((*c.offset((2) as isize)) as u8);
			*p.offset((1) as isize) = ((*c.offset((1) as isize)) as u8);
			*p.offset((2) as isize) = ((*c.offset((0) as isize)) as u8);
			*p.offset((3) as isize) = (((0) as u8) as u8);
			x += ((4) as i32);
		}
		y += ((4 * (*g).w) as i32);
	}
}

pub unsafe fn stbi__gif_load_next(mut s: *mut stbi__context, mut g: *mut stbi__gif, mut comp: *mut i32, mut req_comp: i32) -> *mut u8 {
	let mut i: i32 = std::mem::uninitialized();
	let mut prev_out: *mut u8 = (std::ptr::null_mut());
	if (*g)._out_ == std::ptr::null_mut() && stbi__gif_header(((s) as *mut stbi__context), ((g) as *mut stbi__gif), ((comp) as *mut i32), ((0) as i32)) == 0 { return (std::ptr::null_mut()); }
	if stbi__mad3sizes_valid((((*g).w) as i32), (((*g).h) as i32), ((4) as i32), ((0) as i32)) == 0 { return (if stbi__err((("too large"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	prev_out = (*g)._out_;
	(*g)._out_ = stbi__malloc_mad3(((4) as i32), (((*g).w) as i32), (((*g).h) as i32), ((0) as i32));
	if (*g)._out_ == std::ptr::null_mut() { return (if stbi__err((("outofmem"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
	{
		if (((*g).eflags & 0x1C) >> 2) == 0 { stbi__fill_gif_background(((g) as *mut stbi__gif), ((0) as i32), ((0) as i32), ((4 * (*g).w) as i32), ((4 * (*g).w * (*g).h) as i32)); } else if (((*g).eflags & 0x1C) >> 2) == 1 {
			if (prev_out) != std::ptr::null_mut() { c_runtime::memcpy((((*g)._out_) as *mut u8), ((prev_out) as *mut u8), (((4 * (*g).w * (*g).h) as u64) as u64)); }
			(*g).old_out = prev_out;
		} else if (((*g).eflags & 0x1C) >> 2) == 2 {
			if (prev_out) != std::ptr::null_mut() { c_runtime::memcpy((((*g)._out_) as *mut u8), ((prev_out) as *mut u8), (((4 * (*g).w * (*g).h) as u64) as u64)); }
			stbi__fill_gif_background(((g) as *mut stbi__gif), (((*g).start_x) as i32), (((*g).start_y) as i32), (((*g).max_x) as i32), (((*g).max_y) as i32));
		} else if (((*g).eflags & 0x1C) >> 2) == 3 {
			if ((*g).old_out) != std::ptr::null_mut() {
				i = (((*g).start_y) as i32);
				while (i < (*g).max_y) {
					c_runtime::memcpy(((&mut *(*g)._out_.offset((i + (*g).start_x) as isize)) as *mut u8), ((&mut *(*g).old_out.offset((i + (*g).start_x) as isize)) as *mut u8), ((((*g).max_x - (*g).start_x) as u64) as u64));
					i += ((4 * (*g).w) as i32);
				}
			}
		}
	}
	;
	while (true) {
		{
			if ((stbi__get8(((s) as *mut stbi__context))) as i32) == 0x2C {
				{
					let mut prev_trans: i32 = -1;
					let mut x: i32 = std::mem::uninitialized();
					let mut y: i32 = std::mem::uninitialized();
					let mut w: i32 = std::mem::uninitialized();
					let mut h: i32 = std::mem::uninitialized();
					let mut o: *mut u8;
					x = ((stbi__get16le(((s) as *mut stbi__context))) as i32);
					y = ((stbi__get16le(((s) as *mut stbi__context))) as i32);
					w = ((stbi__get16le(((s) as *mut stbi__context))) as i32);
					h = ((stbi__get16le(((s) as *mut stbi__context))) as i32);
					if ((x + w) > ((*g).w)) || ((y + h) > ((*g).h)) { return (if stbi__err((("bad Image Descriptor"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
					(*g).line_size = (((*g).w * 4) as i32);
					(*g).start_x = ((x * 4) as i32);
					(*g).start_y = ((y * (*g).line_size) as i32);
					(*g).max_x = (((*g).start_x + w * 4) as i32);
					(*g).max_y = (((*g).start_y + h * (*g).line_size) as i32);
					(*g).cur_x = (((*g).start_x) as i32);
					(*g).cur_y = (((*g).start_y) as i32);
					(*g).lflags = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
					if ((*g).lflags & 0x40) != 0 {
						(*g).step = ((8 * (*g).line_size) as i32);
						(*g).parse = ((3) as i32);
					} else {
						(*g).step = (((*g).line_size) as i32);
						(*g).parse = ((0) as i32);
					}
					if ((*g).lflags & 0x80) != 0 {
						stbi__gif_parse_colortable(((s) as *mut stbi__context), (((*g).lpal.as_mut_ptr()) as *mut [u8; 4]), ((2 << ((*g).lflags & 7)) as i32), ((if ((*g).eflags & 0x01) != 0 { (*g).transparent } else { -1 }) as i32));
						(*g).color_table = (((*g).lpal.as_mut_ptr()) as *mut u8);
					} else {
						if ((*g).flags & 0x80) != 0 {
							if (*g).transparent >= 0 && ((*g).eflags & 0x01) != 0 {
								prev_trans = (((**(*g).pal.as_mut_ptr().offset(((*g).transparent) as isize).as_mut_ptr().offset((3) as isize)) as i32) as i32);
								**(*g).pal.as_mut_ptr().offset(((*g).transparent) as isize).as_mut_ptr().offset((3) as isize) = (((0) as u8) as u8);
							}
							(*g).color_table = (((*g).pal.as_mut_ptr()) as *mut u8);
						} else { return (if stbi__err((("missing color table"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
					}
					o = stbi__process_gif_raster(((s) as *mut stbi__context), ((g) as *mut stbi__gif));
					if o == (std::ptr::null_mut()) { return (std::ptr::null_mut()); }
					if prev_trans != -1 { **(*g).pal.as_mut_ptr().offset(((*g).transparent) as isize).as_mut_ptr().offset((3) as isize) = (((prev_trans) as u8) as u8); }
					return o;
				}
			} else if ((stbi__get8(((s) as *mut stbi__context))) as i32) == 0x21 {
				{
					let mut len: i32 = std::mem::uninitialized();
					if ((stbi__get8(((s) as *mut stbi__context))) as i32) == 0xF9 {
						len = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
						if len == 4 {
							(*g).eflags = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
							(*g).delay = ((stbi__get16le(((s) as *mut stbi__context))) as i32);
							(*g).transparent = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
						} else {
							stbi__skip(((s) as *mut stbi__context), ((len) as i32));
						}
					}
					len = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
					while (len != 0) {
						stbi__skip(((s) as *mut stbi__context), ((len) as i32));
						len = (((stbi__get8(((s) as *mut stbi__context))) as i32) as i32);
					}
				}
			} else if ((stbi__get8(((s) as *mut stbi__context))) as i32) == 0x3B { return ((s) as *mut u8); } else { return (if stbi__err((("unknown code"))) != 0 { (std::ptr::null_mut()) } else { (std::ptr::null_mut()) }); }
		}
	}
}

pub unsafe fn stbi__gif_load(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32, mut req_comp: i32, mut ri: *mut stbi__result_info) -> *mut u8 {
	let mut u: *mut u8 = (std::ptr::null_mut());
	let mut g: *mut stbi__gif = ((stbi__malloc(((std::mem::size_of::<stbi__gif>()) as u64))) as *mut stbi__gif);
	c_runtime::memset(((g) as *mut u8), ((0) as i32), ((std::mem::size_of((*g))) as u64));
	u = stbi__gif_load_next(((s) as *mut stbi__context), ((g) as *mut stbi__gif), ((comp) as *mut i32), ((req_comp) as i32));
	if u == ((s) as *mut u8) { u = std::ptr::null_mut(); }
	if (u) != std::ptr::null_mut() {
		*x = (((*g).w) as i32);
		*y = (((*g).h) as i32);
		if (req_comp) != 0 && req_comp != 4 { u = stbi__convert_format(((u) as *mut u8), ((4) as i32), ((req_comp) as i32), ((((*g).w) as u32) as u32), ((((*g).h) as u32) as u32)); }
	} else { if ((*g)._out_) != std::ptr::null_mut() { c_runtime::free((((*g)._out_) as *mut u8)); } }
	c_runtime::free(((g) as *mut stbi__gif));
	return u;
}

pub unsafe fn stbi__gif_info(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
	return stbi__gif_info_raw(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32));
}

pub unsafe fn stbi__bmp_info(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
	let mut p: *mut u8;
	let mut info: stbi__bmp_data = std::mem::uninitialized();
	info.all_a = (((255) as u32) as u32);
	p = stbi__bmp_parse_header(((s) as *mut stbi__context), ((&mut info) as *mut stbi__bmp_data));
	stbi__rewind(((s) as *mut stbi__context));
	if p == (std::ptr::null_mut()) { return 0; }
	if (x) != std::ptr::null_mut() { *x = ((((*s).img_x) as i32) as i32); }
	if (y) != std::ptr::null_mut() { *y = ((((*s).img_y) as i32) as i32); }
	if (comp) != std::ptr::null_mut() { *comp = ((if (info.ma) != 0 { 4 } else { 3 }) as i32); }
	return 1;
}

pub unsafe fn stbi__psd_info(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
	let mut channelCount: i32 = std::mem::uninitialized();
	let mut dummy: i32 = std::mem::uninitialized();
	if x == std::ptr::null_mut() { x = &mut dummy; }
	if y == std::ptr::null_mut() { y = &mut dummy; }
	if comp == std::ptr::null_mut() { comp = &mut dummy; }
	if stbi__get32be(((s) as *mut stbi__context)) != ((0x38425053) as u32) {
		stbi__rewind(((s) as *mut stbi__context));
		return 0;
	}
	if stbi__get16be(((s) as *mut stbi__context)) != 1 {
		stbi__rewind(((s) as *mut stbi__context));
		return 0;
	}
	stbi__skip(((s) as *mut stbi__context), ((6) as i32));
	channelCount = ((stbi__get16be(((s) as *mut stbi__context))) as i32);
	if channelCount < 0 || channelCount > 16 {
		stbi__rewind(((s) as *mut stbi__context));
		return 0;
	}
	*y = (((stbi__get32be(((s) as *mut stbi__context))) as i32) as i32);
	*x = (((stbi__get32be(((s) as *mut stbi__context))) as i32) as i32);
	if stbi__get16be(((s) as *mut stbi__context)) != 8 {
		stbi__rewind(((s) as *mut stbi__context));
		return 0;
	}
	if stbi__get16be(((s) as *mut stbi__context)) != 3 {
		stbi__rewind(((s) as *mut stbi__context));
		return 0;
	}
	*comp = ((4) as i32);
	return 1;
}

pub unsafe fn stbi__info_main(mut s: *mut stbi__context, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
	if (stbi__jpeg_info(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32))) != 0 { return 1; }
	if (stbi__png_info(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32))) != 0 { return 1; }
	if (stbi__gif_info(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32))) != 0 { return 1; }
	if (stbi__bmp_info(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32))) != 0 { return 1; }
	if (stbi__psd_info(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32))) != 0 { return 1; }
	if (stbi__tga_info(((s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32))) != 0 { return 1; }
	return stbi__err((("unknown image type")));
}

pub unsafe fn stbi_info_from_memory(mut buffer: *mut u8, mut len: i32, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
	let mut s: stbi__context = std::mem::uninitialized();
	stbi__start_mem(((&mut s) as *mut stbi__context), ((buffer) as *mut u8), ((len) as i32));
	return stbi__info_main(((&mut s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32));
}

pub unsafe fn stbi_info_from_callbacks(mut c: *mut stbi_io_callbacks, mut user: *mut u8, mut x: *mut i32, mut y: *mut i32, mut comp: *mut i32) -> i32 {
	let mut s: stbi__context = std::mem::uninitialized();
	stbi__start_callbacks(((&mut s) as *mut stbi__context), ((c) as *mut stbi_io_callbacks), ((user) as *mut u8));
	return stbi__info_main(((&mut s) as *mut stbi__context), ((x) as *mut i32), ((y) as *mut i32), ((comp) as *mut i32));
}

static stbi__g_failure_reason: &'static str = "";

#[derive(Clone, Copy)]
pub struct stbi_io_callbacks {
	read: Option<fn(*mut u8, *mut i8, i32) -> i32>,
	skip: fn(*mut u8, i32),
	eof: fn(*mut u8) -> i32,
}

struct stbi__resample {
	resample: unsafe fn(*mut u8, *mut u8, *mut u8, i32, i32) -> *mut u8,
	line0: *mut u8,
	line1: *mut u8,
	hs: i32,
	vs: i32,
	w_lores: i32,
	ystep: i32,
	ypos: i32,
}

struct stbi__jpeg {
	s: *mut stbi__context,
	huff_dc: [stbi__huffman; 4],
	huff_ac: [stbi__huffman; 4],
	dequant: [[u16; 64]; 4],
	fast_ac: [[i16; 512]; 4],
	img_h_max: i32,
	img_v_max: i32,
	img_mcu_x: i32,
	img_mcu_y: i32,
	img_mcu_w: i32,
	img_mcu_h: i32,
	img_comp: [img_comp; 4],
	code_buffer: u32,
	code_bits: i32,
	marker: u8,
	nomore: i32,
	progressive: i32,
	spec_start: i32,
	spec_end: i32,
	succ_high: i32,
	succ_low: i32,
	eob_run: i32,
	jfif: i32,
	app14_color_transform: i32,
	rgb: i32,
	scan_n: i32,
	order: [i32; 4],
	restart_interval: i32,
	todo: i32,
	idct_block_kernel: unsafe fn(*mut u8, i32, *mut i16),
	YCbCr_to_RGB_kernel: unsafe fn(*mut u8, *mut u8, *mut u8, *mut u8, i32, i32),
	resample_row_hv_2_kernel: unsafe fn(*mut u8, *mut u8, *mut u8, i32, i32)
}

unsafe fn stbi__tga_test(s: *mut stbi__context) -> i32 {
	/*    let res: i32 = (i32)(0);
    let sz: i32;
    let tga_color_type: i32;
    stbi__get8(s);
    tga_color_type = (i32)(stbi__get8(s));
    if tga_color_type > 1 { goto errorEnd; }
    sz = (i32)(stbi__get8(s));
    if tga_color_type == 1 {
        if sz != 1 && sz != 9 { goto errorEnd; }
        stbi__skip(s, 4);
        sz = (i32)(stbi__get8(s));
        if sz != 8 && sz != 15 && sz != 16 && sz != 24 && sz != 32 { goto errorEnd; }
        stbi__skip(s, 4);
    } else {
        if sz != 2 && sz != 3 && sz != 10 && sz != 11 { goto errorEnd; }
        stbi__skip(s, 9);
    }
    if stbi__get16le(s) < 1 { goto errorEnd; }
    if stbi__get16le(s) < 1 { goto errorEnd; }
    sz = (i32)(stbi__get8(s));
    if tga_color_type == 1 && sz != 8 && sz != 16 { goto errorEnd; }
    if sz != 8 && sz != 15 && sz != 16 && sz != 24 && sz != 32 { goto errorEnd; }
    res = (i32)(1);
    errorEnd: ;
    stbi__rewind(s);
    return (i32)(res);*/
	return 0;
}

pub fn stbi__err(s: &str) -> i32 {
//    stbi__g_failure_reason = s;
	return 0;
}
